#!/usr/bin/env python3
"""
é€²éšç‰ˆ Android ANR/Tombstone åˆ†æå™¨ v4
æ”¯æ´æ‰€æœ‰ Android ç‰ˆæœ¬çš„ ANR å’Œ Tombstone æ ¼å¼
ä½¿ç”¨ç‰©ä»¶å°å‘è¨­è¨ˆï¼ŒåŸºæ–¼å¤§é‡çœŸå¯¦æ¡ˆä¾‹çš„æ™ºèƒ½åˆ†æ
"""

import os
import re
import sys
import html
import shutil
import time
import json
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Set
from enum import Enum
import traceback


# ============= å·¥å…·å‡½æ•¸ =============

def time_tracker(func_name: str):
    """æ™‚é–“è¿½è¹¤è£é£¾å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            print(f"â±ï¸  {func_name} åŸ·è¡Œæ™‚é–“: {elapsed_time:.3f} ç§’")
            return result
        return wrapper
    return decorator


# ============= è³‡æ–™é¡åˆ¥å®šç¾© =============

class ANRTimeouts:
    """ANR è¶…æ™‚æ™‚é–“å®šç¾©"""
    INPUT_DISPATCHING = 5000  # 5ç§’
    SERVICE_TIMEOUT = 20000   # 20ç§’ (å‰å°æœå‹™)
    SERVICE_BACKGROUND_TIMEOUT = 200000  # 200ç§’ (èƒŒæ™¯æœå‹™)
    BROADCAST_TIMEOUT = 10000  # 10ç§’ (å‰å°å»£æ’­)
    BROADCAST_BACKGROUND_TIMEOUT = 60000  # 60ç§’ (èƒŒæ™¯å»£æ’­)
    CONTENT_PROVIDER_TIMEOUT = 10000  # 10ç§’
    JOB_SCHEDULER_TIMEOUT = 10000  # 10ç§’

class ThreadState(Enum):
    """ç·šç¨‹ç‹€æ…‹æšèˆ‰"""
    RUNNABLE = "RUNNABLE"
    TIMED_WAIT = "TIMED_WAIT"
    WAIT = "WAIT"
    BLOCKED = "BLOCKED"
    SUSPENDED = "SUSPENDED"
    NATIVE = "NATIVE"
    MONITOR = "MONITOR"
    SLEEPING = "SLEEPING"
    ZOMBIE = "ZOMBIE"
    UNKNOWN = "UNKNOWN"


class ANRType(Enum):
    """ANR é¡å‹æšèˆ‰"""
    INPUT_DISPATCHING = "Input ANR"
    SERVICE = "Service ANR"
    BROADCAST = "Broadcast ANR"
    CONTENT_PROVIDER = "Provider ANR"
    ACTIVITY = "Activity ANR"
    FOREGROUND_SERVICE = "Foreground Service ANR"
    UNKNOWN = "Unknown ANR"


# æ“´å±•ä¿¡è™Ÿé¡å‹
class CrashSignal(Enum):
    SIGSEGV = (11, "Segmentation fault")
    SIGABRT = (6, "Abort")
    SIGILL = (4, "Illegal instruction")
    SIGBUS = (7, "Bus error")
    SIGFPE = (8, "Floating point exception")
    SIGKILL = (9, "Kill signal")
    SIGTRAP = (5, "Trace trap")
    SIGSYS = (31, "Bad system call")  # seccomp é•è¦
    SIGPIPE = (13, "Broken pipe")
    UNKNOWN = (0, "Unknown signal")


@dataclass
class ThreadInfo:
    """ç·šç¨‹è³‡è¨Š"""
    name: str
    tid: str
    prio: str = "N/A"
    state: ThreadState = ThreadState.UNKNOWN
    sysTid: Optional[str] = None
    nice: Optional[str] = None
    schedstat: Optional[str] = None
    utm: Optional[str] = None
    stm: Optional[str] = None
    core: Optional[str] = None
    handle: Optional[str] = None
    backtrace: List[str] = field(default_factory=list)
    waiting_info: Optional[str] = None
    held_locks: List[str] = field(default_factory=list)
    waiting_locks: List[str] = field(default_factory=list)

@dataclass
class ANRInfo:
    """ANR è³‡è¨Š"""
    anr_type: ANRType
    process_name: str
    pid: str
    timestamp: Optional[str] = None
    reason: Optional[str] = None
    main_thread: Optional[ThreadInfo] = None
    all_threads: List[ThreadInfo] = field(default_factory=list)
    cpu_usage: Optional[Dict] = None
    memory_info: Optional[Dict] = None
    timeout_info: Optional[Dict] = None  # æ–°å¢æ¬„ä½

@dataclass
class TombstoneInfo:
    """Tombstone è³‡è¨Š"""
    signal: CrashSignal
    signal_code: str
    fault_addr: str
    process_name: str
    pid: str
    tid: str
    thread_name: str
    abort_message: Optional[str] = None
    crash_backtrace: List[Dict] = field(default_factory=list)
    all_threads: List[ThreadInfo] = field(default_factory=list)
    memory_map: List[str] = field(default_factory=list)
    open_files: List[str] = field(default_factory=list)
    registers: Dict[str, str] = field(default_factory=dict)


# ============= åŸºç¤åˆ†æå™¨é¡åˆ¥ =============

class BaseAnalyzer(ABC):
    """åŸºç¤åˆ†æå™¨æŠ½è±¡é¡åˆ¥"""
    
    def __init__(self):
        self.patterns = self._init_patterns()
    
    @abstractmethod
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ–åˆ†ææ¨¡å¼"""
        pass
    
    @abstractmethod
    def analyze(self, file_path: str) -> str:
        """åˆ†ææª”æ¡ˆ"""
        pass


# ============= ANR åˆ†æå™¨ =============

# ============= ANR åˆ†æå™¨ =============

class ANRAnalyzer(BaseAnalyzer):
    """ANR åˆ†æå™¨"""
    
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ– ANR åˆ†ææ¨¡å¼"""
        return {
            'thread_patterns': [
                # æ¨™æº–æ ¼å¼ (Android 4.x - 13)
                r'"([^"]+)"\s+(?:daemon\s+)?prio=(\d+)\s+tid=(\d+)\s+(\w+)',
                # ç°¡åŒ–æ ¼å¼
                r'"([^"]+)".*?tid=(\d+).*?(\w+)',
                # Thread dump æ ¼å¼
                r'Thread-(\d+)\s+"([^"]+)".*?tid=(\d+).*?(\w+)',
                # ART æ ¼å¼ (Android 5.0+)
                r'"([^"]+)".*?\|\s+group="([^"]+)".*?tid=(\d+).*?\|\s+state=(\w)',
                # ç³»çµ±æœå‹™æ ¼å¼
                r'([a-zA-Z0-9._]+)\s+prio=(\d+)\s+tid=(\d+)\s+(\w+)',
                # Native thread æ ¼å¼
                r'Thread\s+(\d+)\s+\(([^)]+)\).*?State:\s+(\w)',
            ],
            'anr_trigger_patterns': [
                r'Input event dispatching timed out.*?Waited\s+(\d+)ms\s+for\s+(.+)',
                r'Reason:\s*Input dispatching timed out.*?Waited\s+(\d+)ms',
                r'executing service\s+([^\s]+).*?timeout=(\d+)ms',
                r'Broadcast of Intent.*?timed out.*?receiver=([^\s]+)',
                r'ContentProvider.*?not responding.*?provider=([^\s]+)',
                r'ANR in\s+([^,\s]+).*?PID:\s*(\d+)',
                r'Subject:\s*ANR.*?Process:\s*([^\s]+)',
                r'Cmd line:\s*([^\s]+)',
                # æ–°å¢çš„æ¨¡å¼
                r'JobScheduler.*?timed out.*?job=([^\s]+)',
                r'Foreground service.*?timed out.*?service=([^\s]+)',
                r'JobService.*?did not return.*?from.*?(\w+)',
            ],
            'lock_patterns': [
                r'waiting to lock\s+<([^>]+)>.*?held by thread\s+(\d+)',
                r'locked\s+<([^>]+)>',
                r'waiting on\s+<([^>]+)>',
                r'- locked\s+<0x([0-9a-f]+)>\s+\(a\s+([^)]+)\)',
                r'heldby=(\d+)',
                # æ–°å¢è·¨é€²ç¨‹é–æ¨¡å¼
                r'held by tid=(\d+) in process (\d+)',
                r'waiting for monitor entry',
                r'waiting for ownable synchronizer',
            ],
            'binder_patterns': [
                r'BinderProxy\.transact',
                r'Binder\.transact',
                r'IPCThreadState::transact',
                r'android\.os\.BinderProxy\.transactNative',
                r'android\.os\.Binder\.execTransact',
                r'oneway\s+transaction',
            ],
            'watchdog_patterns': [
                r'Watchdog.*detected.*deadlock',
                r'WATCHDOG.*TIMEOUT',
                r'system_server.*anr.*Trace\.txt',
                r'com\.android\.server\.Watchdog',
                r'watchdog.*kill.*system_server',
            ],
            'gc_patterns': [
                r'GC_FOR_ALLOC.*?freed.*?paused\s+(\d+)ms',
                r'GC_CONCURRENT.*?freed.*?paused\s+(\d+)ms\+(\d+)ms',
                r'GC_EXPLICIT.*?freed.*?paused\s+(\d+)ms',
                r'Clamp target GC heap',
                r'Alloc.*?concurrent.*?GC',
                r'Starting a blocking GC',
            ],
            'strictmode_patterns': [
                r'StrictMode.*?violation',
                r'DiskReadViolation',
                r'DiskWriteViolation',
                r'NetworkViolation',
                r'CustomSlowCallViolation',
                r'ResourceMismatchViolation',
            ],
        }
    
    @time_tracker("è§£æ ANR æª”æ¡ˆ")
    def analyze(self, file_path: str) -> str:
        """åˆ†æ ANR æª”æ¡ˆ"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            
            # è§£æ ANR è³‡è¨Š
            anr_info = self._parse_anr_info(content)
            
            # å‰µå»ºæ™ºèƒ½åˆ†æå¼•æ“
            intelligent_engine = IntelligentAnalysisEngine()
            
            # ç”Ÿæˆåˆ†æå ±å‘Š
            report = self._generate_report(anr_info, content, intelligent_engine)
            
            return report
            
        except Exception as e:
            return f"âŒ åˆ†æ ANR æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
    
    def _parse_anr_info(self, content: str) -> ANRInfo:
        """è§£æ ANR è³‡è¨Š"""
        lines = content.splitlines()
        
        # è­˜åˆ¥ ANR é¡å‹å’ŒåŸºæœ¬è³‡è¨Š
        anr_type = self._identify_anr_type(content)
        process_info = self._extract_process_info(content)
        
        # è§£ææ‰€æœ‰ç·šç¨‹è³‡è¨Š
        all_threads = self._extract_all_threads(lines, content)
        
        # æ‰¾å‡ºä¸»ç·šç¨‹
        main_thread = self._find_main_thread(all_threads)
        
        # è§£æé¡å¤–è³‡è¨Š
        cpu_usage = self._extract_cpu_usage(content)
        memory_info = self._extract_memory_info(content)
        
        # æ–°å¢ï¼šè§£æ ANR è¶…æ™‚æ™‚é–“
        timeout_info = self._extract_timeout_info(content)
        
        anr_info = ANRInfo(
            anr_type=anr_type,
            process_name=process_info.get('process_name', 'Unknown'),
            pid=process_info.get('pid', 'Unknown'),
            timestamp=process_info.get('timestamp'),
            reason=process_info.get('reason'),
            main_thread=main_thread,
            all_threads=all_threads,
            cpu_usage=cpu_usage,
            memory_info=memory_info
        )
        
        # æ–°å¢ï¼šå°‡è¶…æ™‚è³‡è¨ŠåŠ å…¥ ANRInfo
        anr_info.timeout_info = timeout_info
        
        return anr_info
    
    def _identify_anr_type(self, content: str) -> ANRType:
        """è­˜åˆ¥ ANR é¡å‹ - å¢å¼·ç‰ˆ"""
        type_mappings = {
            # åŸæœ‰çš„æ˜ å°„
            "Input dispatching timed out": ANRType.INPUT_DISPATCHING,
            "Input event dispatching timed out": ANRType.INPUT_DISPATCHING,
            "executing service": ANRType.SERVICE,
            "Broadcast of Intent": ANRType.BROADCAST,
            "BroadcastReceiver": ANRType.BROADCAST,
            "ContentProvider": ANRType.CONTENT_PROVIDER,
            "Activity": ANRType.ACTIVITY,
            "Foreground service": ANRType.FOREGROUND_SERVICE,
            # æ–°å¢çš„é¡å‹æª¢æ¸¬
            "JobScheduler": ANRType.SERVICE,
            "JobService": ANRType.SERVICE,
            "startForeground": ANRType.FOREGROUND_SERVICE,
        }
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Watchdog è¶…æ™‚
        if any(re.search(pattern, content) for pattern in self.patterns['watchdog_patterns']):
            # Watchdog é€šå¸¸æ˜¯ç³»çµ±æœå‹™å•é¡Œ
            return ANRType.SERVICE
        
        for pattern, anr_type in type_mappings.items():
            if pattern in content:
                return anr_type
        
        return ANRType.UNKNOWN
    
    def _extract_process_info(self, content: str) -> Dict:
        """æå–é€²ç¨‹è³‡è¨Š"""
        info = {}
        
        # å˜—è©¦å¤šç¨®æ¨¡å¼æå–é€²ç¨‹åç¨±å’Œ PID
        for pattern in self.patterns['anr_trigger_patterns']:
            match = re.search(pattern, content)
            if match:
                groups = match.groups()
                if len(groups) >= 1:
                    if 'Cmd line' in pattern:
                        info['process_name'] = groups[0]
                    elif 'ANR in' in pattern and len(groups) >= 2:
                        info['process_name'] = groups[0]
                        info['pid'] = groups[1]
                    elif len(groups) >= 2 and groups[0].isdigit():
                        info['timeout'] = groups[0]
                        info['reason'] = groups[1]
                    else:
                        info['process_name'] = groups[0]
                break
        
        # æå–æ™‚é–“æˆ³
        timestamp_match = re.search(r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+)', content)
        if timestamp_match:
            info['timestamp'] = timestamp_match.group(1)
        
        return info
    
    def _extract_timeout_info(self, content: str) -> Dict:
        """æå– ANR è¶…æ™‚è³‡è¨Š"""
        timeout_info = {
            'wait_time': None,
            'timeout_threshold': None,
            'is_foreground': True
        }
        
        # æå–ç­‰å¾…æ™‚é–“
        wait_match = re.search(r'Waited\s+(\d+)ms', content)
        if wait_match:
            timeout_info['wait_time'] = int(wait_match.group(1))
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºå‰å°/èƒŒæ™¯
        if 'background' in content.lower() or 'bg anr' in content.lower():
            timeout_info['is_foreground'] = False
        
        # æ ¹æ“š ANR é¡å‹è¨­å®šé–¾å€¼
        if 'Input' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.INPUT_DISPATCHING
        elif 'Service' in content:
            if timeout_info['is_foreground']:
                timeout_info['timeout_threshold'] = ANRTimeouts.SERVICE_TIMEOUT
            else:
                timeout_info['timeout_threshold'] = ANRTimeouts.SERVICE_BACKGROUND_TIMEOUT
        elif 'Broadcast' in content:
            if timeout_info['is_foreground']:
                timeout_info['timeout_threshold'] = ANRTimeouts.BROADCAST_TIMEOUT
            else:
                timeout_info['timeout_threshold'] = ANRTimeouts.BROADCAST_BACKGROUND_TIMEOUT
        elif 'JobScheduler' in content or 'JobService' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.JOB_SCHEDULER_TIMEOUT
        elif 'ContentProvider' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.CONTENT_PROVIDER_TIMEOUT
        
        return timeout_info
    
    def _extract_all_threads(self, lines: List[str], content: str) -> List[ThreadInfo]:
        """æå–æ‰€æœ‰ç·šç¨‹è³‡è¨Š - å¢å¼·ç‰ˆ"""
        threads = []
        
        for idx, line in enumerate(lines):
            thread_info = self._try_parse_thread(line, idx, lines)
            if thread_info:
                # æå–å †ç–Šè³‡è¨Š
                thread_info.backtrace = self._extract_backtrace(lines, idx)
                
                # æå–é–è³‡è¨Š
                self._extract_lock_info(thread_info, lines, idx)
                
                # æ–°å¢ï¼šæª¢æ¸¬è·¨é€²ç¨‹é–
                self._extract_cross_process_lock_info(thread_info, lines, idx)
                
                # æ–°å¢ï¼šæå–ç·šç¨‹ CPU æ™‚é–“
                self._extract_thread_cpu_time(thread_info, lines, idx)
                
                threads.append(thread_info)
        
        return threads
    
    def _try_parse_thread(self, line: str, idx: int, lines: List[str]) -> Optional[ThreadInfo]:
        """å˜—è©¦è§£æç·šç¨‹è³‡è¨Š"""
        for pattern in self.patterns['thread_patterns']:
            match = re.search(pattern, line)
            if match:
                groups = match.groups()
                
                # æ ¹æ“šä¸åŒæ¨¡å¼è§£æ
                if len(groups) == 4 and 'daemon' not in pattern:
                    name, prio, tid, state = groups
                    return ThreadInfo(
                        name=name,
                        tid=tid,
                        prio=prio,
                        state=self._parse_thread_state(state)
                    )
                elif len(groups) == 3:
                    name, tid, state = groups
                    return ThreadInfo(
                        name=name,
                        tid=tid,
                        state=self._parse_thread_state(state)
                    )
                
        return None
    
    def _parse_thread_state(self, state_str: str) -> ThreadState:
        """è§£æç·šç¨‹ç‹€æ…‹"""
        state_mappings = {
            'R': ThreadState.RUNNABLE,
            'S': ThreadState.SLEEPING,
            'D': ThreadState.WAIT,
            'T': ThreadState.SUSPENDED,
            'Z': ThreadState.ZOMBIE,
            'RUNNABLE': ThreadState.RUNNABLE,
            'TIMED_WAIT': ThreadState.TIMED_WAIT,
            'TIMED_WAITING': ThreadState.TIMED_WAIT,
            'WAIT': ThreadState.WAIT,
            'WAITING': ThreadState.WAIT,
            'BLOCKED': ThreadState.BLOCKED,
            'SUSPENDED': ThreadState.SUSPENDED,
            'NATIVE': ThreadState.NATIVE,
            'MONITOR': ThreadState.MONITOR,
            'SLEEPING': ThreadState.SLEEPING,
            'ZOMBIE': ThreadState.ZOMBIE,
        }
        
        return state_mappings.get(state_str.upper(), ThreadState.UNKNOWN)
    
    def _extract_backtrace(self, lines: List[str], start_idx: int) -> List[str]:
        """æå–å †ç–Šè¿½è¹¤"""
        backtrace = []
        
        for i in range(start_idx + 1, len(lines)):
            line = lines[i]
            
            # æª¢æ¸¬ä¸‹ä¸€å€‹ç·šç¨‹æˆ–çµæŸ
            if self._is_thread_start(line):
                break
            
            # æå–å †ç–Šè¡Œ
            if self._is_stack_frame(line):
                frame = self._clean_stack_frame(line)
                if frame:
                    backtrace.append(frame)
        
        return backtrace
    
    def _is_thread_start(self, line: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºç·šç¨‹é–‹å§‹"""
        return any(re.search(pattern, line) for pattern in self.patterns['thread_patterns'][:3])
    
    def _is_stack_frame(self, line: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºå †ç–Šæ¡†æ¶"""
        patterns = [
            r'^\s*at\s+',
            r'^\s*#\d+\s+',
            r'\([^)]+\.java:\d+\)',
            r'\([^)]+\.kt:\d+\)',
            r'^\s*-\s+(locked|waiting)',
            r'Native Method',
        ]
        return any(re.search(pattern, line) for pattern in patterns)
    
    def _clean_stack_frame(self, line: str) -> str:
        """æ¸…ç†å †ç–Šæ¡†æ¶"""
        # ç§»é™¤å‰ç¶´
        line = re.sub(r'^\s*at\s+', '', line)
        line = re.sub(r'^\s*#\d+\s+', '', line)
        return line.strip()
    
    def _extract_lock_info(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–é–è³‡è¨Š"""
        for i in range(start_idx + 1, min(start_idx + 20, len(lines))):
            line = lines[i]
            
            # æª¢æŸ¥æŒæœ‰çš„é–
            locked_match = re.search(r'- locked\s+<([^>]+)>', line)
            if locked_match:
                thread.held_locks.append(locked_match.group(1))
            
            # æª¢æŸ¥ç­‰å¾…çš„é–
            waiting_match = re.search(r'- waiting (?:on|to lock)\s+<([^>]+)>', line)
            if waiting_match:
                thread.waiting_locks.append(waiting_match.group(1))
                
                # æå–ç­‰å¾…è³‡è¨Š
                held_by_match = re.search(r'held by (?:thread\s+)?(\d+)', line)
                if held_by_match:
                    thread.waiting_info = f"ç­‰å¾…é– {waiting_match.group(1)}ï¼Œè¢«ç·šç¨‹ {held_by_match.group(1)} æŒæœ‰"
            
            # æª¢æŸ¥ parking ç‹€æ…‹
            if 'parking to wait for' in line:
                park_match = re.search(r'parking to wait for\s+<([^>]+)>', line)
                if park_match:
                    thread.waiting_info = f"Parking ç­‰å¾…: {park_match.group(1)}"
    
    def _extract_cross_process_lock_info(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–è·¨é€²ç¨‹é–è³‡è¨Š"""
        for i in range(start_idx + 1, min(start_idx + 20, len(lines))):
            line = lines[i]
            
            # æª¢æŸ¥è·¨é€²ç¨‹ç­‰å¾…
            cross_process_match = re.search(r'held by tid=(\d+) in process (\d+)', line)
            if cross_process_match:
                thread.waiting_info = f"ç­‰å¾…è·¨é€²ç¨‹é–ï¼Œè¢«é€²ç¨‹ {cross_process_match.group(2)} çš„ç·šç¨‹ {cross_process_match.group(1)} æŒæœ‰"
                break
    
    def _extract_thread_cpu_time(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–ç·šç¨‹ CPU æ™‚é–“"""
        # æŸ¥æ‰¾ schedstat è³‡è¨Š
        for i in range(start_idx, min(start_idx + 5, len(lines))):
            line = lines[i]
            
            # schedstat æ ¼å¼: schedstat=( é‹è¡Œæ™‚é–“ ç­‰å¾…æ™‚é–“ æ™‚é–“ç‰‡æ¬¡æ•¸ )
            schedstat_match = re.search(r'schedstat=\(\s*(\d+)\s+(\d+)\s+(\d+)\s*\)', line)
            if schedstat_match:
                thread.schedstat = f"é‹è¡Œ:{int(schedstat_match.group(1))/1000000:.1f}ms " \
                                  f"ç­‰å¾…:{int(schedstat_match.group(2))/1000000:.1f}ms"
            
            # utm/stm æ ¼å¼
            utm_match = re.search(r'utm=(\d+)', line)
            stm_match = re.search(r'stm=(\d+)', line)
            if utm_match:
                thread.utm = utm_match.group(1)
            if stm_match:
                thread.stm = stm_match.group(1)
    
    def _find_main_thread(self, threads: List[ThreadInfo]) -> Optional[ThreadInfo]:
        """æ‰¾å‡ºä¸»ç·šç¨‹"""
        # å„ªå…ˆæŸ¥æ‰¾åç‚º "main" çš„ç·šç¨‹
        for thread in threads:
            if thread.name.lower() == "main":
                return thread
        
        # æŸ¥æ‰¾ tid=1 çš„ç·šç¨‹
        for thread in threads:
            if thread.tid == "1":
                return thread
        
        # æŸ¥æ‰¾åŒ…å« ActivityThread çš„ç·šç¨‹
        for thread in threads:
            if any('ActivityThread' in frame for frame in thread.backtrace):
                return thread
        
        return None
    
    def _extract_cpu_usage(self, content: str) -> Optional[Dict]:
        """æå– CPU ä½¿ç”¨ç‡è³‡è¨Š"""
        cpu_info = {}
        
        # æŸ¥æ‰¾ CPU ä½¿ç”¨ç‡æ¨¡å¼
        cpu_patterns = [
            r'CPU:\s*([\d.]+)%\s*usr\s*\+\s*([\d.]+)%\s*sys',
            r'Load:\s*([\d.]+)\s*/\s*([\d.]+)\s*/\s*([\d.]+)',
            r'cpu\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)',
        ]
        
        for pattern in cpu_patterns:
            match = re.search(pattern, content)
            if match:
                if 'usr' in pattern:
                    cpu_info['user'] = float(match.group(1))
                    cpu_info['system'] = float(match.group(2))
                    cpu_info['total'] = cpu_info['user'] + cpu_info['system']
                elif 'Load' in pattern:
                    cpu_info['load_1min'] = float(match.group(1))
                    cpu_info['load_5min'] = float(match.group(2))
                    cpu_info['load_15min'] = float(match.group(3))
                break
        
        return cpu_info if cpu_info else None
    
    def _extract_memory_info(self, content: str) -> Optional[Dict]:
        """æå–è¨˜æ†¶é«”è³‡è¨Š"""
        memory_info = {}
        
        # æŸ¥æ‰¾è¨˜æ†¶é«”è³‡è¨Šæ¨¡å¼
        patterns = {
            'total': r'MemTotal:\s*(\d+)\s*kB',
            'free': r'MemFree:\s*(\d+)\s*kB',
            'available': r'MemAvailable:\s*(\d+)\s*kB',
            'buffers': r'Buffers:\s*(\d+)\s*kB',
            'cached': r'Cached:\s*(\d+)\s*kB',
            'swap_total': r'SwapTotal:\s*(\d+)\s*kB',
            'swap_free': r'SwapFree:\s*(\d+)\s*kB',
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                memory_info[key] = int(match.group(1))
        
        # è¨ˆç®—ä½¿ç”¨ç‡
        if 'total' in memory_info and 'available' in memory_info:
            used = memory_info['total'] - memory_info['available']
            memory_info['used_percent'] = (used / memory_info['total']) * 100
        
        return memory_info if memory_info else None
    
    def _generate_report(self, anr_info: ANRInfo, content: str, intelligent_engine) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        analyzer = ANRReportGenerator(anr_info, content, intelligent_engine)
        return analyzer.generate()

class ANRReportGenerator:
    """ANR å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, anr_info: ANRInfo, content: str, intelligent_engine=None):
        self.anr_info = anr_info
        self.content = content
        self.report_lines = []
        self.intelligent_engine = intelligent_engine or IntelligentAnalysisEngine()
    
    def generate(self) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        self._add_summary()
        self._add_basic_info()
        self._add_main_thread_analysis()
        self._add_root_cause_analysis()
        self._add_intelligent_analysis()
        self._add_thread_analysis()
        self._add_deadlock_detection()
        self._add_watchdog_analysis()      # æ–°å¢
        self._add_strictmode_analysis()    # æ–°å¢
        self._add_gc_analysis()            # æ–°å¢
        self._add_performance_analysis()
        self._add_system_health_score()    # æ–°å¢
        self._add_suggestions()
        
        return "\n".join(self.report_lines)

    def _add_performance_analysis(self):
        """æ·»åŠ æ€§èƒ½åˆ†æ"""
        self.report_lines.append("\nâš¡ æ€§èƒ½åˆ†æ")
        
        perf_issues = []
        
        # åˆå§‹åŒ–è®Šæ•¸
        available_mb = float('inf')  # é è¨­ç‚ºç„¡é™å¤§
        total_cpu = 0
        
        # 1. ç·šç¨‹æ•¸é‡åˆ†æ
        thread_count = len(self.anr_info.all_threads)
        if thread_count > 200:
            perf_issues.append(f"ç·šç¨‹æ•¸é‡éå¤š: {thread_count} å€‹ (å»ºè­°: < 100)")
            perf_issues.append("  å¯èƒ½åŸå› : ç·šç¨‹æ´©æ¼ã€éåº¦ä½¿ç”¨ç·šç¨‹æ± ")
        elif thread_count > 100:
            perf_issues.append(f"ç·šç¨‹æ•¸é‡è¼ƒå¤š: {thread_count} å€‹")
        
        # 2. èª¿ç”¨æ·±åº¦åˆ†æ
        if self.anr_info.main_thread and len(self.anr_info.main_thread.backtrace) > 50:
            depth = len(self.anr_info.main_thread.backtrace)
            perf_issues.append(f"ä¸»ç·šç¨‹èª¿ç”¨éˆéæ·±: {depth} å±¤")
            perf_issues.append("  å¯èƒ½åŸå› : éè¿´èª¿ç”¨ã€éåº¦çš„æ–¹æ³•åµŒå¥—")
        
        # 3. Binder ç·šç¨‹åˆ†æ
        binder_threads = [t for t in self.anr_info.all_threads if 'Binder' in t.name]
        if len(binder_threads) > 0:
            binder_busy = sum(1 for t in binder_threads if t.state != ThreadState.WAIT)
            if binder_busy == len(binder_threads):
                perf_issues.append(f"æ‰€æœ‰ Binder ç·šç¨‹éƒ½åœ¨å¿™ç¢Œ ({binder_busy}/{len(binder_threads)})")
                perf_issues.append("  å¯èƒ½å°è‡´ IPC è«‹æ±‚æ’éšŠ")
        
        # 4. é–ç«¶çˆ­åˆ†æ
        blocked_on_locks = sum(1 for t in self.anr_info.all_threads 
                              if t.state == ThreadState.BLOCKED or t.waiting_locks)
        if blocked_on_locks > 5:
            perf_issues.append(f"å¤§é‡ç·šç¨‹åœ¨ç­‰å¾…é–: {blocked_on_locks} å€‹")
            perf_issues.append("  å»ºè­°: å„ªåŒ–é–çš„ç²’åº¦ï¼Œä½¿ç”¨ç„¡é–æ•¸æ“šçµæ§‹")
        
        # 5. è¨˜æ†¶é«”å£“åŠ›å°æ€§èƒ½çš„å½±éŸ¿
        if self.anr_info.memory_info:
            available_mb = self.anr_info.memory_info.get('available', float('inf')) / 1024
            if available_mb < 100:
                perf_issues.append(f"ä½è¨˜æ†¶é«”å¯èƒ½å½±éŸ¿æ€§èƒ½: {available_mb:.1f} MB")
                perf_issues.append("  å½±éŸ¿: é »ç¹ GCã€é é¢äº¤æ›")
        
        # 6. CPU åˆ†æ
        if self.anr_info.cpu_usage:
            total_cpu = self.anr_info.cpu_usage.get('total', 0)
            if total_cpu > 80:
                perf_issues.append(f"CPU ä½¿ç”¨ç‡é«˜: {total_cpu:.1f}%")
                
                # åˆ†æ load average
                load_1 = self.anr_info.cpu_usage.get('load_1min', 0)
                if load_1 > 4.0:
                    perf_issues.append(f"  ç³»çµ±è² è¼‰éé«˜: {load_1}")
        
        # 7. GC å½±éŸ¿åˆ†æ
        gc_pause_pattern = r'paused\s+(\d+)ms'
        gc_pauses = re.findall(gc_pause_pattern, self.content)
        if gc_pauses:
            total_pause = sum(int(pause) for pause in gc_pauses)
            max_pause = max(int(pause) for pause in gc_pauses)
            if total_pause > 500:
                perf_issues.append(f"GC æš«åœæ™‚é–“éé•·: ç¸½è¨ˆ {total_pause}ms, æœ€å¤§ {max_pause}ms")
        
        # 8. ç·šç¨‹å„ªå…ˆç´šåˆ†æ
        high_prio_blocked = 0
        for thread in self.anr_info.all_threads:
            if thread.prio and thread.prio.isdigit() and int(thread.prio) <= 5:
                if thread.state == ThreadState.BLOCKED or thread.waiting_locks:
                    high_prio_blocked += 1
        
        if high_prio_blocked > 0:
            perf_issues.append(f"é«˜å„ªå…ˆç´šç·šç¨‹è¢«é˜»å¡: {high_prio_blocked} å€‹")
            perf_issues.append("  å¯èƒ½å­˜åœ¨å„ªå…ˆç´šåè½‰å•é¡Œ")
        
        # é¡¯ç¤ºçµæœ
        if perf_issues:
            self.report_lines.extend(f"  â€¢ {issue}" for issue in perf_issues)
        else:
            self.report_lines.append("  âœ… æœªç™¼ç¾æ˜é¡¯æ€§èƒ½å•é¡Œ")
        
        # æ€§èƒ½è©•åˆ†
        perf_score = 100
        perf_score -= min(thread_count // 50, 20)  # ç·šç¨‹æ•¸æ‰£åˆ†
        perf_score -= min(blocked_on_locks * 2, 20)  # é–ç«¶çˆ­æ‰£åˆ†
        if available_mb < 100:
            perf_score -= 20  # è¨˜æ†¶é«”æ‰£åˆ†
        if total_cpu > 90:
            perf_score -= 20  # CPU æ‰£åˆ†
        
        perf_score = max(perf_score, 0)
        
        self.report_lines.append(f"\n  æ€§èƒ½è©•åˆ†: {perf_score}/100")
        if perf_score < 60:
            self.report_lines.append("  âš ï¸ æ€§èƒ½å•é¡Œéœ€è¦ç«‹å³è™•ç†")
    
    def _add_suggestions(self):
        """æ·»åŠ è§£æ±ºå»ºè­°"""
        self.report_lines.append("\nğŸ’¡ è§£æ±ºå»ºè­°")
        
        suggestions = self._generate_suggestions()
        
        # ç«‹å³è¡Œå‹•é …
        if suggestions['immediate']:
            self.report_lines.append("\nğŸš¨ ç«‹å³è¡Œå‹•:")
            for i, suggestion in enumerate(suggestions['immediate'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # å„ªåŒ–å»ºè­°
        if suggestions['optimization']:
            self.report_lines.append("\nğŸ”§ å„ªåŒ–å»ºè­°:")
            for i, suggestion in enumerate(suggestions['optimization'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # èª¿æŸ¥æ–¹å‘
        if suggestions['investigation']:
            self.report_lines.append("\nğŸ” èª¿æŸ¥æ–¹å‘:")
            for i, suggestion in enumerate(suggestions['investigation'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # é é˜²æªæ–½
        self.report_lines.append("\nğŸ›¡ï¸ é é˜²æªæ–½:")
        prevention_suggestions = [
            "å®šæœŸä½¿ç”¨ Android Studio Profiler ç›£æ§æ‡‰ç”¨æ€§èƒ½",
            "åœ¨é–‹ç™¼éšæ®µå•Ÿç”¨ StrictMode æª¢æ¸¬é•è¦æ“ä½œ",
            "å¯¦æ–½ CI/CD ä¸­çš„æ€§èƒ½æ¸¬è©¦",
            "ç›£æ§ç”Ÿç”¢ç’°å¢ƒçš„ ANR ç‡ (ç›®æ¨™ < 0.47%)",
            "å»ºç«‹ ANR é è­¦æ©Ÿåˆ¶å’Œè‡ªå‹•åŒ–åˆ†æ",
        ]
        
        for i, suggestion in enumerate(prevention_suggestions, 1):
            self.report_lines.append(f"  {i}. {suggestion}")
        
        # å·¥å…·æ¨è–¦
        self.report_lines.append("\nğŸ”¨ æ¨è–¦å·¥å…·:")
        tools = [
            "Systrace - ç³»çµ±ç´šæ€§èƒ½åˆ†æ",
            "Method Tracing - æ–¹æ³•ç´šæ€§èƒ½åˆ†æ",
            "Android Studio Profiler - CPUã€è¨˜æ†¶é«”ã€ç¶²è·¯åˆ†æ",
            "Firebase Performance Monitoring - ç”Ÿç”¢ç’°å¢ƒç›£æ§",
            "Perfetto - æ–°ä¸€ä»£è¿½è¹¤å·¥å…·",
        ]
        
        for tool in tools:
            self.report_lines.append(f"  â€¢ {tool}")
        
        # ç›¸é—œæ–‡æª”
        self.report_lines.append("\nğŸ“š ç›¸é—œæ–‡æª”:")
        docs = [
            "Android å®˜æ–¹ ANR æ–‡æª”: https://developer.android.com/topic/performance/vitals/anr",
            "Thread å’Œ Process æŒ‡å—: https://developer.android.com/guide/components/processes-and-threads",
            "æ€§èƒ½å„ªåŒ–æœ€ä½³å¯¦è¸: https://developer.android.com/topic/performance/",
        ]
        
        for doc in docs:
            self.report_lines.append(f"  â€¢ {doc}")

    def _add_summary(self):
        """æ·»åŠ æ‘˜è¦"""
        self.report_lines.extend([
            "ğŸ¯ ANR åˆ†æå ±å‘Š",
            "=" * 60,
            f"ğŸ“Š ANR é¡å‹: {self.anr_info.anr_type.value}",
            f"ğŸ“± é€²ç¨‹åç¨±: {self.anr_info.process_name}",
            f"ğŸ†” é€²ç¨‹ ID: {self.anr_info.pid}",
        ])
        
        if self.anr_info.timestamp:
            self.report_lines.append(f"ğŸ• ç™¼ç”Ÿæ™‚é–“: {self.anr_info.timestamp}")
        
        # é¡¯ç¤ºè¶…æ™‚è³‡è¨Š
        if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info:
            timeout_info = self.anr_info.timeout_info
            if timeout_info.get('wait_time'):
                self.report_lines.append(
                    f"â±ï¸ ç­‰å¾…æ™‚é–“: {timeout_info['wait_time']}ms "
                    f"(é–¾å€¼: {timeout_info.get('timeout_threshold', 'N/A')}ms)"
                )
        
        # å¿«é€Ÿåˆ¤æ–·åš´é‡ç¨‹åº¦
        severity = self._assess_severity()
        self.report_lines.append(f"ğŸš¨ åš´é‡ç¨‹åº¦: {severity}")
        
        # æ ¹æœ¬åŸå› å¿«é€Ÿå®šä½
        root_cause = self._quick_root_cause()
        self.report_lines.append(f"ğŸ¯ å¯èƒ½åŸå› : {root_cause}")
        
        self.report_lines.extend(["", "=" * 60, ""])
        
    def _assess_severity(self) -> str:
        """è©•ä¼°åš´é‡ç¨‹åº¦"""
        score = 0
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            score += 5
        
        # æª¢æŸ¥ç³»çµ±æœå‹™
        if "system_server" in self.anr_info.process_name:
            score += 3
        elif any(svc in self.anr_info.process_name for svc in 
                ['launcher', 'systemui', 'phone', 'bluetooth']):
            score += 2
        
        # æª¢æŸ¥é˜»å¡ç·šç¨‹æ•¸é‡
        blocked_count = sum(1 for t in self.anr_info.all_threads if t.state == ThreadState.BLOCKED)
        score += min(blocked_count // 3, 3)
        
        # æª¢æŸ¥ CPU ä½¿ç”¨ç‡
        if self.anr_info.cpu_usage and self.anr_info.cpu_usage.get('total', 0) > 90:
            score += 2
        
        # æª¢æŸ¥è¨˜æ†¶é«”å£“åŠ›
        if self.anr_info.memory_info:
            available = self.anr_info.memory_info.get('available', float('inf'))
            if available < 50 * 1024:  # å°æ–¼ 50MB
                score += 3
            elif available < 100 * 1024:  # å°æ–¼ 100MB
                score += 2
        
        # æª¢æŸ¥ä¸»ç·šç¨‹ç‹€æ…‹
        if self.anr_info.main_thread:
            if self.anr_info.main_thread.state == ThreadState.BLOCKED:
                score += 2
            elif self.anr_info.main_thread.waiting_locks:
                score += 1
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Watchdog
        if any(re.search(pattern, self.content) for pattern in 
               ['Watchdog', 'WATCHDOG', 'watchdog']):
            score += 3
        
        # è¿”å›è©•ç´š
        if score >= 8:
            return "ğŸ”´ æ¥µå…¶åš´é‡ (ç³»çµ±ç´šå•é¡Œ/æ­»é–)"
        elif score >= 5:
            return "ğŸŸ  åš´é‡ (å¤šç·šç¨‹é˜»å¡/ç³»çµ±æœå‹™å•é¡Œ)"
        elif score >= 3:
            return "ğŸŸ¡ ä¸­ç­‰ (éœ€è¦ç«‹å³è™•ç†)"
        else:
            return "ğŸŸ¢ è¼•å¾® (æ‡‰ç”¨å±¤å•é¡Œ)"
    
    def _quick_root_cause(self) -> str:
        """å¿«é€Ÿå®šä½æ ¹æœ¬åŸå› """
        causes = []
        
        if self.anr_info.main_thread:
            # æª¢æŸ¥ä¸»ç·šç¨‹å †ç–Šå‰5å¹€
            for i, frame in enumerate(self.anr_info.main_thread.backtrace[:5]):
                frame_lower = frame.lower()
                
                # Binder IPC
                if any(keyword in frame for keyword in ['BinderProxy', 'Binder.transact']):
                    service = self._identify_binder_service(self.anr_info.main_thread.backtrace[i:i+5])
                    if service:
                        causes.append(f"Binder IPC é˜»å¡ ({service})")
                    else:
                        causes.append("Binder IPC é˜»å¡")
                    break
                    
                # åŒæ­¥é–
                elif any(keyword in frame_lower for keyword in ['synchronized', 'lock', 'monitor']):
                    causes.append("åŒæ­¥é–ç­‰å¾…")
                    break
                    
                # ç¶²è·¯æ“ä½œ
                elif any(keyword in frame for keyword in ['Socket', 'Http', 'Network', 'URL']):
                    causes.append("ç¶²è·¯æ“ä½œé˜»å¡")
                    break
                    
                # I/O æ“ä½œ
                elif any(keyword in frame for keyword in ['File', 'read', 'write', 'SQLite']):
                    causes.append("I/O æ“ä½œé˜»å¡")
                    break
                    
                # ä¼‘çœ 
                elif 'sleep' in frame_lower:
                    causes.append("ä¸»ç·šç¨‹ä¼‘çœ ")
                    break
                    
                # SharedPreferences
                elif 'SharedPreferences' in frame and 'commit' in frame:
                    causes.append("SharedPreferences.commit() é˜»å¡")
                    break
                    
                # ContentProvider
                elif 'ContentResolver' in frame or 'ContentProvider' in frame:
                    causes.append("ContentProvider æ“ä½œé˜»å¡")
                    break
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            causes.append("å¯èƒ½å­˜åœ¨æ­»é–")
        
        # æª¢æŸ¥ CPU
        if self.anr_info.cpu_usage and self.anr_info.cpu_usage.get('total', 0) > 90:
            causes.append("CPU ä½¿ç”¨ç‡éé«˜")
        
        # æª¢æŸ¥è¨˜æ†¶é«”
        if self.anr_info.memory_info:
            available = self.anr_info.memory_info.get('available', float('inf'))
            if available < 100 * 1024:
                causes.append("è¨˜æ†¶é«”åš´é‡ä¸è¶³")
        
        # æª¢æŸ¥ç·šç¨‹æ•¸
        if len(self.anr_info.all_threads) > 150:
            causes.append("ç·šç¨‹æ•¸éå¤š")
        
        # åŸºæ–¼ ANR é¡å‹
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            if not causes:
                causes.append("ä¸»ç·šç¨‹ç„¡éŸ¿æ‡‰")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            if not causes:
                causes.append("Service ç”Ÿå‘½é€±æœŸæ–¹æ³•è¶…æ™‚")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            if not causes:
                causes.append("BroadcastReceiver.onReceive è¶…æ™‚")
        
        return " / ".join(causes) if causes else "éœ€é€²ä¸€æ­¥åˆ†æ"
    
    def _has_deadlock(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰æ­»é–"""
        # ç°¡å–®çš„æ­»é–æª¢æ¸¬ï¼šæª¢æŸ¥å¾ªç’°ç­‰å¾…
        waiting_graph = {}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æª¢æŸ¥å¾ªç’°
        visited = set()
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    return True  # ç™¼ç¾å¾ªç’°
                if current in visited:
                    break
                path.append(current)
            
            visited.update(path)
        
        return False
    
    def _add_basic_info(self):
        """æ·»åŠ åŸºæœ¬è³‡è¨Š"""
        self.report_lines.append("ğŸ“‹ è©³ç´°åˆ†æ")
        
        if self.anr_info.reason:
            self.report_lines.append(f"\nâš¡ è§¸ç™¼åŸå› : {self.anr_info.reason}")
        
        # æ·»åŠ è¶…æ™‚è©³æƒ…
        if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info:
            timeout_info = self.anr_info.timeout_info
            if timeout_info.get('wait_time') and timeout_info.get('timeout_threshold'):
                ratio = timeout_info['wait_time'] / timeout_info['timeout_threshold']
                self.report_lines.append(
                    f"â±ï¸ è¶…æ™‚è©³æƒ…: ç­‰å¾…äº† {timeout_info['wait_time']}ms "
                    f"(è¶…éé–¾å€¼ {ratio:.1f} å€)"
                )
        
        # æ·»åŠ é€²ç¨‹è©³æƒ…
        self.report_lines.append(f"\nğŸ“± é€²ç¨‹è©³æƒ…:")
        self.report_lines.append(f"  â€¢ é€²ç¨‹å: {self.anr_info.process_name}")
        self.report_lines.append(f"  â€¢ PID: {self.anr_info.pid}")
        if self.anr_info.timestamp:
            self.report_lines.append(f"  â€¢ æ™‚é–“: {self.anr_info.timestamp}")
    
    def _add_main_thread_analysis(self):
        """æ·»åŠ ä¸»ç·šç¨‹åˆ†æ"""
        self.report_lines.append("\nğŸ” ä¸»ç·šç¨‹åˆ†æ")
        
        if not self.anr_info.main_thread:
            self.report_lines.append("âŒ æœªæ‰¾åˆ°ä¸»ç·šç¨‹è³‡è¨Š")
            return
        
        main = self.anr_info.main_thread
        self.report_lines.extend([
            f"ğŸ§µ ç·šç¨‹åç¨±: {main.name}",
            f"ğŸ”¢ ç·šç¨‹ ID: {main.tid}",
            f"ğŸ“Š ç·šç¨‹ç‹€æ…‹: {main.state.value}",
            f"ğŸ¯ å„ªå…ˆç´š: {main.prio}",
        ])
        
        # åˆ†æç·šç¨‹ç‹€æ…‹
        state_analysis = self._analyze_thread_state(main.state)
        self.report_lines.append(f"ğŸ’¡ ç‹€æ…‹åˆ†æ: {state_analysis}")
        
        # åˆ†æå †ç–Š
        if main.backtrace:
            # æ·±åº¦åˆ†æå †ç–Š
            stack_analysis = self._deep_analyze_stack(main.backtrace)
            
            self.report_lines.append(f"\nğŸ“š å †ç–Šåˆ†æ (å…± {len(main.backtrace)} å±¤):")
            
            # é¡¯ç¤ºåˆ†æçµæœ
            if stack_analysis['root_cause']:
                self.report_lines.append(f"  ğŸ¯ æ ¹æœ¬åŸå› : {stack_analysis['root_cause']}")
            
            if stack_analysis['blocking_operation']:
                self.report_lines.append(f"  â° é˜»å¡æ“ä½œ: {stack_analysis['blocking_operation']}")
            
            if stack_analysis['target_service']:
                self.report_lines.append(f"  ğŸ”— ç›®æ¨™æœå‹™: {stack_analysis['target_service']}")
            
            if stack_analysis['key_findings']:
                for finding in stack_analysis['key_findings']:
                    self.report_lines.append(f"  â€¢ {finding}")
            
            # é¡¯ç¤ºå¸¶å„ªå…ˆç´šæ¨™è¨˜çš„å †ç–Š
            self.report_lines.append("\nğŸ” é—œéµå †ç–Š (æ¨™è¨˜é‡è¦å¹€):")
            
            # åˆ†ææ¯ä¸€å¹€çš„é‡è¦æ€§
            frame_importances = self._analyze_frame_importance(main.backtrace)
            
            for i, (frame, importance) in enumerate(zip(main.backtrace[:20], frame_importances[:20])):
                priority_marker = importance['marker']
                explanation = importance['explanation']
                
                # æ ¹æ“šé‡è¦æ€§é¡¯ç¤ºä¸åŒé¡è‰²çš„æ¨™è¨˜
                if importance['level'] == 'critical':
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
                    if explanation:
                        self.report_lines.append(f"        â””â”€ {explanation}")
                elif importance['level'] == 'important':
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
                    if explanation:
                        self.report_lines.append(f"        â””â”€ {explanation}")
                elif importance['level'] == 'normal' and i < 10:  # åªé¡¯ç¤ºå‰10å€‹æ™®é€šå¹€
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
        
        # é¡¯ç¤ºé–è³‡è¨Š
        if main.held_locks:
            self.report_lines.append(f"\nğŸ”’ æŒæœ‰çš„é–: {', '.join(main.held_locks)}")
        
        if main.waiting_locks:
            self.report_lines.append(f"â° ç­‰å¾…çš„é–: {', '.join(main.waiting_locks)}")
        
        if main.waiting_info:
            self.report_lines.append(f"â³ ç­‰å¾…è³‡è¨Š: {main.waiting_info}")
    
    def _analyze_thread_state(self, state: ThreadState) -> str:
        """åˆ†æç·šç¨‹ç‹€æ…‹"""
        analyses = {
            ThreadState.BLOCKED: "ç·šç¨‹è¢«åŒæ­¥é–é˜»å¡ âš ï¸ [å¯èƒ½æ˜¯ ANR ä¸»å› ]",
            ThreadState.WAIT: "ç·šç¨‹åœ¨ç­‰å¾…æ¢ä»¶ â° [éœ€æª¢æŸ¥ç­‰å¾…åŸå› ]",
            ThreadState.TIMED_WAIT: "ç·šç¨‹åœ¨å®šæ™‚ç­‰å¾… â° [æª¢æŸ¥ç­‰å¾…æ™‚é•·]",
            ThreadState.SUSPENDED: "ç·šç¨‹è¢«æš«åœ âš ï¸ [ç•°å¸¸ç‹€æ…‹]",
            ThreadState.RUNNABLE: "ç·šç¨‹å¯é‹è¡Œ âœ… [æ­£å¸¸ç‹€æ…‹ï¼Œä½†å¯èƒ½åœ¨åŸ·è¡Œè€—æ™‚æ“ä½œ]",
            ThreadState.NATIVE: "åŸ·è¡ŒåŸç”Ÿä»£ç¢¼ ğŸ“± [æª¢æŸ¥ JNI èª¿ç”¨]",
            ThreadState.SLEEPING: "ç·šç¨‹ä¼‘çœ  ğŸ˜´ [ä¸æ‡‰åœ¨ä¸»ç·šç¨‹]",
        }
        
        return analyses.get(state, "æœªçŸ¥ç‹€æ…‹")
    
    def _deep_analyze_stack(self, backtrace: List[str]) -> Dict:
        """æ·±åº¦åˆ†æå †ç–Š"""
        analysis = {
            'root_cause': None,
            'blocking_operation': None,
            'target_service': None,
            'key_findings': []
        }
        
        if not backtrace:
            return analysis
        
        # åˆ†æå‰10å¹€æ‰¾å‡ºé—œéµå•é¡Œ
        for i, frame in enumerate(backtrace[:10]):
            frame_lower = frame.lower()
            
            # Binder IPC åˆ†æ
            if any(keyword in frame for keyword in ['BinderProxy.transact', 'Binder.transact', 'IPCThreadState::transact']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "Binder IPC èª¿ç”¨é˜»å¡"
                
                # å˜—è©¦è­˜åˆ¥ç›®æ¨™æœå‹™
                service = self._identify_binder_service(backtrace[i:i+5])
                if service:
                    analysis['target_service'] = service
                    
                # è­˜åˆ¥å…·é«”çš„ Binder æ–¹æ³•
                method = self._identify_binder_method(backtrace[i:i+5])
                if method:
                    analysis['blocking_operation'] = f"Binder æ–¹æ³•: {method}"
                else:
                    analysis['blocking_operation'] = "Binder IPC èª¿ç”¨"
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° Binder IPC èª¿ç”¨")
            
            # åŒæ­¥é–åˆ†æ
            elif 'synchronized' in frame_lower or any(lock in frame_lower for lock in ['lock', 'monitor', 'mutex']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "åŒæ­¥é–ç­‰å¾…"
                
                lock_type = self._identify_lock_type([frame])
                if lock_type:
                    analysis['blocking_operation'] = lock_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°é–æ“ä½œ")
            
            # I/O æ“ä½œåˆ†æ
            elif any(io_op in frame for io_op in ['FileInputStream', 'FileOutputStream', 'RandomAccessFile', 'read', 'write']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "I/O æ“ä½œé˜»å¡"
                    
                io_type = self._identify_io_type([frame])
                if io_type:
                    analysis['blocking_operation'] = io_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° I/O æ“ä½œ")
            
            # è³‡æ–™åº«æ“ä½œ
            elif any(db in frame for db in ['SQLite', 'database', 'Cursor', 'ContentProvider']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "è³‡æ–™åº«æ“ä½œé˜»å¡"
                    
                analysis['blocking_operation'] = "è³‡æ–™åº«æ“ä½œ"
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°è³‡æ–™åº«æ“ä½œ")
            
            # ç¶²è·¯æ“ä½œ
            elif any(net in frame for net in ['Socket', 'HttpURLConnection', 'URLConnection', 'OkHttp']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "ç¶²è·¯è«‹æ±‚é˜»å¡"
                    
                network_type = self._identify_network_type([frame])
                if network_type:
                    analysis['blocking_operation'] = network_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°ç¶²è·¯æ“ä½œ")
            
            # UI æ¸²æŸ“
            elif any(ui in frame for ui in ['onDraw', 'onMeasure', 'onLayout', 'inflate', 'measure']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "UI æ¸²æŸ“é˜»å¡"
                    
                ui_operation = self._identify_ui_operation([frame])
                if ui_operation:
                    analysis['blocking_operation'] = ui_operation
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° UI æ“ä½œ")
            
            # ä¼‘çœ æ“ä½œ
            elif 'sleep' in frame_lower:
                analysis['root_cause'] = "ä¸»ç·šç¨‹ä¼‘çœ  (åš´é‡å•é¡Œ)"
                analysis['blocking_operation'] = "Thread.sleep()"
                analysis['key_findings'].append(f"âš ï¸ åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° sleep æ“ä½œ")
            
            # Native æ–¹æ³•
            elif 'native' in frame_lower or 'Native Method' in frame:
                if i < 3:  # åªæœ‰åœ¨é ‚å±¤å¹¾å¹€æ‰èªç‚ºæ˜¯ Native é˜»å¡
                    if not analysis['root_cause']:
                        analysis['root_cause'] = "Native æ–¹æ³•é˜»å¡"
                    analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤é€²å…¥ Native æ–¹æ³•")
        
        # æª¢æŸ¥ç‰¹æ®Šæ¨¡å¼
        if len(backtrace) > 50:
            analysis['key_findings'].append(f"èª¿ç”¨éˆéæ·± ({len(backtrace)} å±¤)ï¼Œå¯èƒ½æœ‰éè¿´")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Handler/Looper æ¨¡å¼
        if any('Handler' in frame or 'Looper' in frame for frame in backtrace[:5]):
            analysis['key_findings'].append("æ¶‰åŠ Handler/Looper æ¶ˆæ¯è™•ç†")
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºåŸå› ï¼Œé€²è¡Œæ›´æ·±å…¥åˆ†æ
        if not analysis['root_cause']:
            if any('wait' in frame.lower() or 'park' in frame.lower() for frame in backtrace[:5]):
                analysis['root_cause'] = "ç·šç¨‹ç­‰å¾…"
                analysis['blocking_operation'] = "ç­‰å¾…æ¢ä»¶æˆ–äº‹ä»¶"
            else:
                analysis['root_cause'] = "æœªçŸ¥é˜»å¡åŸå› "
        
        return analysis
    
    def _analyze_frame_importance(self, backtrace: List[str]) -> List[Dict]:
        """åˆ†ææ¯ä¸€å¹€çš„é‡è¦æ€§"""
        importances = []
        
        for i, frame in enumerate(backtrace):
            importance = {
                'level': 'normal',
                'marker': 'âšª',
                'explanation': None
            }
            
            frame_lower = frame.lower()
            
            # æœ€é«˜å„ªå…ˆç´š - ç´…è‰²æ¨™è¨˜
            if any(critical in frame for critical in [
                'BinderProxy.transact', 'Binder.transact', 'IPCThreadState::transact'
            ]):
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'Binder IPC èª¿ç”¨é˜»å¡'
            
            elif 'sleep' in frame_lower:
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'ä¸»ç·šç¨‹ä¼‘çœ  - åš´é‡å•é¡Œï¼'
            
            elif 'synchronized' in frame_lower or 'lock' in frame_lower:
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'åŒæ­¥é–ç­‰å¾…'
            
            elif any(io in frame for io in ['Socket', 'Http', 'URLConnection']):
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'ç¶²è·¯æ“ä½œåœ¨ä¸»ç·šç¨‹'
            
            # ä¸­ç­‰å„ªå…ˆç´š - é»ƒè‰²æ¨™è¨˜
            elif any(io in frame for io in ['FileInputStream', 'FileOutputStream', 'read', 'write']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'I/O æ“ä½œ'
            
            elif any(db in frame for db in ['SQLite', 'database', 'Cursor']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'è³‡æ–™åº«æ“ä½œ'
            
            elif any(ui in frame for ui in ['onDraw', 'onMeasure', 'onLayout']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'UI æ¸²æŸ“æ“ä½œ'
            
            elif 'wait' in frame_lower or 'park' in frame_lower:
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'ç­‰å¾…æ“ä½œ'
            
            elif i == 0:  # ç¬¬ä¸€å¹€ç¸½æ˜¯é‡è¦çš„
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'é ‚å±¤èª¿ç”¨'
            
            # Native æ–¹æ³•
            elif 'native' in frame_lower or 'Native Method' in frame:
                if i < 3:
                    importance['level'] = 'important'
                    importance['marker'] = 'ğŸŸ¡'
                    importance['explanation'] = 'Native æ–¹æ³•'
                else:
                    importance['marker'] = 'âšª'
            
            importances.append(importance)
        
        return importances
    
    def _identify_binder_method(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ Binder æ–¹æ³•"""
        # æŸ¥æ‰¾å…·é«”çš„æ–¹æ³•èª¿ç”¨
        for frame in frames:
            # åŒ¹é…æ¨™æº– Java æ–¹æ³•æ ¼å¼
            match = re.search(r'\.(\w+)\([^)]*\)', frame)
            if match:
                method = match.group(1)
                # éæ¿¾æ‰ä¸€äº›é€šç”¨æ–¹æ³•
                if method not in ['transact', 'onTransact', 'execTransact', 'invoke']:
                    return method
        
        return None
    
    def _identify_lock_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥é–é¡å‹"""
        for frame in frames:
            if 'synchronized' in frame:
                # å˜—è©¦æå–åŒæ­¥çš„å°è±¡
                match = re.search(r'synchronized\s*\(([^)]+)\)', frame)
                if match:
                    return f"synchronized ({match.group(1)})"
                return "synchronized åŒæ­¥é–"
            elif 'ReentrantLock' in frame:
                return "ReentrantLock å¯é‡å…¥é–"
            elif 'ReadWriteLock' in frame:
                return "ReadWriteLock è®€å¯«é–"
            elif 'Semaphore' in frame:
                return "Semaphore ä¿¡è™Ÿé‡"
            elif 'CountDownLatch' in frame:
                return "CountDownLatch å€’è¨ˆæ™‚é–"
            elif 'CyclicBarrier' in frame:
                return "CyclicBarrier å¾ªç’°å±éšœ"
            elif 'monitor' in frame.lower():
                return "Monitor ç›£è¦–å™¨é–"
        
        return "æœªçŸ¥é¡å‹çš„é–"
    
    def _identify_io_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ I/O é¡å‹"""
        for frame in frames:
            if 'FileInputStream' in frame or 'FileReader' in frame:
                return "æ–‡ä»¶è®€å–"
            elif 'FileOutputStream' in frame or 'FileWriter' in frame:
                return "æ–‡ä»¶å¯«å…¥"
            elif 'RandomAccessFile' in frame:
                return "éš¨æ©Ÿæ–‡ä»¶è¨ªå•"
            elif 'BufferedReader' in frame or 'BufferedWriter' in frame:
                return "ç·©è¡ I/O"
            elif 'SharedPreferences' in frame:
                return "SharedPreferences è®€å¯«"
            elif 'SQLite' in frame or 'database' in frame:
                return "è³‡æ–™åº« I/O"
            elif 'ContentResolver' in frame:
                return "ContentProvider è¨ªå•"
            elif 'AssetManager' in frame:
                return "Asset è³‡æºè®€å–"
        
        return "æ–‡ä»¶ I/O"
    
    def _identify_network_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ç¶²è·¯é¡å‹"""
        for frame in frames:
            if 'HttpURLConnection' in frame:
                return "HttpURLConnection è«‹æ±‚"
            elif 'Socket' in frame:
                return "Socket é€£æ¥"
            elif 'OkHttp' in frame:
                return "OkHttp è«‹æ±‚"
            elif 'Volley' in frame:
                return "Volley ç¶²è·¯è«‹æ±‚"
            elif 'Retrofit' in frame:
                return "Retrofit API èª¿ç”¨"
            elif 'AsyncHttpClient' in frame:
                return "AsyncHttpClient è«‹æ±‚"
            elif 'HttpClient' in frame:
                return "HttpClient è«‹æ±‚"
        
        return "ç¶²è·¯è«‹æ±‚"
    
    def _identify_ui_operation(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ UI æ“ä½œ"""
        for frame in frames:
            if 'inflate' in frame:
                return "View å¸ƒå±€å¡«å……"
            elif 'onMeasure' in frame:
                return "View æ¸¬é‡"
            elif 'onDraw' in frame:
                return "View ç¹ªè£½"
            elif 'onLayout' in frame:
                return "View å¸ƒå±€"
            elif 'measure(' in frame:
                return "æ¸¬é‡æ“ä½œ"
            elif 'layout(' in frame:
                return "å¸ƒå±€æ“ä½œ"
            elif 'draw(' in frame:
                return "ç¹ªè£½æ“ä½œ"
            elif 'RecyclerView' in frame:
                return "RecyclerView æ“ä½œ"
            elif 'ListView' in frame:
                return "ListView æ“ä½œ"
            elif 'TextView' in frame and 'setText' in frame:
                return "TextView æ›´æ–°"
        
        return "UI æ“ä½œ"
    
    def _add_root_cause_analysis(self):
        """æ·»åŠ æ ¹æœ¬åŸå› åˆ†æ"""
        self.report_lines.append("\nğŸ¯ æ ¹æœ¬åŸå› åˆ†æ")
        
        # Binder åˆ†æ
        binder_issues = self._analyze_binder_issues()
        if binder_issues:
            self.report_lines.append("\nğŸ”— Binder IPC å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in binder_issues)
        
        # é–åˆ†æ
        lock_issues = self._analyze_lock_issues()
        if lock_issues:
            self.report_lines.append("\nğŸ”’ é–ç«¶çˆ­å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in lock_issues)
        
        # I/O åˆ†æ
        io_issues = self._analyze_io_issues()
        if io_issues:
            self.report_lines.append("\nğŸ’¾ I/O å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in io_issues)
        
        # ç³»çµ±è³‡æºåˆ†æ
        resource_issues = self._analyze_resource_issues()
        if resource_issues:
            self.report_lines.append("\nğŸ–¥ï¸ ç³»çµ±è³‡æºå•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in resource_issues)
        
        self._add_intelligent_analysis()  # æ–°å¢é€™è¡Œ
 
    def _add_intelligent_analysis(self):
        """æ·»åŠ æ™ºèƒ½åˆ†æ - å•é¡Œä¾†é¾å»è„ˆ"""
        self.report_lines.append("\nğŸ§  æ™ºèƒ½åˆ†æ - å•é¡Œä¾†é¾å»è„ˆ")
        
        # åˆ†æèª¿ç”¨éˆ
        if self.anr_info.main_thread:
            call_chain = self.intelligent_engine.analyze_call_chain(
                self.anr_info.main_thread.backtrace
            )
            
            # é¡¯ç¤ºèª¿ç”¨æµç¨‹
            if call_chain['call_flow']:
                self.report_lines.append("\nğŸ“Š èª¿ç”¨æµç¨‹åˆ†æ:")
                for i, flow in enumerate(call_chain['call_flow']):
                    indent = "  " * (i + 1)
                    marker = "â†’" if i < len(call_chain['call_flow']) - 1 else "âœ˜"
                    self.report_lines.append(
                        f"{indent}{marker} {flow['type']}: {flow['detail']}"
                    )
                    if 'target' in flow:
                        self.report_lines.append(f"{indent}  ç›®æ¨™: {flow['target']}")
                    if 'method' in flow:
                        self.report_lines.append(f"{indent}  æ–¹æ³•: {flow['method']}")
            
            # é¡¯ç¤ºé˜»å¡é»
            if call_chain['blocking_points']:
                self.report_lines.append("\nğŸš« è­˜åˆ¥çš„é˜»å¡é»:")
                for point in call_chain['blocking_points']:
                    self.report_lines.append(
                        f"  â€¢ ç¬¬ {point['level']} å±¤: {point['description']} "
                        f"[{point['type']}]"
                    )
            
            # é¡¯ç¤ºæœå‹™äº¤äº’
            if call_chain['service_interactions']:
                self.report_lines.append("\nğŸ”„ æœå‹™äº¤äº’éˆ:")
                for interaction in call_chain['service_interactions']:
                    self.report_lines.append(
                        f"  â€¢ {interaction['from']} â†’ {interaction['to']} "
                        f"({interaction['type']})"
                    )
        
        # åŒ¹é…å·²çŸ¥æ¨¡å¼
        known_patterns = self.intelligent_engine.match_known_patterns(self.anr_info)
        if known_patterns:
            self.report_lines.append("\nğŸ¯ åŒ¹é…çš„å·²çŸ¥å•é¡Œæ¨¡å¼:")
            for pattern in known_patterns[:3]:  # é¡¯ç¤ºå‰3å€‹æœ€åŒ¹é…çš„
                self.report_lines.append(
                    f"\n  ğŸ“Œ {pattern['root_cause']} "
                    f"(ä¿¡å¿ƒåº¦: {pattern['confidence']*100:.0f}%)"
                )
                self.report_lines.append(f"     åš´é‡æ€§: {pattern['severity']}")
                self.report_lines.append("     è§£æ±ºæ–¹æ¡ˆ:")
                for solution in pattern['solutions']:
                    self.report_lines.append(f"       â€¢ {solution}")
        
        # æ™‚åºåˆ†æ
        self._add_timeline_analysis()
    
    def _add_timeline_analysis(self):
        """æ·»åŠ é€šç”¨çš„æ™‚åºåˆ†æ"""
        self.report_lines.append("\nâ±ï¸ äº‹ä»¶æ™‚åºåˆ†æ:")
        
        events = []
        
        # åŸºæ–¼ ANR é¡å‹æ§‹å»ºæ™‚åº
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            events.append("1. ç”¨æˆ¶è§¸ç™¼è¼¸å…¥äº‹ä»¶ï¼ˆè§¸æ‘¸/æŒ‰éµï¼‰")
            events.append("2. InputDispatcher å˜—è©¦åˆ†ç™¼äº‹ä»¶åˆ°æ‡‰ç”¨")
            events.append("3. æ‡‰ç”¨ä¸»ç·šç¨‹ç„¡éŸ¿æ‡‰")
            events.append("4. ç­‰å¾…è¶…é 5 ç§’")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            events.append("1. Service æ¥æ”¶åˆ°å•Ÿå‹•/ç¶å®šè«‹æ±‚")
            events.append("2. onCreate/onStartCommand é–‹å§‹åŸ·è¡Œ")
            events.append("3. ä¸»ç·šç¨‹è¢«é˜»å¡")
            timeout = ANRTimeouts.SERVICE_TIMEOUT if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info.get('is_foreground') else ANRTimeouts.SERVICE_BACKGROUND_TIMEOUT
            events.append(f"4. è¶…é {timeout/1000} ç§’æœªå®Œæˆ")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            events.append("1. ç³»çµ±/æ‡‰ç”¨ç™¼é€å»£æ’­")
            events.append("2. BroadcastReceiver.onReceive é–‹å§‹åŸ·è¡Œ")
            events.append("3. è™•ç†æ™‚é–“éé•·")
            timeout = ANRTimeouts.BROADCAST_TIMEOUT if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info.get('is_foreground') else ANRTimeouts.BROADCAST_BACKGROUND_TIMEOUT
            events.append(f"4. è¶…é {timeout/1000} ç§’æœªå®Œæˆ")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        
        # åŸºæ–¼å †ç–Šåˆ†æè£œå……äº‹ä»¶
        if self.anr_info.main_thread:
            for i, frame in enumerate(self.anr_info.main_thread.backtrace[:5]):
                if 'Binder' in frame:
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: é€²è¡Œ Binder IPC èª¿ç”¨")
                elif 'wait' in frame.lower() or 'lock' in frame.lower():
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: ç·šç¨‹ç­‰å¾…/é–ç«¶çˆ­")
                elif any(io in frame for io in ['File', 'SQLite', 'Socket']):
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: I/O æ“ä½œ")
        
        for event in events:
            self.report_lines.append(f"  {event}")
    
    def _add_watchdog_analysis(self):
        """æ·»åŠ  Watchdog åˆ†æ"""
        watchdog_info = self.intelligent_engine._detect_watchdog_timeout(self.content)
        if watchdog_info:
            self.report_lines.append("\nâš ï¸ Watchdog æª¢æ¸¬")
            self.report_lines.append(f"  é¡å‹: {watchdog_info['type']}")
            self.report_lines.append(f"  åš´é‡æ€§: {watchdog_info['severity']}")
            self.report_lines.append(f"  èªªæ˜: {watchdog_info['description']}")
            self.report_lines.append("  å»ºè­°:")
            self.report_lines.append("    â€¢ æª¢æŸ¥ system_server æ˜¯å¦æœ‰æ­»é–")
            self.report_lines.append("    â€¢ åˆ†æç³»çµ±æœå‹™çš„ CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨")
            self.report_lines.append("    â€¢ æŸ¥çœ‹ /data/anr/traces.txt ç²å–å®Œæ•´è³‡è¨Š")
    
    def _add_strictmode_analysis(self):
        """æ·»åŠ  StrictMode é•è¦åˆ†æ"""
        violations = self.intelligent_engine._detect_strictmode_violations(self.content)
        if violations:
            self.report_lines.append("\nğŸš« StrictMode é•è¦æª¢æ¸¬")
            for violation in violations:
                self.report_lines.append(f"  â€¢ {violation['type']}: {violation['description']}")
                self.report_lines.append(f"    å»ºè­°: {violation['suggestion']}")
    
    def _add_gc_analysis(self):
        """æ·»åŠ  GC åˆ†æ"""
        gc_info = self.intelligent_engine._analyze_gc_impact(self.content)
        if gc_info['gc_count'] > 0:
            self.report_lines.append("\nâ™»ï¸ åƒåœ¾å›æ”¶åˆ†æ")
            self.report_lines.append(f"  â€¢ GC æ¬¡æ•¸: {gc_info['gc_count']}")
            self.report_lines.append(f"  â€¢ ç¸½æš«åœæ™‚é–“: {gc_info['total_pause_time']}ms")
            self.report_lines.append(f"  â€¢ å½±éŸ¿è©•ä¼°: {gc_info['impact']}")
            
            if gc_info['impact'] in ['high', 'medium']:
                self.report_lines.append("  å»ºè­°:")
                self.report_lines.append("    â€¢ å„ªåŒ–è¨˜æ†¶é«”åˆ†é…ç­–ç•¥")
                self.report_lines.append("    â€¢ é¿å…å‰µå»ºå¤§é‡è‡¨æ™‚å°è±¡")
                self.report_lines.append("    â€¢ ä½¿ç”¨å°è±¡æ± é‡ç”¨å°è±¡")
    
    def _add_system_health_score(self):
        """æ·»åŠ ç³»çµ±å¥åº·åº¦è©•åˆ†"""
        health_score = self.intelligent_engine._calculate_system_health_score(self.anr_info)
        
        # å„²å­˜å¥åº·åˆ†æ•¸ä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
        self._last_health_score = health_score['score']
        
        self.report_lines.append("\nğŸ¥ ç³»çµ±å¥åº·åº¦è©•ä¼°")
        
        # ä½¿ç”¨åœ–å½¢åŒ–é¡¯ç¤ºåˆ†æ•¸
        score = health_score['score']
        if score >= 80:
            score_display = f"ğŸŸ¢ {score}/100 (å¥åº·)"
        elif score >= 60:
            score_display = f"ğŸŸ¡ {score}/100 (ä¸€èˆ¬)"
        elif score >= 40:
            score_display = f"ğŸŸ  {score}/100 (è¼ƒå·®)"
        else:
            score_display = f"ğŸ”´ {score}/100 (åš´é‡)"
        
        self.report_lines.append(f"  ç¸½åˆ†: {score_display}")
        
        if health_score['factors']:
            self.report_lines.append("  æ‰£åˆ†å› ç´ :")
            for factor in health_score['factors']:
                self.report_lines.append(f"    â€¢ {factor}")
        
        if 'recommendation' in health_score:
            self.report_lines.append(f"  å»ºè­°: {health_score['recommendation']}")
    
    def _add_thread_analysis(self):
        """æ·»åŠ ç·šç¨‹åˆ†æ - å¢å¼·ç‰ˆ"""
        if len(self.anr_info.all_threads) == 0:
            return
        
        self.report_lines.append(f"\nğŸ§µ ç·šç¨‹åˆ†æ (å…± {len(self.anr_info.all_threads)} å€‹)")
        
        # ç·šç¨‹åˆ†é¡çµ±è¨ˆ
        thread_stats = self._get_thread_statistics()
        
        self.report_lines.append("\nğŸ“Š ç·šç¨‹ç‹€æ…‹çµ±è¨ˆ:")
        for state, count in thread_stats.items():
            if count > 0:
                self.report_lines.append(f"  â€¢ {state}: {count} å€‹")
        
        # é¡¯ç¤ºé‡è¦ç·šç¨‹
        important_threads = self._get_important_threads()
        if important_threads:
            self.report_lines.append("\nğŸ” é‡è¦ç·šç¨‹:")
            for thread in important_threads[:10]:
                summary = self._summarize_thread(thread)
                self.report_lines.append(f"  â€¢ {summary}")
                
                # æ–°å¢ï¼šé¡¯ç¤º Crashlytics é¢¨æ ¼æ¨™ç±¤
                tags = self.intelligent_engine._identify_crashlytics_tags(thread)
                if tags:
                    self.report_lines.append(f"    æ¨™ç±¤: {', '.join(tags)}")

    def _summarize_thread(self, thread: ThreadInfo) -> str:
        """ç¸½çµç·šç¨‹è³‡è¨Š"""
        summary_parts = [f"{thread.name} (tid={thread.tid}"]
        
        # æ·»åŠ å„ªå…ˆç´š
        if thread.prio and thread.prio != "N/A":
            summary_parts.append(f"prio={thread.prio}")
        
        # æ·»åŠ ç‹€æ…‹
        summary_parts.append(f"{thread.state.value})")
        
        summary = ", ".join(summary_parts)
        
        # æ·»åŠ é¡å¤–è³‡è¨Š
        extra_info = []
        
        if thread.waiting_info:
            extra_info.append(thread.waiting_info)
        elif thread.waiting_locks:
            if len(thread.waiting_locks) == 1:
                extra_info.append(f"ç­‰å¾…é–: {thread.waiting_locks[0]}")
            else:
                extra_info.append(f"ç­‰å¾… {len(thread.waiting_locks)} å€‹é–")
        elif thread.held_locks:
            if len(thread.held_locks) == 1:
                extra_info.append(f"æŒæœ‰é–: {thread.held_locks[0]}")
            else:
                extra_info.append(f"æŒæœ‰ {len(thread.held_locks)} å€‹é–")
        
        # æ·»åŠ  CPU æ™‚é–“è³‡è¨Šï¼ˆå¦‚æœæœ‰ï¼‰
        if thread.schedstat:
            extra_info.append(thread.schedstat)
        elif thread.utm and thread.stm:
            utm_ms = int(thread.utm) * 10  # jiffies to ms (å‡è¨­ HZ=100)
            stm_ms = int(thread.stm) * 10
            extra_info.append(f"CPU: usr={utm_ms}ms sys={stm_ms}ms")
        
        # æª¢æŸ¥æ˜¯å¦åœ¨åŸ·è¡Œç‰¹å®šæ“ä½œ
        if thread.backtrace:
            for frame in thread.backtrace[:3]:
                if 'sleep' in frame.lower():
                    extra_info.append("ğŸ›Œ ä¼‘çœ ä¸­")
                    break
                elif 'wait' in frame.lower() or 'park' in frame.lower():
                    extra_info.append("â° ç­‰å¾…ä¸­")
                    break
                elif any(io in frame for io in ['File', 'SQLite', 'Socket']):
                    extra_info.append("ğŸ’¾ I/O æ“ä½œ")
                    break
                elif 'Binder' in frame:
                    extra_info.append("ğŸ”— Binder IPC")
                    break
        
        if extra_info:
            summary += " - " + ", ".join(extra_info)
        
        return summary
        
    def _get_important_threads(self) -> List[ThreadInfo]:
            """ç²å–é‡è¦ç·šç¨‹"""
            important = []
            seen_threads = set()
            
            # 1. ä¸»ç·šç¨‹ç¸½æ˜¯é‡è¦çš„
            if self.anr_info.main_thread:
                important.append(self.anr_info.main_thread)
                seen_threads.add(self.anr_info.main_thread.tid)
            
            # 2. é˜»å¡çš„ç·šç¨‹
            blocked_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.state == ThreadState.BLOCKED:
                    blocked_threads.append(thread)
            
            # æŒ‰å„ªå…ˆç´šæ’åºé˜»å¡çš„ç·šç¨‹
            blocked_threads.sort(key=lambda t: int(t.prio) if t.prio.isdigit() else 999)
            important.extend(blocked_threads[:5])
            seen_threads.update(t.tid for t in blocked_threads[:5])
            
            # 3. ç­‰å¾…é–çš„ç·šç¨‹
            waiting_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.waiting_locks:
                    waiting_threads.append(thread)
            
            important.extend(waiting_threads[:5])
            seen_threads.update(t.tid for t in waiting_threads[:5])
            
            # 4. ç³»çµ±é—œéµç·šç¨‹
            critical_thread_names = [
                'Binder:', 'FinalizerDaemon', 'FinalizerWatchdogDaemon',
                'ReferenceQueueDaemon', 'HeapTaskDaemon', 'RenderThread',
                'UI Thread', 'AsyncTask', 'OkHttp', 'grpc', 'Retrofit'
            ]
            
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads:
                    for critical_name in critical_thread_names:
                        if critical_name in thread.name:
                            important.append(thread)
                            seen_threads.add(thread.tid)
                            break
            
            # 5. åŸ·è¡Œ Binder èª¿ç”¨çš„ç·šç¨‹
            binder_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads:
                    if any('Binder' in frame for frame in thread.backtrace[:3]):
                        binder_threads.append(thread)
            
            important.extend(binder_threads[:3])
            seen_threads.update(t.tid for t in binder_threads[:3])
            
            # 6. Native ç‹€æ…‹çš„ç·šç¨‹ï¼ˆå¯èƒ½åœ¨åŸ·è¡Œ JNIï¼‰
            native_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.state == ThreadState.NATIVE:
                    native_threads.append(thread)
            
            important.extend(native_threads[:3])
            
            return important[:20]  # æœ€å¤šè¿”å›20å€‹é‡è¦ç·šç¨‹
    
    def _get_thread_statistics(self) -> Dict[str, int]:
        """ç²å–ç·šç¨‹çµ±è¨ˆ"""
        stats = {}
        
        for thread in self.anr_info.all_threads:
            state_name = thread.state.value
            stats[state_name] = stats.get(state_name, 0) + 1
        
        # æŒ‰æ•¸é‡æ’åº
        sorted_stats = dict(sorted(stats.items(), key=lambda x: x[1], reverse=True))
        
        return sorted_stats
        
    def _add_deadlock_detection(self):
        """æ·»åŠ æ­»é–æª¢æ¸¬ - å¢å¼·ç‰ˆ"""
        # ä½¿ç”¨å¢å¼·çš„æ­»é–æª¢æ¸¬
        deadlock_info = self.intelligent_engine._detect_complex_deadlock(self.anr_info.all_threads)
        
        if deadlock_info['has_deadlock']:
            self.report_lines.append("\nğŸ’€ æ­»é–æª¢æ¸¬")
            
            if deadlock_info['cross_process']:
                self.report_lines.append("  âš ï¸ æª¢æ¸¬åˆ°è·¨é€²ç¨‹æ­»é–!")
            
            if deadlock_info['cycles']:
                for i, cycle in enumerate(deadlock_info['cycles'], 1):
                    self.report_lines.append(f"  æ­»é–å¾ªç’° {i}:")
                    for thread_info in cycle:
                        self.report_lines.append(f"    â€¢ {thread_info}")
    
    def _generate_suggestions(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå»ºè­° - å¢å¼·ç‰ˆ"""
        suggestions = {
            'immediate': [],
            'optimization': [],
            'investigation': []
        }
        
        # åŸºæ–¼ä¸»ç·šç¨‹ç‹€æ…‹
        if self.anr_info.main_thread:
            # æª¢æŸ¥å †ç–Š
            for frame in self.anr_info.main_thread.backtrace[:5]:
                if 'sleep' in frame.lower():
                    suggestions['immediate'].append("ç«‹å³ç§»é™¤ä¸»ç·šç¨‹ä¸­çš„ sleep æ“ä½œ")
                elif any(keyword in frame for keyword in ['File', 'SQLite', 'SharedPreferences']):
                    suggestions['immediate'].append("å°‡ I/O æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹ (ä½¿ç”¨ Kotlin å”ç¨‹æˆ– ExecutorService)")
                elif any(keyword in frame for keyword in ['Http', 'Socket', 'URL']):
                    suggestions['immediate'].append("å°‡ç¶²è·¯è«‹æ±‚ç§»è‡³èƒŒæ™¯ç·šç¨‹")
                elif 'synchronized' in frame:
                    suggestions['optimization'].append("æª¢æŸ¥åŒæ­¥é–çš„ä½¿ç”¨ï¼Œè€ƒæ…®ä½¿ç”¨ç„¡é–æ•¸æ“šçµæ§‹æˆ– ReadWriteLock")
        
        # åŸºæ–¼ ANR é¡å‹
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            suggestions['immediate'].append("æª¢æŸ¥ UI ç·šç¨‹æ˜¯å¦æœ‰è€—æ™‚æ“ä½œ")
            suggestions['optimization'].append("ä½¿ç”¨ Systrace åˆ†æ UI æ€§èƒ½")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ Choreographer ç›£æ§å¹€ç‡")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            suggestions['immediate'].append("Service çš„ onStartCommand æ‡‰å¿«é€Ÿè¿”å›")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ JobIntentService æˆ– WorkManager")
            suggestions['investigation'].append("æª¢æŸ¥æ˜¯å¦éœ€è¦å‰å°æœå‹™")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            suggestions['immediate'].append("BroadcastReceiver çš„ onReceive æ‡‰åœ¨ 10 ç§’å…§å®Œæˆ")
            suggestions['optimization'].append("ä½¿ç”¨ goAsync() è™•ç†è€—æ™‚æ“ä½œ")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ LocalBroadcastManager æ¸›å°‘é–‹éŠ·")
        
        # åŸºæ–¼å•é¡Œé¡å‹
        if self._has_deadlock():
            suggestions['immediate'].append("é‡æ–°è¨­è¨ˆé–çš„ç²å–é †åºï¼Œé¿å…å¾ªç’°ç­‰å¾…")
            suggestions['investigation'].append("ä½¿ç”¨ Android Studio çš„ CPU Profiler åˆ†ææ­»é–")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ java.util.concurrent åŒ…ä¸­çš„é«˜ç´šåŒæ­¥å·¥å…·")
        
        if any('Binder' in frame for frame in (self.anr_info.main_thread.backtrace[:5] if self.anr_info.main_thread else [])):
            suggestions['investigation'].append("æª¢æŸ¥ system_server çš„å¥åº·ç‹€æ…‹")
            suggestions['investigation'].append("ä½¿ç”¨ 'dumpsys activity' æŸ¥çœ‹ç³»çµ±ç‹€æ…‹")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ç•°æ­¥ Binder èª¿ç”¨ (oneway)")
        
        # åŸºæ–¼ç³»çµ±å¥åº·åº¦
        if hasattr(self, '_last_health_score') and self._last_health_score < 60:
            suggestions['immediate'].append("ç³»çµ±è³‡æºç·Šå¼µï¼Œè€ƒæ…®å„ªåŒ–æ‡‰ç”¨è¨˜æ†¶é«”ä½¿ç”¨")
            suggestions['optimization'].append("å¯¦æ–½è¨˜æ†¶é«”å¿«å–ç­–ç•¥")
        
        # é€šç”¨å»ºè­°
        suggestions['investigation'].extend([
            "æ”¶é›†æ›´å¤š ANR traces ç¢ºèªå•é¡Œé‡ç¾æ€§",
            "ä½¿ç”¨ Android Studio Profiler åˆ†æ CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨",
            "æª¢æŸ¥ç›¸é—œæ™‚é–“æ®µçš„ logcat (ç‰¹åˆ¥æ˜¯ system_server)",
            "é–‹å•Ÿ StrictMode æª¢æ¸¬æ½›åœ¨å•é¡Œ",
        ])
        
        suggestions['optimization'].extend([
            "ä½¿ç”¨ Kotlin Coroutines æˆ– RxJava è™•ç†ç•°æ­¥æ“ä½œ",
            "å¯¦æ–½é©ç•¶çš„ç·šç¨‹æ± ç®¡ç† (é¿å…å‰µå»ºéå¤šç·šç¨‹)",
            "è€ƒæ…®ä½¿ç”¨ Android Jetpack çš„ WorkManager",
            "å®šæœŸ review ä¸»ç·šç¨‹çš„æ‰€æœ‰æ“ä½œ",
        ])
        
        return suggestions

    def _analyze_binder_issues(self) -> List[str]:
            """åˆ†æ Binder å•é¡Œ"""
            issues = []
            
            if not self.anr_info.main_thread:
                return issues
            
            # æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦åœ¨ç­‰å¾… Binder
            for frame in self.anr_info.main_thread.backtrace[:10]:
                if 'BinderProxy' in frame or 'Binder.transact' in frame:
                    issues.append("ä¸»ç·šç¨‹æ­£åœ¨ç­‰å¾… Binder IPC éŸ¿æ‡‰")
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰ system_server å•é¡Œ
                    if 'system_server' in self.content:
                        issues.append("æª¢æ¸¬åˆ° system_server ç›¸é—œè³‡è¨Šï¼Œå¯èƒ½æ˜¯ç³»çµ±æœå‹™å•é¡Œ")
                    
                    # å˜—è©¦è­˜åˆ¥ç›®æ¨™æœå‹™
                    service = self._identify_binder_service(self.anr_info.main_thread.backtrace[:10])
                    if service:
                        issues.append(f"ç›®æ¨™æœå‹™: {service}")
                    
                    break
            
            # æª¢æŸ¥å…¶ä»–ç·šç¨‹çš„ Binder ç‹€æ…‹
            binder_waiting_threads = 0
            for thread in self.anr_info.all_threads:
                if thread != self.anr_info.main_thread:
                    for frame in thread.backtrace[:5]:
                        if 'Binder' in frame:
                            binder_waiting_threads += 1
                            break
            
            if binder_waiting_threads > 3:
                issues.append(f"ç™¼ç¾ {binder_waiting_threads} å€‹ç·šç¨‹åœ¨ç­‰å¾… Binder èª¿ç”¨")
                issues.append("å¯èƒ½å­˜åœ¨ Binder ç·šç¨‹æ± è€—ç›¡å•é¡Œ")
            
            return issues
        
    def _analyze_lock_issues(self) -> List[str]:
        """åˆ†æé–å•é¡Œ"""
        issues = []
        
        # çµ±è¨ˆé˜»å¡ç·šç¨‹
        blocked_threads = [t for t in self.anr_info.all_threads if t.state == ThreadState.BLOCKED]
        if len(blocked_threads) > 3:
            issues.append(f"ç™¼ç¾ {len(blocked_threads)} å€‹ç·šç¨‹è™•æ–¼ BLOCKED ç‹€æ…‹")
            issues.append("å¯èƒ½å­˜åœ¨åš´é‡çš„é–ç«¶çˆ­")
            
            # åˆ—å‡ºå‰3å€‹é˜»å¡çš„ç·šç¨‹
            for thread in blocked_threads[:3]:
                if thread.waiting_info:
                    issues.append(f"  - {thread.name}: {thread.waiting_info}")
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            issues.append("âš ï¸ æª¢æ¸¬åˆ°å¯èƒ½çš„æ­»é–æƒ…æ³")
            
            # æ‰¾å‡ºæ­»é–ç·šç¨‹
            deadlock_info = self._find_deadlock_threads()
            if deadlock_info:
                issues.extend(deadlock_info)
        
        # æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦æŒæœ‰é–
        if self.anr_info.main_thread and self.anr_info.main_thread.held_locks:
            issues.append(f"ä¸»ç·šç¨‹æŒæœ‰ {len(self.anr_info.main_thread.held_locks)} å€‹é–")
            for lock in self.anr_info.main_thread.held_locks[:3]:
                issues.append(f"  - {lock}")
        
        return issues
    
    def _analyze_io_issues(self) -> List[str]:
        """åˆ†æ I/O å•é¡Œ"""
        issues = []
        
        if not self.anr_info.main_thread:
            return issues
        
        io_keywords = [
            ('File', 'æ–‡ä»¶'),
            ('read', 'è®€å–'),
            ('write', 'å¯«å…¥'),
            ('SQLite', 'è³‡æ–™åº«'),
            ('database', 'è³‡æ–™åº«'),
            ('SharedPreferences', 'åå¥½è¨­å®š'),
            ('ContentResolver', 'ContentProvider'),
            ('AssetManager', 'Asset è³‡æº'),
        ]
        
        for frame in self.anr_info.main_thread.backtrace[:10]:
            for keyword, desc in io_keywords:
                if keyword in frame:
                    issues.append(f"ä¸»ç·šç¨‹æ­£åœ¨åŸ·è¡Œ {desc} ç›¸é—œçš„ I/O æ“ä½œ")
                    issues.append("å»ºè­°å°‡ I/O æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹")
                    
                    # ç‰¹å®šå»ºè­°
                    if 'SharedPreferences' in frame:
                        issues.append("è€ƒæ…®ä½¿ç”¨ apply() è€Œé commit()")
                    elif 'SQLite' in frame or 'database' in frame:
                        issues.append("ä½¿ç”¨ AsyncQueryHandler æˆ– Room çš„ç•°æ­¥ API")
                    
                    return issues
        
        # æª¢æŸ¥ç¶²è·¯ I/O
        network_keywords = ['Socket', 'Http', 'URL', 'Network', 'Download', 'Upload']
        for frame in self.anr_info.main_thread.backtrace[:10]:
            for keyword in network_keywords:
                if keyword in frame:
                    issues.append("ä¸»ç·šç¨‹æ­£åœ¨åŸ·è¡Œç¶²è·¯æ“ä½œ")
                    issues.append("åš´é‡é•å Android æœ€ä½³å¯¦è¸")
                    issues.append("ä½¿ç”¨ Retrofitã€OkHttp æˆ– Volley çš„ç•°æ­¥ API")
                    return issues
        
        return issues
    
    def _analyze_resource_issues(self) -> List[str]:
        """åˆ†æç³»çµ±è³‡æºå•é¡Œ"""
        issues = []
        
        # CPU åˆ†æ
        if self.anr_info.cpu_usage:
            total_cpu = self.anr_info.cpu_usage.get('total', 0)
            if total_cpu > 90:
                issues.append(f"CPU ä½¿ç”¨ç‡éé«˜: {total_cpu:.1f}%")
                issues.append("å¯èƒ½åŸå› : ç„¡é™å¾ªç’°ã€éåº¦è¨ˆç®—ã€é »ç¹ GC")
            elif total_cpu > 70:
                issues.append(f"CPU ä½¿ç”¨ç‡è¼ƒé«˜: {total_cpu:.1f}%")
            
            # æª¢æŸ¥è² è¼‰
            load_1min = self.anr_info.cpu_usage.get('load_1min', 0)
            if load_1min > 4.0:
                issues.append(f"ç³»çµ±è² è¼‰éé«˜: {load_1min}")
        
        # è¨˜æ†¶é«”åˆ†æ
        if self.anr_info.memory_info:
            if 'available' in self.anr_info.memory_info:
                available_mb = self.anr_info.memory_info['available'] / 1024
                if available_mb < 100:
                    issues.append(f"å¯ç”¨è¨˜æ†¶é«”åš´é‡ä¸è¶³: {available_mb:.1f} MB")
                    issues.append("å¯èƒ½è§¸ç™¼é »ç¹çš„ GC å’Œè¨˜æ†¶é«”å£“ç¸®")
                elif available_mb < 200:
                    issues.append(f"å¯ç”¨è¨˜æ†¶é«”è¼ƒä½: {available_mb:.1f} MB")
            
            # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨ç‡
            if 'used_percent' in self.anr_info.memory_info:
                used_percent = self.anr_info.memory_info['used_percent']
                if used_percent > 90:
                    issues.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {used_percent:.1f}%")
        
        # GC åˆ†æ
        gc_count = self.content.count('GC_')
        if gc_count > 10:
            issues.append(f"é »ç¹çš„åƒåœ¾å›æ”¶: {gc_count} æ¬¡")
            issues.append("å»ºè­°å„ªåŒ–è¨˜æ†¶é«”åˆ†é…ç­–ç•¥")
        elif gc_count > 5:
            issues.append(f"åƒåœ¾å›æ”¶è¼ƒå¤š: {gc_count} æ¬¡")
        
        # æª¢æŸ¥ OutOfMemoryError
        if "OutOfMemoryError" in self.content:
            issues.append("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤ (OutOfMemoryError)")
            issues.append("æ‡‰ç”¨å¯èƒ½å­˜åœ¨è¨˜æ†¶é«”æ´©æ¼")
        
        # æª¢æŸ¥ç³»çµ±è² è¼‰
        if "load average" in self.content:
            load_match = re.search(r'load average:\s*([\d.]+),\s*([\d.]+),\s*([\d.]+)', self.content)
            if load_match:
                load1 = float(load_match.group(1))
                load5 = float(load_match.group(2))
                load15 = float(load_match.group(3))
                if load1 > 8.0:
                    issues.append(f"ç³»çµ±è² è¼‰æ¥µé«˜: 1åˆ†é˜å¹³å‡ {load1}")
                elif load1 > 4.0:
                    issues.append(f"ç³»çµ±è² è¼‰éé«˜: 1åˆ†é˜å¹³å‡ {load1}")
        
        # ç·šç¨‹æ•¸åˆ†æ
        thread_count = len(self.anr_info.all_threads)
        if thread_count > 200:
            issues.append(f"ç·šç¨‹æ•¸é‡éå¤š: {thread_count} å€‹")
            issues.append("å¯èƒ½å­˜åœ¨ç·šç¨‹æ´©æ¼")
        elif thread_count > 100:
            issues.append(f"ç·šç¨‹æ•¸é‡è¼ƒå¤š: {thread_count} å€‹")
        
        return issues
    
    def _has_deadlock(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰æ­»é–"""
        # ç°¡å–®çš„æ­»é–æª¢æ¸¬ï¼šæª¢æŸ¥å¾ªç’°ç­‰å¾…
        waiting_graph = {}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æª¢æŸ¥å¾ªç’°
        visited = set()
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    return True  # ç™¼ç¾å¾ªç’°
                if current in visited:
                    break
                path.append(current)
            
            visited.update(path)
        
        return False
    
    def _find_deadlock_threads(self) -> List[str]:
        """æ‰¾å‡ºæ­»é–ç·šç¨‹"""
        info = []
        
        # å»ºç«‹ç­‰å¾…åœ–
        waiting_graph = {}
        thread_map = {t.tid: t for t in self.anr_info.all_threads}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æ‰¾å‡ºå¾ªç’°
        visited = set()
        cycles_found = set()
        
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    # æ‰¾åˆ°å¾ªç’°
                    cycle_start = path.index(current)
                    cycle = path[cycle_start:]
                    cycle_key = tuple(sorted(cycle))
                    
                    if cycle_key not in cycles_found:
                        cycles_found.add(cycle_key)
                        
                        cycle_info = []
                        for tid in cycle:
                            if tid in thread_map:
                                thread = thread_map[tid]
                                cycle_info.append(f"{thread.name} (tid={tid})")
                        
                        info.append(f"æ­»é–å¾ªç’°: {' -> '.join(cycle_info)} -> {cycle_info[0]}")
                    break
                    
                path.append(current)
            
            visited.update(path)
        
        return info
    
    def _identify_binder_service(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ Binder ç›®æ¨™æœå‹™"""
        # æ“´å±•æœå‹™è­˜åˆ¥è¦å‰‡
        service_patterns = {
            'WindowManager': [
                'getWindowInsets', 'addWindow', 'removeWindow', 'updateViewLayout',
                'WindowManagerService', 'WindowManager$', 'IWindowManager',
                'ViewRootImpl', 'relayoutWindow', 'WindowSession'
            ],
            'ActivityManager': [
                'startActivity', 'bindService', 'getRunningTasks', 'getServices',
                'ActivityManagerService', 'ActivityManager$', 'IActivityManager',
                'broadcastIntent', 'startService', 'stopService'
            ],
            'PackageManager': [
                'getPackageInfo', 'queryIntentActivities', 'getApplicationInfo',
                'PackageManagerService', 'PackageManager$', 'IPackageManager',
                'getInstalledPackages', 'resolveActivity'
            ],
            'PowerManager': [
                'isScreenOn', 'goToSleep', 'wakeUp', 'PowerManagerService',
                'PowerManager$', 'IPowerManager', 'acquire', 'release'
            ],
            'InputManager': [
                'injectInputEvent', 'getInputDevice', 'InputManagerService',
                'InputManager$', 'IInputManager', 'InputMethodManager'
            ],
            'NotificationManager': [
                'notify', 'cancel', 'NotificationManagerService',
                'NotificationManager$', 'INotificationManager', 'enqueueNotification'
            ],
            'AudioManager': [
                'setStreamVolume', 'AudioService', 'AudioManager$', 'IAudioService',
                'playSoundEffect', 'setRingerMode'
            ],
            'TelephonyManager': [
                'getDeviceId', 'getNetworkType', 'TelephonyRegistry',
                'TelephonyManager$', 'ITelephony', 'getPhoneType'
            ],
            'LocationManager': [
                'getLastKnownLocation', 'requestLocationUpdates',
                'LocationManagerService', 'ILocationManager', 'removeUpdates'
            ],
            'SensorManager': [
                'registerListener', 'SensorService', 'ISensorService',
                'unregisterListener', 'getDefaultSensor'
            ],
            'ConnectivityManager': [
                'getActiveNetworkInfo', 'ConnectivityService', 'IConnectivityManager',
                'requestNetwork', 'getNetworkCapabilities'
            ],
            'WifiManager': [
                'getWifiState', 'WifiService', 'IWifiManager',
                'startScan', 'getConnectionInfo'
            ],
        }
        
        for service, patterns in service_patterns.items():
            for frame in frames:
                if any(pattern in frame for pattern in patterns):
                    return service
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…·é«”æœå‹™ï¼Œå˜—è©¦å¾ frame ä¸­æå–
        for frame in frames:
            if 'Service' in frame:
                match = re.search(r'(\w+Service)', frame)
                if match:
                    return match.group(1)
            elif 'Manager' in frame and 'Proxy' in frame:
                match = re.search(r'(\w+Manager)', frame)
                if match:
                    return match.group(1)
        
        return None

# ============= Tombstone åˆ†æå™¨ =============
class TombstoneAnalyzer(BaseAnalyzer):
    """Tombstone åˆ†æå™¨"""
    
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ– Tombstone åˆ†ææ¨¡å¼"""
        return {
            'signal_patterns': [
                r'signal\s+(\d+)\s+\((\w+)\)',
                r'si_signo=(\d+).*?si_code=(\d+)',
                r'Fatal signal\s+(\d+)\s+\((\w+)\)',
                r'terminating with uncaught exception',
                r'Abort message',
            ],
            'process_patterns': [
                r'pid:\s*(\d+),\s*tid:\s*(\d+),\s*name:\s*([^\s]+)',
                r'pid\s+(\d+)\s+tid\s+(\d+)\s+name\s+([^\s]+)',
                r'Process:\s*([^,\s]+).*?PID:\s*(\d+)',
                r'Cmdline:\s*(.+)',
                r'>>> ([^\s]+) <<<',
            ],
            'abort_patterns': [
                r'Abort message:\s*["\'](.+?)["\']',
                r'Abort message:\s*(.+?)(?:\n|$)',
                r'abort_message:\s*"(.+?)"',
                r'CHECK\s+failed:\s*(.+)',
                r'Fatal Exception:\s*(.+)',
            ],
            'backtrace_patterns': [
                r'#(\d+)\s+pc\s+([0-9a-fA-F]+)\s+([^\s]+)(?:\s+\((.+?)\))?',
                r'#(\d+)\s+([0-9a-fA-F]+)\s+([^\s]+)(?:\s+\((.+?)\))?',
                r'backtrace:\s*#(\d+)\s+pc\s+([0-9a-fA-F]+)',
                r'at\s+([^\(]+)\(([^\)]+)\)',
            ],
            'memory_patterns': [
                r'([0-9a-f]+)-([0-9a-f]+)\s+([rwxps-]+)\s+([0-9a-f]+)\s+([0-9a-f:]+)\s+(\d+)\s+(.*)',
                r'memory near',
                r'code around',
            ],
            'register_patterns': [
                r'(r\d+|x\d+|pc|sp|lr|fp)\s+([0-9a-fA-F]+)',
                r'(eax|ebx|ecx|edx|esi|edi|ebp|esp|eip)\s+([0-9a-fA-F]+)',
            ],
            'fortify_patterns': [
                r'FORTIFY:\s*(.+)',
                r'fortify_fatal:\s*(.+)',
                r'detected source and destination buffer overlap',
                r'buffer overflow detected',
            ],
            'seccomp_patterns': [
                r'seccomp prevented call to disallowed.*?system call\s+(\d+)',
                r'signal\s+31\s+\(SIGSYS\)',
                r'SYS_SECCOMP',
            ],
            'java_patterns': [
                r'java:\s*(.+)',
                r'at\s+([a-zA-Z0-9._$]+)\(([^)]+)\)',
                r'Caused by:\s*(.+)',
            ],
        }
    
    @time_tracker("è§£æ Tombstone æª”æ¡ˆ")
    def analyze(self, file_path: str) -> str:
        """åˆ†æ Tombstone æª”æ¡ˆ"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            
            # è§£æ Tombstone è³‡è¨Š
            tombstone_info = self._parse_tombstone_info(content)
            
            # ç”Ÿæˆåˆ†æå ±å‘Š
            report = self._generate_report(tombstone_info, content)
            
            return report
            
        except Exception as e:
            return f"âŒ åˆ†æ Tombstone æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
    
    def _parse_tombstone_info(self, content: str) -> TombstoneInfo:
        """è§£æ Tombstone è³‡è¨Š"""
        lines = content.splitlines()
        
        # è§£æåŸºæœ¬è³‡è¨Š
        signal_info = self._extract_signal_info(content)
        process_info = self._extract_process_info(content)
        abort_message = self._extract_abort_message(content)
        
        # è§£æå´©æ½°å †ç–Š
        crash_backtrace = self._extract_backtrace(content)
        
        # è§£æè¨˜æ†¶é«”æ˜ å°„
        memory_map = self._extract_memory_map(content)
        
        # è§£ææ‰“é–‹çš„æª”æ¡ˆ
        open_files = self._extract_open_files(content)
        
        # è§£æå¯„å­˜å™¨
        registers = self._extract_registers(content)
        
        # è§£ææ‰€æœ‰ç·šç¨‹
        all_threads = self._extract_all_threads_tombstone(lines, content)
        
        # æ–°å¢ï¼šè§£æ Java å †ç–Šï¼ˆå¦‚æœæœ‰ï¼‰
        java_stack = self._extract_java_stack(content)
        
        tombstone_info = TombstoneInfo(
            signal=signal_info.get('signal', CrashSignal.UNKNOWN),
            signal_code=signal_info.get('code', 'Unknown'),
            fault_addr=signal_info.get('fault_addr', 'Unknown'),
            process_name=process_info.get('process_name', 'Unknown'),
            pid=process_info.get('pid', 'Unknown'),
            tid=process_info.get('tid', 'Unknown'),
            thread_name=process_info.get('thread_name', 'Unknown'),
            abort_message=abort_message,
            crash_backtrace=crash_backtrace,
            all_threads=all_threads,
            memory_map=memory_map,
            open_files=open_files,
            registers=registers
        )
        
        # æ–°å¢ï¼šåŠ å…¥ Java å †ç–Š
        if hasattr(tombstone_info, 'java_stack'):
            tombstone_info.java_stack = java_stack
        
        return tombstone_info
    
    def _extract_signal_info(self, content: str) -> Dict:
        """æå–ä¿¡è™Ÿè³‡è¨Š"""
        info = {}
        
        # æå–ä¿¡è™Ÿ
        for pattern in self.patterns['signal_patterns']:
            match = re.search(pattern, content)
            if match:
                if 'signal' in pattern and len(match.groups()) >= 2:
                    signal_num = int(match.group(1))
                    signal_name = match.group(2) if len(match.groups()) >= 2 else None
                    
                    # åŒ¹é…ä¿¡è™Ÿæšèˆ‰
                    for signal in CrashSignal:
                        if signal.value[0] == signal_num:
                            info['signal'] = signal
                            break
                    else:
                        info['signal'] = CrashSignal.UNKNOWN
                    
                    info['signal_num'] = signal_num
                    info['signal_name'] = signal_name
                    break
        
        # ç‰¹æ®Šè™•ç† SIGSYS (seccomp)
        if any(re.search(pattern, content) for pattern in self.patterns['seccomp_patterns']):
            info['signal'] = CrashSignal.SIGSYS
            info['signal_num'] = 31
            info['signal_name'] = 'SIGSYS'
            
            # æå–è¢«é˜»æ­¢çš„ç³»çµ±èª¿ç”¨è™Ÿ
            syscall_match = re.search(r'system call\s+(\d+)', content)
            if syscall_match:
                info['blocked_syscall'] = syscall_match.group(1)
        
        # æå–ä¿¡è™Ÿç¢¼
        code_match = re.search(r'(?:si_code|code)[=:\s]+([0-9-]+)', content)
        if code_match:
            info['code'] = code_match.group(1)
            
            # è§£æä¿¡è™Ÿç¢¼å«ç¾©
            info['code_meaning'] = self._interpret_signal_code(
                info.get('signal', CrashSignal.UNKNOWN),
                info['code']
            )
        
        # æå–æ•…éšœåœ°å€
        fault_patterns = [
            r'fault addr\s+([0-9a-fxA-FX]+)',
            r'si_addr\s+([0-9a-fxA-FX]+)',
            r'Accessing address:\s*([0-9a-fxA-FX]+)',
            r'Cause:\s*null pointer dereference',
        ]
        
        for pattern in fault_patterns:
            match = re.search(pattern, content)
            if match:
                if 'null pointer' in pattern:
                    info['fault_addr'] = '0x0'
                else:
                    info['fault_addr'] = match.group(1)
                break
        
        # æª¢æŸ¥ç‰¹æ®Šæ•…éšœåœ°å€
        if info.get('fault_addr'):
            addr = info['fault_addr'].lower()
            if addr in ['0x0', '0', '00000000', '0000000000000000']:
                info['fault_type'] = 'null_pointer'
            elif addr == '0xdeadbaad':
                info['fault_type'] = 'abort_marker'
            elif addr.startswith('0xdead'):
                info['fault_type'] = 'debug_marker'
            elif addr == '0xdeadbeef':
                info['fault_type'] = 'uninitialized'
        
        return info
    
    def _interpret_signal_code(self, signal: CrashSignal, code: str) -> str:
        """è§£é‡‹ä¿¡è™Ÿç¢¼çš„å«ç¾©"""
        try:
            code_num = int(code)
        except:
            return "Unknown"
        
        if signal == CrashSignal.SIGSEGV:
            segv_codes = {
                1: "SEGV_MAPERR - åœ°å€æœªæ˜ å°„",
                2: "SEGV_ACCERR - ç„¡è¨ªå•æ¬Šé™",
                3: "SEGV_BNDERR - é‚Šç•Œæª¢æŸ¥å¤±æ•—",
                4: "SEGV_PKUERR - ä¿è­·éµéŒ¯èª¤",
            }
            return segv_codes.get(code_num, f"Unknown SIGSEGV code {code_num}")
        elif signal == CrashSignal.SIGBUS:
            bus_codes = {
                1: "BUS_ADRALN - åœ°å€å°é½ŠéŒ¯èª¤",
                2: "BUS_ADRERR - ä¸å­˜åœ¨çš„ç‰©ç†åœ°å€",
                3: "BUS_OBJERR - å°è±¡ç‰¹å®šç¡¬é«”éŒ¯èª¤",
            }
            return bus_codes.get(code_num, f"Unknown SIGBUS code {code_num}")
        elif signal == CrashSignal.SIGILL:
            ill_codes = {
                1: "ILL_ILLOPC - éæ³•æ“ä½œç¢¼",
                2: "ILL_ILLOPN - éæ³•æ“ä½œæ•¸",
                3: "ILL_ILLADR - éæ³•å°‹å€æ¨¡å¼",
                4: "ILL_ILLTRP - éæ³•é™·é˜±",
                5: "ILL_PRVOPC - ç‰¹æ¬Šæ“ä½œç¢¼",
                6: "ILL_PRVREG - ç‰¹æ¬Šå¯„å­˜å™¨",
                7: "ILL_COPROC - å”è™•ç†å™¨éŒ¯èª¤",
                8: "ILL_BADSTK - å…§éƒ¨å †ç–ŠéŒ¯èª¤",
            }
            return ill_codes.get(code_num, f"Unknown SIGILL code {code_num}")
        
        return f"Signal code {code_num}"
    
    def _extract_process_info(self, content: str) -> Dict:
        """æå–é€²ç¨‹è³‡è¨Š"""
        info = {}
        
        for pattern in self.patterns['process_patterns']:
            match = re.search(pattern, content)
            if match:
                groups = match.groups()
                if 'pid:' in pattern and len(groups) >= 3:
                    info['pid'] = groups[0]
                    info['tid'] = groups[1]
                    info['process_name'] = groups[2]
                elif 'Process:' in pattern and len(groups) >= 2:
                    info['process_name'] = groups[0]
                    info['pid'] = groups[1]
                elif '>>>' in pattern and len(groups) >= 1:
                    info['process_name'] = groups[0]
                elif 'Cmdline:' in pattern and len(groups) >= 1:
                    info['cmdline'] = groups[0]
                    # å¾ cmdline æå–é€²ç¨‹å
                    if '/' in groups[0]:
                        info['process_name'] = groups[0].split('/')[-1]
                    else:
                        info['process_name'] = groups[0]
                
                if 'pid' in info and 'tid' in info:
                    break
        
        # æå–ç·šç¨‹åç¨±
        thread_patterns = [
            r'Thread-\d+\s+"([^"]+)"',
            r'name:\s*([^\s]+)\s+>>>',
            r'thread_name:\s*([^\s]+)',
        ]
        
        for pattern in thread_patterns:
            thread_match = re.search(pattern, content)
            if thread_match:
                info['thread_name'] = thread_match.group(1)
                break
        
        if 'thread_name' not in info:
            info['thread_name'] = info.get('process_name', 'Unknown')
        
        # æå– ABI å’Œæ§‹å»ºæŒ‡ç´‹
        abi_match = re.search(r"ABI:\s*'([^']+)'", content)
        if abi_match:
            info['abi'] = abi_match.group(1)
        
        fingerprint_match = re.search(r"Build fingerprint:\s*'([^']+)'", content)
        if fingerprint_match:
            info['build_fingerprint'] = fingerprint_match.group(1)
        
        return info
    
    def _extract_abort_message(self, content: str) -> Optional[str]:
        """æå– abort message"""
        for pattern in self.patterns['abort_patterns']:
            match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
            if match:
                message = match.group(1).strip()
                # æ¸…ç†è¨Šæ¯
                message = message.replace('\\n', '\n')
                message = message.replace('\\t', '\t')
                return message
        
        # æª¢æŸ¥ FORTIFY è¨Šæ¯
        for pattern in self.patterns['fortify_patterns']:
            match = re.search(pattern, content)
            if match:
                return f"FORTIFY: {match.group(1)}"
        
        return None
    
    def _extract_backtrace(self, content: str) -> List[Dict]:
        """æå–å´©æ½°å †ç–Š"""
        backtrace = []
        
        # æŸ¥æ‰¾ backtrace å€æ®µ
        backtrace_patterns = [
            r'(?:backtrace:|stack:)\s*\n(.*?)(?:\n\n|memory map:|open files:)',
            r'((?:#\d+\s+pc\s+[0-9a-fA-F]+.*\n)+)',
            r'Stack Trace:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        backtrace_text = None
        for pattern in backtrace_patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                backtrace_text = match.group(1)
                break
        
        if backtrace_text:
            # è§£æå †ç–Šå¹€
            for pattern in self.patterns['backtrace_patterns']:
                frames = re.findall(pattern, backtrace_text, re.MULTILINE)
                
                for frame_match in frames:
                    if len(frame_match) >= 3:
                        frame_info = {
                            'num': int(frame_match[0]) if frame_match[0].isdigit() else 0,
                            'pc': frame_match[1],
                            'location': frame_match[2],
                            'symbol': frame_match[3] if len(frame_match) > 3 else None
                        }
                        
                        # è§£æç¬¦è™Ÿè³‡è¨Š
                        if frame_info['symbol']:
                            frame_info['demangled'] = self._demangle_symbol(frame_info['symbol'])
                        
                        backtrace.append(frame_info)
                
                if backtrace:
                    break
        
        return backtrace
    
    def _demangle_symbol(self, symbol: str) -> str:
        """å˜—è©¦ demangle C++ ç¬¦è™Ÿ"""
        # é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰è©²èª¿ç”¨ c++filt
        if symbol.startswith('_Z'):
            # C++ mangled symbol
            return f"{symbol} (C++ mangled)"
        return symbol
    
    def _extract_memory_map(self, content: str) -> List[str]:
        """æå–è¨˜æ†¶é«”æ˜ å°„"""
        memory_map = []
        
        # æŸ¥æ‰¾ memory map å€æ®µ
        map_patterns = [
            r'memory map.*?:\s*\n(.*?)(?:\n\n|open files:|$)',
            r'maps:\s*\n(.*?)(?:\n\n|$)',
            r'memory near.*?:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in map_patterns:
            map_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if map_section:
                map_text = map_section.group(1)
                
                # è§£æè¨˜æ†¶é«”æ˜ å°„è¡Œ
                for line in map_text.splitlines():
                    if re.match(r'[0-9a-f]+-[0-9a-f]+\s+[rwxps-]+', line):
                        memory_map.append(line.strip())
                
                if memory_map:
                    break
        
        return memory_map[:100]  # é™åˆ¶æ•¸é‡
    
    def _extract_open_files(self, content: str) -> List[str]:
        """æå–æ‰“é–‹çš„æª”æ¡ˆ"""
        open_files = []
        
        # æŸ¥æ‰¾ open files å€æ®µ
        files_patterns = [
            r'open files.*?:\s*\n(.*?)(?:\n\n|$)',
            r'fd table:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in files_patterns:
            files_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if files_section:
                files_text = files_section.group(1)
                
                for line in files_text.splitlines():
                    line = line.strip()
                    if line and not line.startswith('-'):
                        # è§£ææ–‡ä»¶æè¿°ç¬¦è³‡è¨Š
                        fd_match = re.match(r'(\d+):\s+(.+)', line)
                        if fd_match:
                            open_files.append(f"fd {fd_match.group(1)}: {fd_match.group(2)}")
                        else:
                            open_files.append(line)
                
                if open_files:
                    break
        
        return open_files[:50]  # é™åˆ¶æ•¸é‡
    
    def _extract_registers(self, content: str) -> Dict[str, str]:
        """æå–å¯„å­˜å™¨è³‡è¨Š"""
        registers = {}
        
        # æŸ¥æ‰¾å¯„å­˜å™¨å€æ®µ
        reg_patterns = [
            r'registers.*?:\s*\n(.*?)(?:\n\n|backtrace:|$)',
            r'((?:[rx]\d+|pc|sp|lr|fp)\s+[0-9a-fA-F]+.*\n)+',
        ]
        
        for pattern in reg_patterns:
            reg_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if reg_section:
                reg_text = reg_section.group(1)
                
                # è§£æå¯„å­˜å™¨
                for reg_pattern in self.patterns['register_patterns']:
                    matches = re.findall(reg_pattern, reg_text)
                    
                    for reg_name, reg_value in matches:
                        registers[reg_name] = reg_value
                
                if registers:
                    break
        
        # ç‰¹æ®Šè™•ç†æŸäº›æ¶æ§‹çš„å¯„å­˜å™¨é¡¯ç¤º
        if not registers:
            # ARM64 æ ¼å¼
            arm64_match = re.search(
                r'x0\s+([0-9a-f]+)\s+x1\s+([0-9a-f]+)\s+x2\s+([0-9a-f]+)\s+x3\s+([0-9a-f]+)',
                content
            )
            if arm64_match:
                for i in range(4):
                    registers[f'x{i}'] = arm64_match.group(i + 1)
        
        return registers
    
    def _extract_all_threads_tombstone(self, lines: List[str], content: str) -> List[ThreadInfo]:
        """æå–æ‰€æœ‰ç·šç¨‹è³‡è¨Š (Tombstone)"""
        threads = []
        
        # æŸ¥æ‰¾ç·šç¨‹å€æ®µ
        thread_patterns = [
            r'(?:threads|other threads).*?:\s*\n(.*?)(?:\n\n|memory map:|$)',
            r'--- --- --- --- --- --- --- ---\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in thread_patterns:
            thread_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if thread_section:
                thread_text = thread_section.group(1)
                
                # è§£ææ¯å€‹ç·šç¨‹
                thread_blocks = re.split(r'\n(?=tid=|Thread \d+)', thread_text)
                
                for block in thread_blocks:
                    if 'tid=' in block or 'Thread' in block:
                        thread_info = self._parse_thread_block(block)
                        if thread_info:
                            threads.append(thread_info)
                
                break
        
        return threads
    
    def _parse_thread_block(self, block: str) -> Optional[ThreadInfo]:
        """è§£æç·šç¨‹å€å¡Š"""
        # æå–ç·šç¨‹è³‡è¨Š
        tid_match = re.search(r'tid=(\d+)', block)
        name_match = re.search(r'name=([^\s]+)', block)
        
        if tid_match:
            thread = ThreadInfo(
                name=name_match.group(1) if name_match else 'Unknown',
                tid=tid_match.group(1),
                state=ThreadState.UNKNOWN
            )
            
            # æå–å †ç–Š
            stack_lines = []
            for line in block.splitlines():
                if re.match(r'\s*#\d+\s+pc', line):
                    stack_lines.append(line.strip())
            
            thread.backtrace = stack_lines
            return thread
        
        return None
    
    def _extract_java_stack(self, content: str) -> List[str]:
        """æå– Java å †ç–Šï¼ˆå¦‚æœæœ‰ï¼‰"""
        java_stack = []
        
        # æŸ¥æ‰¾ Java å †ç–Šå€æ®µ
        java_patterns = [
            r'java stack trace.*?:\s*\n(.*?)(?:\n\n|$)',
            r'(at\s+[a-zA-Z0-9._$]+\([^)]+\).*\n)+',
        ]
        
        for pattern in java_patterns:
            java_match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if java_match:
                java_text = java_match.group(1)
                
                # è§£æ Java å †ç–Šè¡Œ
                for line in java_text.splitlines():
                    if line.strip().startswith('at '):
                        java_stack.append(line.strip())
                    elif line.strip().startswith('Caused by:'):
                        java_stack.append(line.strip())
                
                break
        
        return java_stack
    
    def _generate_report(self, info: TombstoneInfo, content: str) -> str:
        """ç”Ÿæˆ Tombstone å ±å‘Š"""
        generator = TombstoneReportGenerator(info, content)
        return generator.generate()
    
class TombstoneReportGenerator:
    """Tombstone å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, info: TombstoneInfo, content: str):
        self.info = info
        self.content = content
        self.report_lines = []
        self.intelligent_engine = IntelligentAnalysisEngine()
    
    def generate(self) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        self._add_summary()
        self._add_basic_info()
        self._add_signal_analysis()
        self._add_abort_analysis()
        self._add_backtrace_analysis()
        self._add_memory_analysis()
        self._add_root_cause_analysis()
        self._add_intelligent_crash_analysis()  # æ–°å¢
        self._add_fortify_analysis()           # æ–°å¢
        self._add_symbol_resolution_guide()    # æ–°å¢
        self._add_suggestions()
        
        return "\n".join(self.report_lines)
    
    def _add_summary(self):
        """æ·»åŠ æ‘˜è¦"""
        self.report_lines.extend([
            "ğŸ’¥ Tombstone å´©æ½°åˆ†æå ±å‘Š",
            "=" * 60,
            f"ğŸ“Š å´©æ½°é¡å‹: {self._get_crash_type()}",
            f"ğŸš¨ ä¿¡è™Ÿ: {self.info.signal.value[1]} (signal {self.info.signal.value[0]})",
            f"ğŸ“± é€²ç¨‹: {self.info.process_name} (pid={self.info.pid})",
            f"ğŸ§µ ç·šç¨‹: {self.info.thread_name} (tid={self.info.tid})",
        ])
        
        # å¿«é€Ÿåˆ¤æ–·
        severity = self._assess_severity()
        self.report_lines.append(f"âš ï¸ åš´é‡ç¨‹åº¦: {severity}")
        
        root_cause = self._quick_root_cause()
        self.report_lines.append(f"ğŸ¯ å¯èƒ½åŸå› : {root_cause}")
        
        fixability = self._assess_fixability()
        self.report_lines.append(f"ğŸ”§ å¯ä¿®å¾©æ€§: {fixability}")
        
        self.report_lines.extend(["", "=" * 60, ""])

    def _get_crash_type(self) -> str:
        """ç²å–å´©æ½°é¡å‹"""
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000', '0000000000000000']:
                return "ç©ºæŒ‡é‡è§£å¼•ç”¨"
            else:
                return "è¨˜æ†¶é«”è¨ªå•é•è¦"
        elif self.info.signal == CrashSignal.SIGABRT:
            return "ç¨‹åºä¸»å‹•çµ‚æ­¢"
        elif self.info.signal == CrashSignal.SIGILL:
            return "éæ³•æŒ‡ä»¤"
        elif self.info.signal == CrashSignal.SIGBUS:
            return "åŒ¯æµæ’éŒ¯èª¤"
        elif self.info.signal == CrashSignal.SIGFPE:
            return "æµ®é»ç•°å¸¸"
        else:
            return "æœªçŸ¥å´©æ½°é¡å‹"
    
    def _assess_severity(self) -> str:
        """è©•ä¼°åš´é‡ç¨‹åº¦"""
        # æª¢æŸ¥æ˜¯å¦ç‚ºç³»çµ±é€²ç¨‹
        if any(keyword in self.info.process_name for keyword in ['system_server', 'zygote', 'mediaserver']):
            return "ğŸ”´ æ¥µå…¶åš´é‡ (ç³»çµ±é€²ç¨‹å´©æ½°)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¡†æ¶åº«
        if self.info.crash_backtrace:
            for frame in self.info.crash_backtrace[:3]:
                location = frame.get('location', '')
                if any(lib in location for lib in ['libc.so', 'libandroid_runtime.so', 'libbinder.so']):
                    return "ğŸŸ  åš´é‡ (æ¡†æ¶å±¤å´©æ½°)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå» å•†åº«
        if any('vendor' in frame.get('location', '') for frame in self.info.crash_backtrace[:5]):
            return "ğŸŸ¡ ä¸­ç­‰ (å» å•†åº«å•é¡Œ)"
        
        return "ğŸŸ¢ è¼•å¾® (æ‡‰ç”¨å±¤å´©æ½°)"
    
    def _quick_root_cause(self) -> str:
        """å¿«é€Ÿå®šä½æ ¹æœ¬åŸå› """
        causes = []
        
        # åŸºæ–¼ä¿¡è™Ÿ
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000']:
                causes.append("ç©ºæŒ‡é‡è§£å¼•ç”¨")
            else:
                causes.append("é‡æŒ‡é‡æˆ–è¨˜æ†¶é«”è¶Šç•Œ")
        elif self.info.signal == CrashSignal.SIGABRT:
            if self.info.abort_message:
                if 'assert' in self.info.abort_message.lower():
                    causes.append("æ–·è¨€å¤±æ•—")
                elif 'check failed' in self.info.abort_message.lower():
                    causes.append("æª¢æŸ¥å¤±æ•—")
                else:
                    causes.append("ä¸»å‹•çµ‚æ­¢")
            else:
                causes.append("ç•°å¸¸çµ‚æ­¢")
        
        # åŸºæ–¼å †ç–Š
        if self.info.crash_backtrace:
            top_frame = self.info.crash_backtrace[0]
            symbol = top_frame.get('symbol', '')
            location = top_frame.get('location', '')
            
            if 'malloc' in symbol or 'free' in symbol:
                causes.append("è¨˜æ†¶é«”ç®¡ç†éŒ¯èª¤")
            elif 'strlen' in symbol or 'strcpy' in symbol:
                causes.append("å­—ä¸²è™•ç†éŒ¯èª¤")
            elif 'JNI' in location:
                causes.append("JNI èª¿ç”¨éŒ¯èª¤")
        
        return " / ".join(causes) if causes else "éœ€é€²ä¸€æ­¥åˆ†æ"
    
    def _assess_fixability(self) -> str:
        """è©•ä¼°å¯ä¿®å¾©æ€§"""
        # æª¢æŸ¥æ˜¯å¦åœ¨æ‡‰ç”¨ä»£ç¢¼
        if self.info.crash_backtrace:
            for frame in self.info.crash_backtrace[:5]:
                location = frame.get('location', '')
                if self.info.process_name in location:
                    return "ğŸŸ¢ å®¹æ˜“ (æ‡‰ç”¨å±¤ä»£ç¢¼)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå» å•†åº«
        if any('vendor' in frame.get('location', '') for frame in self.info.crash_backtrace[:5]):
            return "ğŸŸ¡ ä¸­ç­‰ (éœ€è¦å» å•†æ”¯æ´)"
        
        # ç³»çµ±åº«
        if any(lib in frame.get('location', '') for frame in self.info.crash_backtrace[:3] 
               for lib in ['libc.so', 'libandroid_runtime.so']):
            return "ğŸ”´ å›°é›£ (ç³»çµ±å±¤å•é¡Œ)"
        
        return "ğŸŸ¡ ä¸­ç­‰"
    
    def _add_basic_info(self):
        """æ·»åŠ åŸºæœ¬è³‡è¨Š"""
        self.report_lines.append("ğŸ“‹ è©³ç´°è³‡è¨Š")
        self.report_lines.append(f"\nğŸ“ æ•…éšœåœ°å€: {self.info.fault_addr}")
        
        # åˆ†ææ•…éšœåœ°å€
        addr_analysis = self._analyze_fault_address()
        if addr_analysis:
            self.report_lines.append(f"   åˆ†æ: {addr_analysis}")
        
        self.report_lines.append(f"ğŸ“Ÿ ä¿¡è™Ÿç¢¼: {self.info.signal_code}")
    
    def _analyze_fault_address(self) -> Optional[str]:
        """åˆ†ææ•…éšœåœ°å€"""
        addr = self.info.fault_addr.lower()
        
        if addr in ['0x0', '0', '00000000', '0000000000000000']:
            return "ç©ºæŒ‡é‡ - å˜—è©¦è¨ªå• NULL"
        elif addr == '0xdeadbaad':
            return "Bionic libc abort æ¨™è¨˜"
        elif addr.startswith('0xdead'):
            return "å¯èƒ½æ˜¯èª¿è©¦æ¨™è¨˜æˆ–æå£çš„æŒ‡é‡"
        elif int(addr, 16) < 0x1000:
            return "ä½åœ°å€ - å¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»"
        elif int(addr, 16) > 0x7fffffffffff:
            return "å…§æ ¸åœ°å€ç©ºé–“ - å¯èƒ½æ˜¯å…§æ ¸éŒ¯èª¤"
        
        # æª¢æŸ¥æ˜¯å¦åœ¨è¨˜æ†¶é«”æ˜ å°„ä¸­
        for mem_line in self.info.memory_map[:20]:
            if '-' in mem_line:
                parts = mem_line.split()
                if parts:
                    range_str = parts[0]
                    if '-' in range_str:
                        start, end = range_str.split('-')
                        try:
                            if int(start, 16) <= int(addr, 16) <= int(end, 16):
                                # æ‰¾åˆ°å°æ‡‰çš„è¨˜æ†¶é«”å€åŸŸ
                                if len(parts) > 6:
                                    return f"ä½æ–¼ {parts[6]}"
                        except:
                            pass
        
        return None
    
    def _add_signal_analysis(self):
        """æ·»åŠ ä¿¡è™Ÿåˆ†æ"""
        self.report_lines.append(f"\nğŸ” ä¿¡è™Ÿåˆ†æ")
        
        signal_analyses = {
            CrashSignal.SIGSEGV: [
                "è¨˜æ†¶é«”è¨ªå•é•è¦ - ç¨‹åºå˜—è©¦è¨ªå•ç„¡æ•ˆè¨˜æ†¶é«”",
                "å¸¸è¦‹åŸå› : ç©ºæŒ‡é‡ã€é‡æŒ‡é‡ã€æ•¸çµ„è¶Šç•Œã€ä½¿ç”¨å·²é‡‹æ”¾çš„è¨˜æ†¶é«”",
            ],
            CrashSignal.SIGABRT: [
                "ç¨‹åºä¸»å‹•çµ‚æ­¢ - é€šå¸¸ç”± abort() èª¿ç”¨è§¸ç™¼",
                "å¸¸è¦‹åŸå› : assert å¤±æ•—ã€æª¢æ¸¬åˆ°åš´é‡éŒ¯èª¤ã€æ‰‹å‹•èª¿ç”¨ abort",
            ],
            CrashSignal.SIGILL: [
                "éæ³•æŒ‡ä»¤ - CPU ç„¡æ³•åŸ·è¡Œçš„æŒ‡ä»¤",
                "å¸¸è¦‹åŸå› : ä»£ç¢¼æå£ã€å‡½æ•¸æŒ‡é‡éŒ¯èª¤ã€CPU æ¶æ§‹ä¸åŒ¹é…",
            ],
            CrashSignal.SIGBUS: [
                "åŒ¯æµæ’éŒ¯èª¤ - è¨˜æ†¶é«”å°é½Šæˆ–ç¡¬é«”å•é¡Œ",
                "å¸¸è¦‹åŸå› : æœªå°é½Šçš„è¨˜æ†¶é«”è¨ªå•ã€ç¡¬é«”æ•…éšœ",
            ],
            CrashSignal.SIGFPE: [
                "æµ®é»ç•°å¸¸ - æ•¸å­¸é‹ç®—éŒ¯èª¤",
                "å¸¸è¦‹åŸå› : é™¤é›¶ã€æ•´æ•¸æº¢å‡ºã€ç„¡æ•ˆçš„æµ®é»é‹ç®—",
            ],
        }
        
        analyses = signal_analyses.get(self.info.signal, ["æœªçŸ¥ä¿¡è™Ÿé¡å‹"])
        for analysis in analyses:
            self.report_lines.append(f"  â€¢ {analysis}")
    
    def _add_abort_analysis(self):
        """æ·»åŠ  abort message åˆ†æ"""
        if not self.info.abort_message:
            return
        
        self.report_lines.append(f"\nğŸ—¨ï¸ Abort Message åˆ†æ")
        self.report_lines.append(f"è¨Šæ¯: {self.info.abort_message}")
        
        # åˆ†æ abort message
        analyses = []
        
        msg_lower = self.info.abort_message.lower()
        
        if 'assert' in msg_lower:
            analyses.append("æª¢æ¸¬åˆ°æ–·è¨€å¤±æ•—")
            
            # å˜—è©¦æå–æ–‡ä»¶å’Œè¡Œè™Ÿ
            file_match = re.search(r'(\w+\.\w+):(\d+)', self.info.abort_message)
            if file_match:
                analyses.append(f"ä½ç½®: {file_match.group(1)}:{file_match.group(2)}")
        
        elif 'check failed' in msg_lower:
            analyses.append("åŸ·è¡Œæ™‚æª¢æŸ¥å¤±æ•—")
        
        elif 'fatal' in msg_lower:
            analyses.append("è‡´å‘½éŒ¯èª¤")
        
        elif 'out of memory' in msg_lower:
            analyses.append("è¨˜æ†¶é«”ä¸è¶³")
        
        elif 'stack overflow' in msg_lower:
            analyses.append("å †ç–Šæº¢å‡º")
        
        if analyses:
            self.report_lines.append("åˆ†æ:")
            for analysis in analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
    
    def _add_backtrace_analysis(self):
        """æ·»åŠ å †ç–Šåˆ†æ"""
        if not self.info.crash_backtrace:
            self.report_lines.append("\nâŒ ç„¡å´©æ½°å †ç–Šè³‡è¨Š")
            return
        
        self.report_lines.append(f"\nğŸ“š å´©æ½°å †ç–Šåˆ†æ (å…± {len(self.info.crash_backtrace)} å±¤)")
        
        # æ‰¾å‡ºå´©æ½°é»
        crash_point = self._find_crash_point()
        if crash_point:
            self.report_lines.append(f"ğŸ’¥ å´©æ½°é»: {crash_point}")
        
        # åˆ†æå †ç–Š
        stack_analyses = self._analyze_crash_stack()
        if stack_analyses:
            self.report_lines.append("\nå †ç–Šåˆ†æ:")
            for analysis in stack_analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
        
        # é¡¯ç¤ºé—œéµå †ç–Š
        self.report_lines.append("\né—œéµå †ç–Š:")
        for i, frame in enumerate(self.info.crash_backtrace[:15]):
            frame_str = self._format_frame(frame)
            marker = self._get_frame_marker_tombstone(frame)
            self.report_lines.append(f"  #{i:02d} {frame_str} {marker}")
    
    def _find_crash_point(self) -> Optional[str]:
        """æ‰¾å‡ºå´©æ½°é»"""
        for frame in self.info.crash_backtrace[:5]:
            if frame.get('symbol'):
                return f"#{frame['num']} {frame['symbol']} @ {frame['location']}"
        
        # å¦‚æœæ²’æœ‰ç¬¦è™Ÿï¼Œè¿”å›ç¬¬ä¸€å€‹æœ‰æ•ˆå¹€
        if self.info.crash_backtrace:
            frame = self.info.crash_backtrace[0]
            return f"#{frame['num']} pc {frame['pc']} @ {frame['location']}"
        
        return None
    
    def _analyze_crash_stack(self) -> List[str]:
        """åˆ†æå´©æ½°å †ç–Š"""
        analyses = []
        
        # æª¢æŸ¥è¨˜æ†¶é«”ç®¡ç†å•é¡Œ
        memory_funcs = ['malloc', 'free', 'realloc', 'calloc', 'delete', 'new']
        for frame in self.info.crash_backtrace[:10]:
            symbol = frame.get('symbol', '')
            if any(func in symbol for func in memory_funcs):
                analyses.append("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ç®¡ç†å‡½æ•¸ - å¯èƒ½æ˜¯è¨˜æ†¶é«”æå£æˆ–é›™é‡é‡‹æ”¾")
                break
        
        # æª¢æŸ¥å­—ä¸²æ“ä½œ
        string_funcs = ['strlen', 'strcpy', 'strcat', 'strcmp', 'memcpy', 'memmove']
        for frame in self.info.crash_backtrace[:10]:
            symbol = frame.get('symbol', '')
            if any(func in symbol for func in string_funcs):
                analyses.append("æª¢æ¸¬åˆ°å­—ä¸²æ“ä½œå‡½æ•¸ - å¯èƒ½æ˜¯ç·©è¡å€æº¢å‡ºæˆ–ç„¡æ•ˆæŒ‡é‡")
                break
        
        # æª¢æŸ¥ JNI
        jni_found = False
        for frame in self.info.crash_backtrace[:10]:
            location = frame.get('location', '')
            symbol = frame.get('symbol', '')
            if 'JNI' in location or 'jni' in symbol.lower():
                analyses.append("æª¢æ¸¬åˆ° JNI èª¿ç”¨ - æª¢æŸ¥ Java/Native ä»‹é¢")
                jni_found = True
                break
        
        # æª¢æŸ¥ç³»çµ±åº«
        system_libs = ['libc.so', 'libandroid_runtime.so', 'libbinder.so', 'libutils.so']
        for frame in self.info.crash_backtrace[:5]:
            location = frame.get('location', '')
            for lib in system_libs:
                if lib in location:
                    if not jni_found:  # é¿å…é‡è¤‡
                        analyses.append(f"å´©æ½°ç™¼ç”Ÿåœ¨ç³»çµ±åº« {lib}")
                    break
        
        # æª¢æŸ¥å †ç–Šæ·±åº¦
        if len(self.info.crash_backtrace) > 50:
            analyses.append(f"å †ç–Šéæ·± ({len(self.info.crash_backtrace)} å±¤) - å¯èƒ½æœ‰éè¿´æˆ–å †ç–Šæº¢å‡º")
        
        return analyses
    
    def _format_frame(self, frame: Dict) -> str:
        """æ ¼å¼åŒ–å †ç–Šå¹€"""
        pc = frame.get('pc', 'Unknown')
        location = frame.get('location', 'Unknown')
        symbol = frame.get('symbol', '')
        
        if symbol:
            return f"pc {pc} {location} ({symbol})"
        else:
            return f"pc {pc} {location}"
    
    def _get_frame_marker_tombstone(self, frame: Dict) -> str:
        """ç²å–å †ç–Šå¹€æ¨™è¨˜ (Tombstone)"""
        symbol = frame.get('symbol', '')
        location = frame.get('location', '')
        
        # è¨˜æ†¶é«”ç®¡ç†
        if any(func in symbol for func in ['malloc', 'free', 'new', 'delete']):
            return "ğŸ’¾ [è¨˜æ†¶é«”]"
        
        # å­—ä¸²æ“ä½œ
        elif any(func in symbol for func in ['strlen', 'strcpy', 'strcat']):
            return "ğŸ“ [å­—ä¸²]"
        
        # JNI
        elif 'JNI' in location or 'jni' in symbol.lower():
            return "â˜• [JNI]"
        
        # ç³»çµ±åº«
        elif 'libc.so' in location:
            return "ğŸ”§ [libc]"
        elif 'libandroid_runtime.so' in location:
            return "ğŸ¤– [Runtime]"
        elif 'libbinder.so' in location:
            return "ğŸ”— [Binder]"
        
        # å» å•†åº«
        elif 'vendor' in location:
            return "ğŸ­ [å» å•†]"
        
        # æ‡‰ç”¨åº«
        elif self.info.process_name in location:
            return "ğŸ“± [æ‡‰ç”¨]"
        
        return ""
    
    def _add_memory_analysis(self):
        """æ·»åŠ è¨˜æ†¶é«”åˆ†æ"""
        if not self.info.memory_map:
            return
        
        self.report_lines.append(f"\nğŸ’¾ è¨˜æ†¶é«”æ˜ å°„åˆ†æ (é¡¯ç¤ºå‰ 20 é …)")
        
        # åˆ†ææ•…éšœåœ°å€æ‰€åœ¨å€åŸŸ
        fault_region = self._find_fault_memory_region()
        if fault_region:
            self.report_lines.append(f"\næ•…éšœåœ°å€æ‰€åœ¨å€åŸŸ:")
            self.report_lines.append(f"  {fault_region}")
        
        # é¡¯ç¤ºé—œéµè¨˜æ†¶é«”å€åŸŸ
        self.report_lines.append("\né—œéµè¨˜æ†¶é«”å€åŸŸ:")
        for i, mem_line in enumerate(self.info.memory_map[:20]):
            if any(keyword in mem_line for keyword in [
                self.info.process_name,
                'stack',
                'heap',
                '/system/lib',
                '/vendor/lib'
            ]):
                self.report_lines.append(f"  {mem_line}")
    
    def _find_fault_memory_region(self) -> Optional[str]:
        """æ‰¾å‡ºæ•…éšœåœ°å€æ‰€åœ¨çš„è¨˜æ†¶é«”å€åŸŸ"""
        try:
            fault_addr_int = int(self.info.fault_addr, 16)
        except:
            return None
        
        for mem_line in self.info.memory_map:
            if '-' in mem_line:
                parts = mem_line.split()
                if parts:
                    range_str = parts[0]
                    if '-' in range_str:
                        start_str, end_str = range_str.split('-')
                        try:
                            start = int(start_str, 16)
                            end = int(end_str, 16)
                            if start <= fault_addr_int <= end:
                                return mem_line
                        except:
                            continue
        
        return None
    
    def _add_root_cause_analysis(self):
        """æ·»åŠ æ ¹æœ¬åŸå› åˆ†æ"""
        self.report_lines.append("\nğŸ¯ æ ¹æœ¬åŸå› åˆ†æ")
        
        # åŸºæ–¼ä¿¡è™Ÿå’Œå †ç–Šçš„ç¶œåˆåˆ†æ
        root_causes = []
        
        # ç©ºæŒ‡é‡åˆ†æ
        if self.info.signal == CrashSignal.SIGSEGV and self.info.fault_addr in ['0x0', '0', '00000000']:
            root_causes.append("ç©ºæŒ‡é‡è§£å¼•ç”¨:")
            root_causes.append("  â€¢ æª¢æŸ¥æŒ‡é‡æ˜¯å¦åœ¨ä½¿ç”¨å‰åˆå§‹åŒ–")
            root_causes.append("  â€¢ æª¢æŸ¥å‡½æ•¸è¿”å›å€¼æ˜¯å¦ç‚º NULL")
            root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æå‰é‡‹æ”¾çš„æƒ…æ³")
        
        # è¨˜æ†¶é«”æå£åˆ†æ
        elif self.info.signal == CrashSignal.SIGSEGV:
            if self.info.crash_backtrace:
                top_symbol = self.info.crash_backtrace[0].get('symbol', '')
                if any(func in top_symbol for func in ['free', 'delete']):
                    root_causes.append("å¯èƒ½çš„é›™é‡é‡‹æ”¾æˆ–ä½¿ç”¨å·²é‡‹æ”¾è¨˜æ†¶é«”:")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡ free/delete")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦åœ¨é‡‹æ”¾å¾Œç¹¼çºŒä½¿ç”¨æŒ‡é‡")
                elif any(func in top_symbol for func in ['malloc', 'new']):
                    root_causes.append("è¨˜æ†¶é«”åˆ†é…å¤±æ•—æˆ–å †æå£:")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰è¨˜æ†¶é«”æ´©æ¼")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰ç·©è¡å€æº¢å‡º")
            
            root_causes.append("è¨˜æ†¶é«”è¨ªå•é•è¦:")
            root_causes.append("  â€¢ æª¢æŸ¥æ•¸çµ„é‚Šç•Œ")
            root_causes.append("  â€¢ æª¢æŸ¥æŒ‡é‡é‹ç®—")
        
        # Abort åˆ†æ
        elif self.info.signal == CrashSignal.SIGABRT:
            if self.info.abort_message:
                if 'assert' in self.info.abort_message.lower():
                    root_causes.append("æ–·è¨€å¤±æ•—:")
                    root_causes.append("  â€¢ ç¨‹åºç‹€æ…‹ä¸ç¬¦åˆé æœŸ")
                    root_causes.append("  â€¢ æª¢æŸ¥æ–·è¨€æ¢ä»¶")
                elif 'check failed' in self.info.abort_message.lower():
                    root_causes.append("é‹è¡Œæ™‚æª¢æŸ¥å¤±æ•—:")
                    root_causes.append("  â€¢ æª¢æŸ¥å¤±æ•—çš„æ¢ä»¶")
                    root_causes.append("  â€¢ åˆ†æç‚ºä½•æœƒé”åˆ°é€™å€‹ç‹€æ…‹")
            else:
                root_causes.append("ç¨‹åºä¸»å‹•çµ‚æ­¢:")
                root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æ˜ç¢ºçš„ abort() èª¿ç”¨")
                root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æœªæ•ç²çš„ç•°å¸¸")
        
        for cause in root_causes:
            self.report_lines.append(f"  {cause}")
        
        self._add_intelligent_crash_analysis()  # æ–°å¢é€™è¡Œ
    
    def _add_intelligent_crash_analysis(self):
        """æ·»åŠ æ™ºèƒ½å´©æ½°åˆ†æ"""
        self.report_lines.append("\nğŸ§  æ™ºèƒ½å´©æ½°åˆ†æ")
        
        # åˆ†æå´©æ½°æ¨¡å¼
        crash_analysis = self.intelligent_engine.analyze_crash_pattern(self.info)
        
        # é¡¯ç¤ºå´©æ½°æµç¨‹
        if crash_analysis['crash_flow']:
            self.report_lines.append("\nğŸ“Š å´©æ½°èª¿ç”¨æµç¨‹:")
            for i, flow in enumerate(crash_analysis['crash_flow']):
                marker = "â†’" if i < len(crash_analysis['crash_flow']) - 1 else "ğŸ’¥"
                self.report_lines.append(
                    f"  {marker} #{i} pc {flow['pc']} @ {flow['location']}"
                )
                if flow['symbol']:
                    self.report_lines.append(f"      {flow['symbol']}")
                if flow['analysis'] != 'æœªçŸ¥':
                    self.report_lines.append(f"      åˆ†æ: {flow['analysis']}")
        
        # é¡¯ç¤ºè¨˜æ†¶é«”ä¸Šä¸‹æ–‡
        if crash_analysis['memory_context']:
            ctx = crash_analysis['memory_context']
            self.report_lines.append("\nğŸ’¾ è¨˜æ†¶é«”ä¸Šä¸‹æ–‡åˆ†æ:")
            
            if ctx['analysis']:
                self.report_lines.append(f"  â€¢ {ctx['analysis']}")
            
            if ctx['fault_location']:
                self.report_lines.append(f"  â€¢ å´©æ½°ä½ç½®: {ctx['fault_location']}")
            
            if ctx['nearby_regions']:
                self.report_lines.append("  â€¢ é™„è¿‘å€åŸŸ:")
                for region in ctx['nearby_regions'][:3]:
                    self.report_lines.append(f"    - {region}")
        
        # å´©æ½°ç°½å
        if crash_analysis['crash_signature']:
            self.report_lines.append(f"\nğŸ”‘ å´©æ½°ç°½å: {crash_analysis['crash_signature']}")
            self.report_lines.append("  (å¯ç”¨æ–¼æœå°‹ç›¸ä¼¼å´©æ½°)")
        
        # åŒ¹é…å·²çŸ¥æ¨¡å¼
        known_patterns = self.intelligent_engine.match_tombstone_patterns(self.info)
        if known_patterns:
            self.report_lines.append("\nğŸ¯ åŒ¹é…çš„å·²çŸ¥å´©æ½°æ¨¡å¼:")
            for pattern in known_patterns[:3]:
                self.report_lines.append(
                    f"\n  ğŸ“Œ {pattern['root_cause']} "
                    f"(ä¿¡å¿ƒåº¦: {pattern['confidence']*100:.0f}%)"
                )
                self.report_lines.append(f"     åš´é‡æ€§: {pattern['severity']}")
                self.report_lines.append("     è§£æ±ºæ–¹æ¡ˆ:")
                for solution in pattern['solutions']:
                    self.report_lines.append(f"       â€¢ {solution}")
        
        # ç›¸ä¼¼å´©æ½°å»ºè­°
        self._add_similar_crash_suggestions()
    
    def _add_similar_crash_suggestions(self):
        """æ·»åŠ ç›¸ä¼¼å´©æ½°å»ºè­°"""
        self.report_lines.append("\nğŸ” ç›¸ä¼¼å´©æ½°åˆ†æ:")
        
        # åŸºæ–¼å´©æ½°ç‰¹å¾µçµ¦å‡ºå»ºè­°
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000', '0000000000000000']:
                self.report_lines.extend([
                    "  â€¢ é€™æ˜¯å…¸å‹çš„ç©ºæŒ‡é‡å´©æ½°",
                    "  â€¢ å»ºè­°æœå°‹é¡ä¼¼çš„ç©ºæŒ‡é‡å´©æ½°æ¡ˆä¾‹",
                    "  â€¢ ä½¿ç”¨é˜²ç¦¦æ€§ç·¨ç¨‹æª¢æŸ¥æ‰€æœ‰æŒ‡é‡",
                ])
            elif int(self.info.fault_addr, 16) < 0x1000:
                self.report_lines.extend([
                    "  â€¢ ä½åœ°å€è¨ªå•ï¼Œå¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»",
                    "  â€¢ æª¢æŸ¥æ•¸çµ„æˆ–çµæ§‹é«”æˆå“¡è¨ªå•",
                ])
            else:
                self.report_lines.extend([
                    "  â€¢ è¨˜æ†¶é«”è¨ªå•é•è¦ï¼Œå¯èƒ½æ˜¯é‡æŒ‡é‡æˆ–ç·©è¡å€æº¢å‡º",
                    "  â€¢ å»ºè­°é–‹å•Ÿ AddressSanitizer (ASAN) é€²è¡Œèª¿è©¦",
                    "  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰ use-after-free æƒ…æ³",
                ])
        elif self.info.signal == CrashSignal.SIGABRT:
            self.report_lines.extend([
                "  â€¢ ä¸»å‹•çµ‚æ­¢é€šå¸¸ç”± assert æˆ–æª¢æŸ¥å¤±æ•—å¼•èµ·",
                "  â€¢ æŸ¥çœ‹ abort_message ç²å–æ›´å¤šè³‡è¨Š",
                "  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æœªæ•ç²çš„ç•°å¸¸",
            ])
        elif self.info.signal == CrashSignal.SIGSYS:
            self.report_lines.extend([
                "  â€¢ Seccomp é•è¦ - å˜—è©¦èª¿ç”¨è¢«ç¦æ­¢çš„ç³»çµ±èª¿ç”¨",
                "  â€¢ æª¢æŸ¥æ‡‰ç”¨çš„ seccomp ç­–ç•¥",
                "  â€¢ é¿å…ä½¿ç”¨å—é™çš„ç³»çµ±èª¿ç”¨",
            ])
    
    def _add_fortify_analysis(self):
        """æ·»åŠ  FORTIFY åˆ†æ"""
        fortify_info = self.intelligent_engine._analyze_fortify_failure(self.content)
        if fortify_info:
            self.report_lines.append("\nğŸ›¡ï¸ FORTIFY ä¿è­·æª¢æ¸¬")
            self.report_lines.append(f"  é¡å‹: {fortify_info['type']}")
            self.report_lines.append(f"  è¨Šæ¯: {fortify_info['message']}")
            self.report_lines.append(f"  åš´é‡æ€§: {fortify_info['severity']}")
            self.report_lines.append(f"  å»ºè­°: {fortify_info['suggestion']}")
            self.report_lines.append("  å¸¸è¦‹åŸå› :")
            self.report_lines.append("    â€¢ ç·©è¡å€æº¢å‡º")
            self.report_lines.append("    â€¢ å­—ä¸²æ“ä½œè¶Šç•Œ")
            self.report_lines.append("    â€¢ æ ¼å¼åŒ–å­—ä¸²æ¼æ´")
    
    def _add_symbol_resolution_guide(self):
        """æ·»åŠ ç¬¦è™Ÿè§£ææŒ‡å—"""
        self.report_lines.append("\nğŸ”§ ç¬¦è™Ÿè§£ææŒ‡å—")
        
        # ç”Ÿæˆ addr2line å‘½ä»¤
        addr2line_cmds = self._generate_addr2line_commands(self.info)
        if addr2line_cmds:
            self.report_lines.append("\nğŸ“ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è§£æè©³ç´°ç¬¦è™Ÿ:")
            for i, cmd in enumerate(addr2line_cmds[:5], 1):
                self.report_lines.append(f"  {i}. {cmd}")
            
            if len(addr2line_cmds) > 5:
                self.report_lines.append(f"  ... é‚„æœ‰ {len(addr2line_cmds) - 5} å€‹å‘½ä»¤")
        
        # æä¾› ndk-stack ä½¿ç”¨å»ºè­°
        self.report_lines.append("\nğŸ’¡ æˆ–ä½¿ç”¨ ndk-stack å·¥å…·:")
        self.report_lines.append("  $ ndk-stack -sym <path-to-symbols> -dump <tombstone-file>")
        
        # ç¬¦è™Ÿæ–‡ä»¶ä½ç½®æç¤º
        self.report_lines.append("\nğŸ“‚ ç¬¦è™Ÿæ–‡ä»¶é€šå¸¸ä½æ–¼:")
        self.report_lines.append("  â€¢ æœ¬åœ°ç·¨è­¯: out/target/product/*/symbols/")
        self.report_lines.append("  â€¢ NDK æ‡‰ç”¨: app/build/intermediates/cmake/*/obj/")
        self.report_lines.append("  â€¢ ç³»çµ±åº«: éœ€è¦å°æ‡‰ç‰ˆæœ¬çš„ symbols.zip")
    
    def _generate_addr2line_commands(self, tombstone_info: TombstoneInfo) -> List[str]:
        """ç”Ÿæˆ addr2line å‘½ä»¤ä¾›é–‹ç™¼è€…ä½¿ç”¨"""
        commands = []
        seen_libs = set()
        
        for frame in tombstone_info.crash_backtrace:
            location = frame.get('location', '')
            pc = frame.get('pc', '')
            
            # åªç‚º .so æ–‡ä»¶ç”Ÿæˆå‘½ä»¤
            if '.so' in location and location not in seen_libs:
                seen_libs.add(location)
                
                # åˆ¤æ–·æ¶æ§‹
                if 'arm64' in self.content or 'aarch64' in self.content:
                    prefix = "aarch64-linux-android-"
                elif 'arm' in self.content:
                    prefix = "arm-linux-androideabi-"
                elif 'x86_64' in self.content:
                    prefix = "x86_64-linux-android-"
                else:
                    prefix = "i686-linux-android-"
                
                cmd = f"{prefix}addr2line -C -f -e {location} {pc}"
                commands.append(cmd)
        
        return commands
    
    def _add_backtrace_analysis(self):
        """æ·»åŠ å †ç–Šåˆ†æ - å¢å¼·ç‰ˆ"""
        if not self.info.crash_backtrace:
            self.report_lines.append("\nâŒ ç„¡å´©æ½°å †ç–Šè³‡è¨Š")
            return
        
        self.report_lines.append(f"\nğŸ“š å´©æ½°å †ç–Šåˆ†æ (å…± {len(self.info.crash_backtrace)} å±¤)")
        
        # æ‰¾å‡ºå´©æ½°é»
        crash_point = self._find_crash_point()
        if crash_point:
            self.report_lines.append(f"ğŸ’¥ å´©æ½°é»: {crash_point}")
        
        # åˆ†æå †ç–Š
        stack_analyses = self._analyze_crash_stack()
        if stack_analyses:
            self.report_lines.append("\nå †ç–Šåˆ†æ:")
            for analysis in stack_analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
        
        # é¡¯ç¤ºé—œéµå †ç–Š
        self.report_lines.append("\né—œéµå †ç–Š:")
        for i, frame in enumerate(self.info.crash_backtrace[:15]):
            frame_str = self._format_frame(frame)
            marker = self._get_frame_marker_tombstone(frame)
            self.report_lines.append(f"  #{i:02d} {frame_str} {marker}")
            
            # å°é—œéµå¹€æ·»åŠ é¡å¤–åˆ†æ
            if i < 5 and not frame.get('symbol'):
                self.report_lines.append(f"      ğŸ’¡ æç¤º: ä½¿ç”¨ addr2line è§£æç¬¦è™Ÿ")
    
    def _generate_suggestions(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå»ºè­° - å¢å¼·ç‰ˆ"""
        suggestions = {
            'debugging': [],
            'fixing': [],
            'prevention': []
        }
        
        # èª¿è©¦å»ºè­°
        suggestions['debugging'].extend([
            "ä½¿ç”¨ addr2line å·¥å…·è§£æè©³ç´°çš„æºç¢¼ä½ç½®",
            "åœ¨ Android Studio ä¸­ä½¿ç”¨ LLDB èª¿è©¦å™¨é‡ç¾å•é¡Œ",
            "é–‹å•Ÿ AddressSanitizer (ASAN) æª¢æ¸¬è¨˜æ†¶é«”éŒ¯èª¤",
            "æ”¶é›† coredump é€²è¡Œé›¢ç·šåˆ†æ",
        ])
        
        # åŸºæ–¼å´©æ½°é¡å‹çš„å»ºè­°
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000']:
                suggestions['fixing'].extend([
                    "æª¢æŸ¥æ‰€æœ‰æŒ‡é‡ä½¿ç”¨å‰æ˜¯å¦ç‚º NULL",
                    "ç‚ºæŒ‡é‡æ·»åŠ é˜²ç¦¦æ€§æª¢æŸ¥",
                    "ä½¿ç”¨æ™ºèƒ½æŒ‡é‡ (å¦‚ std::unique_ptr, std::shared_ptr)",
                    "å•Ÿç”¨ç·¨è­¯å™¨çš„ -Wnull-dereference è­¦å‘Š",
                ])
            else:
                suggestions['fixing'].extend([
                    "æª¢æŸ¥æ•¸çµ„é‚Šç•Œè¨ªå•",
                    "ä½¿ç”¨ valgrind æˆ– ASAN æª¢æ¸¬è¨˜æ†¶é«”å•é¡Œ",
                    "æª¢æŸ¥å¤šç·šç¨‹ä¸‹çš„è¨˜æ†¶é«”è¨ªå•ç«¶çˆ­",
                    "ç¢ºèªè¨˜æ†¶é«”å°é½Šè¦æ±‚",
                ])
        
        elif self.info.signal == CrashSignal.SIGABRT:
            suggestions['fixing'].extend([
                "æª¢æŸ¥ assert æ¢ä»¶æ˜¯å¦åˆç†",
                "æ·»åŠ æ›´å¤šçš„éŒ¯èª¤è™•ç†å’Œæ¢å¾©æ©Ÿåˆ¶",
                "ä½¿ç”¨ try-catch æ•ç² C++ ç•°å¸¸",
                "æª¢æŸ¥æ˜¯å¦æœ‰è³‡æºè€—ç›¡ï¼ˆå¦‚è¨˜æ†¶é«”ã€æ–‡ä»¶å¥æŸ„ï¼‰",
            ])
        
        elif self.info.signal == CrashSignal.SIGSYS:
            suggestions['fixing'].extend([
                "æª¢æŸ¥ seccomp ç­–ç•¥é…ç½®",
                "é¿å…ä½¿ç”¨è¢«é™åˆ¶çš„ç³»çµ±èª¿ç”¨",
                "æ›´æ–°åˆ°æ”¯æ´çš„ API èª¿ç”¨æ–¹å¼",
            ])
        
        # JNI ç›¸é—œ
        if any('JNI' in frame.get('location', '') or 'jni' in frame.get('symbol', '').lower() 
               for frame in self.info.crash_backtrace[:10]):
            suggestions['fixing'].extend([
                "æª¢æŸ¥ JNI èª¿ç”¨çš„åƒæ•¸æœ‰æ•ˆæ€§",
                "ç¢ºä¿ JNI å±€éƒ¨å¼•ç”¨æ­£ç¢ºç®¡ç† (ä½¿ç”¨ NewLocalRef/DeleteLocalRef)",
                "æª¢æŸ¥ Java å’Œ Native ä¹‹é–“çš„æ•¸æ“šé¡å‹åŒ¹é…",
                "é©—è­‰ JNI æ–¹æ³•ç°½åæ­£ç¢ºæ€§",
                "ä½¿ç”¨ CheckJNI æ¨¡å¼èª¿è©¦ (-Xcheck:jni)",
            ])
        
        # é é˜²å»ºè­°
        suggestions['prevention'].extend([
            "ä½¿ç”¨éœæ…‹åˆ†æå·¥å…· (å¦‚ Clang Static Analyzer, PVS-Studio)",
            "ç·¨å¯«å–®å…ƒæ¸¬è©¦è¦†è“‹é‚Šç•Œæƒ…æ³",
            "ä½¿ç”¨ Code Review æª¢æŸ¥è¨˜æ†¶é«”ç®¡ç†",
            "é–‹å•Ÿç·¨è­¯å™¨çš„æ‰€æœ‰è­¦å‘Š (-Wall -Wextra -Werror)",
            "ä½¿ç”¨ Sanitizers é€²è¡ŒæŒçºŒæ¸¬è©¦ (ASAN, TSAN, UBSAN)",
            "å¯¦æ–½ FORTIFY_SOURCE ä¿è­·",
            "å®šæœŸé€²è¡Œ Fuzzing æ¸¬è©¦",
        ])
        
        # ç³»çµ±åº«å´©æ½°
        if any(lib in frame.get('location', '') for frame in self.info.crash_backtrace[:3]
               for lib in ['libc.so', 'libandroid_runtime.so']):
            suggestions['debugging'].append("æ”¶é›†å®Œæ•´çš„ bugreport åˆ†æç³»çµ±ç‹€æ…‹")
            suggestions['fixing'].append("æª¢æŸ¥æ˜¯å¦æœ‰ç³»çµ±è³‡æºè€—ç›¡")
            suggestions['fixing'].append("é©—è­‰ API èª¿ç”¨åƒæ•¸çš„æœ‰æ•ˆæ€§")
        
        return suggestions


# ============= åˆ†æå™¨å·¥å»  =============

class AnalyzerFactory:
    """åˆ†æå™¨å·¥å» """
    
    @staticmethod
    def create_analyzer(file_type: str) -> BaseAnalyzer:
        """å‰µå»ºåˆ†æå™¨"""
        if file_type.lower() == "anr":
            return ANRAnalyzer()
        elif file_type.lower() in ["tombstone", "tombstones"]:
            return TombstoneAnalyzer()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {file_type}")


# ============= ä¸»ç¨‹å¼ =============

class LogAnalyzerSystem:
    """æ—¥èªŒåˆ†æç³»çµ±"""
    
    def __init__(self, input_folder: str, output_folder: str):
        self.input_folder = input_folder
        self.output_folder = output_folder
        self.stats = {
            'anr_count': 0,
            'tombstone_count': 0,
            'error_count': 0,
            'total_time': 0,
        }
    
    def analyze(self):
        """åŸ·è¡Œåˆ†æ"""
        start_time = time.time()
        
        print("ğŸš€ å•Ÿå‹•é€²éšç‰ˆ ANR/Tombstone åˆ†æç³»çµ±...")
        print(f"ğŸ“‚ è¼¸å…¥è³‡æ–™å¤¾: {self.input_folder}")
        print(f"ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾: {self.output_folder}")
        print("")
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(self.output_folder, exist_ok=True)
        
        # æƒææª”æ¡ˆ
        files_to_analyze = self._scan_files()
        print(f"ğŸ“Š æ‰¾åˆ° {len(files_to_analyze)} å€‹æª”æ¡ˆéœ€è¦åˆ†æ")
        print("")
        
        # åˆ†ææª”æ¡ˆ
        index_data = {}
        for file_info in files_to_analyze:
            try:
                self._analyze_file(file_info, index_data)
            except Exception as e:
                print(f"âŒ åˆ†æ {file_info['path']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                self.stats['error_count'] += 1
        
        # ç”Ÿæˆç´¢å¼•
        self._generate_index(index_data)
        
        # é¡¯ç¤ºçµ±è¨ˆ
        self.stats['total_time'] = time.time() - start_time
        self._show_statistics()
    
    def _scan_files(self) -> List[Dict]:
        """æƒææª”æ¡ˆ"""
        files = []
        
        for root, dirs, filenames in os.walk(self.input_folder):
            base_dir = os.path.basename(root).lower()
            
            if base_dir in ["anr", "tombstones", "tombstone"]:
                for filename in filenames:
                    # è·³éç‰¹å®šæª”æ¡ˆ
                    if filename.endswith('.pb') or filename.endswith('.txt.analyzed'):
                        continue
                    
                    file_path = os.path.join(root, filename)
                    file_type = "anr" if base_dir == "anr" else "tombstone"
                    
                    files.append({
                        'path': file_path,
                        'type': file_type,
                        'name': filename,
                        'rel_path': os.path.relpath(file_path, self.input_folder)
                    })
        
        return files
    
    def _analyze_file(self, file_info: Dict, index_data: Dict):
        """åˆ†æå–®å€‹æª”æ¡ˆ"""
        print(f"ğŸ” åˆ†æ {file_info['type'].upper()}: {file_info['name']}")
        
        # å‰µå»ºåˆ†æå™¨
        analyzer = AnalyzerFactory.create_analyzer(file_info['type'])
        
        # åŸ·è¡Œåˆ†æ
        result = analyzer.analyze(file_info['path'])
        
        # ä¿å­˜çµæœ
        output_dir = os.path.join(self.output_folder, os.path.dirname(file_info['rel_path']))
        os.makedirs(output_dir, exist_ok=True)
        
        output_file = os.path.join(output_dir, file_info['name'] + '.analyzed.txt')
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result)
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        original_copy = os.path.join(output_dir, file_info['name'])
        shutil.copy2(file_info['path'], original_copy)
        
        # æ›´æ–°ç´¢å¼•
        self._update_index(index_data, file_info['rel_path'], output_file, original_copy)
        
        # æ›´æ–°çµ±è¨ˆ
        if file_info['type'] == 'anr':
            self.stats['anr_count'] += 1
        else:
            self.stats['tombstone_count'] += 1
    
    def _update_index(self, index_data: Dict, rel_path: str, analyzed_file: str, original_file: str):
        """æ›´æ–°ç´¢å¼•"""
        parts = rel_path.split(os.sep)
        current = index_data
        
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]
        
        filename = parts[-1]
        current[filename + '.analyzed.txt'] = {
            'analyzed_file': analyzed_file,
            'original_file': original_file
        }
    
    def _generate_index(self, index_data: Dict):
        """ç”Ÿæˆ HTML ç´¢å¼•"""
        html_content = self._generate_html_index(index_data)
        
        index_file = os.path.join(self.output_folder, 'index.html')
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"\nğŸ“ å·²ç”Ÿæˆç´¢å¼•æª”æ¡ˆ: {index_file}")
    
    def _generate_html_index(self, index_data: Dict) -> str:
        """ç”Ÿæˆ HTML ç´¢å¼•å…§å®¹"""
        def render_tree(data, prefix=""):
            html_str = "<ul>"
            for name, value in sorted(data.items()):
                if isinstance(value, dict) and 'analyzed_file' in value:
                    # æª”æ¡ˆé …ç›®
                    analyzed_rel = os.path.relpath(value['analyzed_file'], self.output_folder)
                    original_rel = os.path.relpath(value['original_file'], self.output_folder)
                    
                    html_str += f'<li class="file-item">'
                    html_str += f'<span class="file-icon">ğŸ“„</span>'
                    html_str += f'<a href="{html.escape(analyzed_rel)}" target="_blank" class="analyzed-link">{html.escape(name)}</a>'
                    html_str += f'<span class="source-link">'
                    html_str += f'(<a href="{html.escape(original_rel)}" target="_blank">åŸå§‹æª”æ¡ˆ</a>)'
                    html_str += f'</span>'
                    html_str += f'</li>'
                elif isinstance(value, dict):
                    # ç›®éŒ„é …ç›®
                    html_str += f'<li class="folder">'
                    html_str += f'<span class="folder-icon">ğŸ“</span>'
                    html_str += f'<strong>{html.escape(name)}</strong>'
                    html_str += render_tree(value, prefix + '/' + name)
                    html_str += f'</li>'
            html_str += "</ul>"
            return html_str
        
        return f"""<!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <title>é€²éšç‰ˆ Android Log åˆ†æå ±å‘Š v5 - æ™ºèƒ½åˆ†æç³»çµ±</title>
        <style>
            * {{
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }}
            
            body {{
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                padding: 20px;
            }}
            
            .container {{
                max-width: 1400px;
                margin: 0 auto;
            }}
            
            .header {{
                background: rgba(255, 255, 255, 0.95);
                border-radius: 20px;
                padding: 40px;
                margin-bottom: 30px;
                box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                backdrop-filter: blur(10px);
                position: relative;
                overflow: hidden;
            }}
            
            .header::before {{
                content: "";
                position: absolute;
                top: -50%;
                right: -50%;
                width: 200%;
                height: 200%;
                background: radial-gradient(circle, rgba(102, 126, 234, 0.1) 0%, transparent 70%);
                animation: pulse 4s ease-in-out infinite;
            }}
            
            @keyframes pulse {{
                0%, 100% {{ transform: scale(1); }}
                50% {{ transform: scale(1.1); }}
            }}
            
            h1 {{
                color: #2d3748;
                margin: 0 0 20px 0;
                font-size: 3em;
                font-weight: 800;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                position: relative;
                z-index: 1;
            }}
            
            .subtitle {{
                color: #4a5568;
                font-size: 1.2em;
                margin-bottom: 30px;
                position: relative;
                z-index: 1;
            }}
            
            .stats {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 20px;
                margin-top: 30px;
                position: relative;
                z-index: 1;
            }}
            
            .stat-card {{
                background: linear-gradient(135deg, #f5f7fa 0%, #e9ecef 100%);
                padding: 25px;
                border-radius: 15px;
                box-shadow: 0 5px 15px rgba(0,0,0,0.08);
                transition: all 0.3s ease;
                position: relative;
                overflow: hidden;
            }}
            
            .stat-card::before {{
                content: "";
                position: absolute;
                top: 0;
                left: 0;
                width: 5px;
                height: 100%;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                transition: width 0.3s ease;
            }}
            
            .stat-card:hover {{
                transform: translateY(-5px);
                box-shadow: 0 10px 30px rgba(0,0,0,0.15);
            }}
            
            .stat-card:hover::before {{
                width: 100%;
                opacity: 0.1;
            }}
            
            .stat-card h3 {{
                margin: 0 0 10px 0;
                color: #4a5568;
                font-size: 0.9em;
                text-transform: uppercase;
                letter-spacing: 1px;
                position: relative;
                z-index: 1;
            }}
            
            .stat-card .value {{
                font-size: 2.5em;
                font-weight: 700;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                position: relative;
                z-index: 1;
            }}
            
            .content {{
                background: rgba(255, 255, 255, 0.95);
                border-radius: 20px;
                padding: 40px;
                box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                backdrop-filter: blur(10px);
            }}
            
            .content h2 {{
                color: #2d3748;
                margin-bottom: 30px;
                font-size: 2em;
                display: flex;
                align-items: center;
                gap: 10px;
            }}
            
            ul {{
                list-style: none;
                padding-left: 0;
            }}
            
            li {{
                margin: 12px 0;
                padding: 15px 20px;
                background: #f8f9fa;
                border-radius: 10px;
                transition: all 0.3s ease;
                display: flex;
                align-items: center;
                gap: 10px;
            }}
            
            li:hover {{
                background: #e9ecef;
                transform: translateX(5px);
            }}
            
            li.folder {{
                background: transparent;
                padding: 10px 0;
                flex-direction: column;
                align-items: flex-start;
            }}
            
            li.folder > strong {{
                color: #4a5568;
                font-size: 1.2em;
                margin-bottom: 10px;
                display: flex;
                align-items: center;
                gap: 10px;
            }}
            
            li.folder ul {{
                width: 100%;
                margin-top: 10px;
                padding-left: 30px;
            }}
            
            .file-icon, .folder-icon {{
                font-size: 1.2em;
            }}
            
            a {{
                color: #667eea;
                text-decoration: none;
                font-weight: 500;
                transition: all 0.3s ease;
                position: relative;
            }}
            
            a::after {{
                content: "";
                position: absolute;
                bottom: -2px;
                left: 0;
                width: 0;
                height: 2px;
                background: #667eea;
                transition: width 0.3s ease;
            }}
            
            a:hover {{
                color: #764ba2;
            }}
            
            a:hover::after {{
                width: 100%;
            }}
            
            .analyzed-link {{
                flex: 1;
            }}
            
            .source-link {{
                color: #718096;
                font-size: 0.9em;
                margin-left: auto;
            }}
            
            .source-link a {{
                color: #718096;
            }}
            
            .source-link a:hover {{
                color: #4a5568;
            }}
            
            .features {{
                background: linear-gradient(135deg, #e0e7ff 0%, #d8b4fe 100%);
                border-radius: 15px;
                padding: 30px;
                margin: 30px 0;
                position: relative;
                z-index: 1;
            }}
            
            .features h3 {{
                color: #5b21b6;
                margin-bottom: 20px;
                font-size: 1.5em;
                display: flex;
                align-items: center;
                gap: 10px;
            }}
            
            .features ul {{
                margin: 0;
                padding-left: 25px;
            }}
            
            .features li {{
                list-style-type: disc;
                margin: 10px 0;
                padding: 5px 0;
                background: transparent;
                color: #4c1d95;
                font-weight: 500;
            }}
            
            .features li:hover {{
                transform: none;
            }}
            
            .timestamp {{
                color: #718096;
                font-size: 0.9em;
                margin-top: 20px;
                position: relative;
                z-index: 1;
            }}
            
            /* å‹•ç•«æ•ˆæœ */
            @keyframes fadeIn {{
                from {{
                    opacity: 0;
                    transform: translateY(20px);
                }}
                to {{
                    opacity: 1;
                    transform: translateY(0);
                }}
            }}
            
            .stat-card {{
                animation: fadeIn 0.6s ease-out forwards;
            }}
            
            .stat-card:nth-child(2) {{
                animation-delay: 0.1s;
            }}
            
            .stat-card:nth-child(3) {{
                animation-delay: 0.2s;
            }}
            
            .stat-card:nth-child(4) {{
                animation-delay: 0.3s;
            }}
            
            /* éŸ¿æ‡‰å¼è¨­è¨ˆ */
            @media (max-width: 768px) {{
                .container {{
                    padding: 10px;
                }}
                
                h1 {{
                    font-size: 2em;
                }}
                
                .header, .content {{
                    padding: 20px;
                }}
                
                .stats {{
                    grid-template-columns: 1fr;
                }}
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸš€ é€²éšç‰ˆ Android Log åˆ†æå ±å‘Š v5</h1>
                <p class="subtitle">åŸºæ–¼ç‰©ä»¶å°å‘è¨­è¨ˆçš„æ™ºèƒ½åˆ†æç³»çµ±ï¼Œæ·±åº¦è§£æå•é¡Œçš„ä¾†é¾å»è„ˆ</p>
                
                <div class="stats">
                    <div class="stat-card">
                        <h3>ANR æª”æ¡ˆ</h3>
                        <div class="value">{self.stats['anr_count']}</div>
                    </div>
                    <div class="stat-card">
                        <h3>Tombstone æª”æ¡ˆ</h3>
                        <div class="value">{self.stats['tombstone_count']}</div>
                    </div>
                    <div class="stat-card">
                        <h3>ç¸½æª”æ¡ˆæ•¸</h3>
                        <div class="value">{self.stats['anr_count'] + self.stats['tombstone_count']}</div>
                    </div>
                    <div class="stat-card">
                        <h3>åˆ†ææ™‚é–“</h3>
                        <div class="value">{self.stats['total_time']:.1f}s</div>
                    </div>
                </div>
                
                <div class="features">
                    <h3>ğŸ¯ æ™ºèƒ½åˆ†æç‰¹é»</h3>
                    <ul>
                        <li>æ™ºèƒ½è­˜åˆ¥å•é¡Œçš„å®Œæ•´èª¿ç”¨éˆå’Œä¾†é¾å»è„ˆ</li>
                        <li>æ·±åº¦åˆ†æ Binder IPC é˜»å¡å’Œæœå‹™äº¤äº’</li>
                        <li>è‡ªå‹•åŒ¹é…å·²çŸ¥å•é¡Œæ¨¡å¼åº«</li>
                        <li>æä¾›äº‹ä»¶æ™‚åºåˆ†æå’Œæ ¹æœ¬åŸå› å®šä½</li>
                        <li>WebView ç›¸é—œ ANR çš„å°ˆé–€åˆ†æ</li>
                        <li>system_server å¥åº·ç‹€æ…‹è©•ä¼°</li>
                        <li>åŸºæ–¼ AI çš„è§£æ±ºæ–¹æ¡ˆæ¨è–¦</li>
                        <li>æ”¯æ´æ‰€æœ‰ Android ç‰ˆæœ¬ (4.x - 14)</li>
                        <li>ç²¾ç¢ºçš„å´©æ½°é»å®šä½å’Œè¨˜æ†¶é«”åˆ†æ</li>
                        <li>è¦–è¦ºåŒ–çš„å•é¡Œåš´é‡æ€§è©•ç´š</li>
                    </ul>
                </div>
                
                <p class="timestamp"><strong>ç”Ÿæˆæ™‚é–“:</strong> {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="content">
                <h2>ğŸ“ åˆ†æçµæœ</h2>
                {render_tree(index_data)}
            </div>
        </div>
    </body>
    </html>"""
    
    def _show_statistics(self):
        """é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š"""
        print("\n" + "=" * 60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("=" * 60)
        
        print(f"\nğŸ“Š åˆ†æçµ±è¨ˆ:")
        print(f"  â€¢ ANR æª”æ¡ˆ: {self.stats['anr_count']} å€‹")
        print(f"  â€¢ Tombstone æª”æ¡ˆ: {self.stats['tombstone_count']} å€‹")
        print(f"  â€¢ éŒ¯èª¤æ•¸é‡: {self.stats['error_count']} å€‹")
        print(f"  â€¢ ç¸½åŸ·è¡Œæ™‚é–“: {self.stats['total_time']:.2f} ç§’")
        
        if self.stats['anr_count'] + self.stats['tombstone_count'] > 0:
            avg_time = self.stats['total_time'] / (self.stats['anr_count'] + self.stats['tombstone_count'])
            print(f"  â€¢ å¹³å‡è™•ç†æ™‚é–“: {avg_time:.3f} ç§’/æª”æ¡ˆ")
        
        print(f"\nğŸ¯ è¼¸å‡ºç›®éŒ„: {self.output_folder}")
        print(f"ğŸŒ è«‹é–‹å•Ÿ {os.path.join(self.output_folder, 'index.html')} æŸ¥çœ‹åˆ†æå ±å‘Š")

# ============= æ™ºèƒ½åˆ†æå¼•æ“ =============
class IntelligentAnalysisEngine:
    """æ™ºèƒ½åˆ†æå¼•æ“ - ç”¨æ–¼æ·±åº¦åˆ†æå•é¡Œçš„ä¾†é¾å»è„ˆ"""
    
    def __init__(self):
        self.analysis_patterns = self._init_analysis_patterns()
        self.known_issues_db = self._init_known_issues()
    
    def _get_health_recommendation(self, score: int) -> str:
        """æ ¹æ“šå¥åº·åˆ†æ•¸æä¾›å»ºè­°"""
        if score >= 80:
            return "ç³»çµ±é‹è¡Œæ­£å¸¸ï¼Œç¹¼çºŒä¿æŒ"
        elif score >= 60:
            return "ç³»çµ±æœ‰è¼•å¾®å£“åŠ›ï¼Œå»ºè­°å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"
        elif score >= 40:
            return "ç³»çµ±å£“åŠ›è¼ƒå¤§ï¼Œéœ€è¦ç«‹å³å„ªåŒ–"
        else:
            return "ç³»çµ±åš´é‡ç•°å¸¸ï¼Œéœ€è¦ç·Šæ€¥è™•ç†"
            
    def _init_analysis_patterns(self) -> Dict:
        """åˆå§‹åŒ–åˆ†ææ¨¡å¼åº«"""
        return {
            'binder_deadlock_patterns': {
                'windowmanager_timeout': {
                    'signatures': [
                        'BinderProxy.transactNative',
                        'WindowManager.*getWindowInsets',
                        'system_server.*block'
                    ],
                    'root_cause': 'WindowManager æœå‹™é˜»å¡',
                    'severity': 'critical',
                    'solutions': [
                        'æª¢æŸ¥ system_server è² è¼‰å’Œ GC ç‹€æ³',
                        'åˆ†æ WindowManager æœå‹™æ˜¯å¦æœ‰æ­»é–',
                        'æŸ¥çœ‹åŒæ™‚é–“çš„å…¶ä»– Binder èª¿ç”¨'
                    ]
                },
                'webview_anr': {
                    'signatures': [
                        'chromium.*WebView',
                        'onDisplayChanged',
                        'WindowMetricsController'
                    ],
                    'root_cause': 'WebView æ¸²æŸ“å¼•æ“é˜»å¡',
                    'severity': 'high',
                    'solutions': [
                        'æª¢æŸ¥ WebView ç‰ˆæœ¬å’Œç›¸å®¹æ€§',
                        'åˆ†æ WebView æ¸²æŸ“ç·šç¨‹ç‹€æ…‹',
                        'è€ƒæ…®å»¶é²æˆ–ç•°æ­¥è¼‰å…¥ WebView'
                    ]
                }
            },
            'system_service_patterns': {
                'input_timeout': {
                    'signatures': [
                        'Input dispatching timed out',
                        'Waited.*ms for',
                        'FocusEvent.*hasFocus'
                    ],
                    'root_cause': 'Input äº‹ä»¶åˆ†ç™¼è¶…æ™‚',
                    'severity': 'critical',
                    'solutions': [
                        'æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦æœ‰è€—æ™‚æ“ä½œ',
                        'åˆ†æ InputDispatcher ç‹€æ…‹',
                        'æŸ¥çœ‹æ˜¯å¦æœ‰ Window focus åˆ‡æ›å•é¡Œ'
                    ]
                }
            }
        }
    
    def _init_known_issues(self) -> Dict:
        """åˆå§‹åŒ–å·²çŸ¥å•é¡Œè³‡æ–™åº«"""
        return {
            # é€šç”¨çš„å·²çŸ¥å•é¡Œæ¨¡å¼ï¼Œè€Œéç‰¹å®šè¨­å‚™
            'webview_display_change_anr': {
                'patterns': [
                    'WebView.*onDisplayChanged',
                    'WindowManager.*getWindowInsets',
                    'chromium.*TrichroneWebView'
                ],
                'description': 'WebView åœ¨é¡¯ç¤ºé…ç½®è®Šæ›´æ™‚çš„ ANR',
                'affected_versions': ['Android 10+', 'WebView 83+'],
                'workarounds': [
                    'å»¶é² WebView åˆå§‹åŒ–',
                    'ä½¿ç”¨ç•°æ­¥è¼‰å…¥',
                    'é¿å…åœ¨ onDisplayChanged ä¸­é€²è¡ŒåŒæ­¥æ“ä½œ'
                ]
            },
            'system_server_overload': {
                'patterns': [
                    'system_server.*block',
                    'InputDispatcher.*timed out',
                    'Waited.*ms for.*system_server'
                ],
                'description': 'system_server éè¼‰å°è‡´çš„ ANR',
                'affected_versions': ['æ‰€æœ‰ Android ç‰ˆæœ¬'],
                'workarounds': [
                    'æ¸›å°‘åŒæ™‚é€²è¡Œçš„ç³»çµ±æœå‹™èª¿ç”¨',
                    'ä½¿ç”¨æ‰¹é‡æ“ä½œ',
                    'å¯¦æ–½é‡è©¦æ©Ÿåˆ¶'
                ]
            },
            'binder_transaction_limit': {
                'patterns': [
                    'TransactionTooLargeException',
                    'Binder transaction.*too large',
                    'data parcel size.*bytes'
                ],
                'description': 'Binder äº‹å‹™å¤§å°è¶…é™',
                'affected_versions': ['æ‰€æœ‰ Android ç‰ˆæœ¬'],
                'workarounds': [
                    'æ¸›å°‘å–®æ¬¡å‚³è¼¸çš„æ•¸æ“šé‡',
                    'åˆ†æ‰¹å‚³è¼¸å¤§æ•¸æ“š',
                    'ä½¿ç”¨ ContentProvider æˆ–æ–‡ä»¶å‚³è¼¸'
                ]
            }
        }
    
    def analyze_call_chain(self, backtrace: List[str]) -> Dict:
        """åˆ†æèª¿ç”¨éˆï¼Œæ‰¾å‡ºå•é¡Œçš„å®Œæ•´è„ˆçµ¡"""
        analysis = {
            'call_flow': [],
            'blocking_points': [],
            'service_interactions': [],
            'potential_causes': []
        }
        
        # å»ºç«‹èª¿ç”¨æµç¨‹åœ–
        for i, frame in enumerate(backtrace):
            # æå–é—œéµè³‡è¨Š
            if 'BinderProxy' in frame:
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'IPC',
                    'detail': 'Binder IPC èª¿ç”¨',
                    'target': self._extract_binder_target(frame, backtrace[i:i+3])
                })
            elif 'WindowManager' in frame:
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'System Service',
                    'detail': 'WindowManager æœå‹™èª¿ç”¨',
                    'method': self._extract_method_name(frame)
                })
            elif 'WebView' in frame or 'chromium' in frame.lower():
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'WebView',
                    'detail': 'WebView å…ƒä»¶',
                    'action': self._extract_webview_action(frame)
                })
        
        # è­˜åˆ¥é˜»å¡é»
        analysis['blocking_points'] = self._identify_blocking_points(backtrace)
        
        # åˆ†ææœå‹™äº¤äº’
        analysis['service_interactions'] = self._analyze_service_interactions(backtrace)
        
        return analysis
    
    def _extract_binder_target(self, frame: str, context_frames: List[str]) -> str:
        """æå– Binder èª¿ç”¨çš„ç›®æ¨™æœå‹™"""
        # å¾å¾ŒçºŒå¹€ä¸­æ‰¾å‡ºç›®æ¨™æœå‹™
        for ctx_frame in context_frames[1:]:
            if 'WindowManager' in ctx_frame:
                return 'WindowManagerService'
            elif 'ActivityManager' in ctx_frame:
                return 'ActivityManagerService'
            elif 'PackageManager' in ctx_frame:
                return 'PackageManagerService'
        return 'Unknown Service'
    
    def _extract_method_name(self, frame: str) -> str:
        """æå–æ–¹æ³•åç¨±"""
        match = re.search(r'\.(\w+)\(', frame)
        return match.group(1) if match else 'Unknown'
    
    def _extract_webview_action(self, frame: str) -> str:
        """æå– WebView ç›¸é—œå‹•ä½œ"""
        if 'onDisplayChanged' in frame:
            return 'é¡¯ç¤ºé…ç½®è®Šæ›´'
        elif 'loadUrl' in frame:
            return 'è¼‰å…¥ URL'
        elif 'onDraw' in frame:
            return 'æ¸²æŸ“ç¹ªè£½'
        return 'å…¶ä»–æ“ä½œ'
    
    def _identify_blocking_points(self, backtrace: List[str]) -> List[Dict]:
        """è­˜åˆ¥é˜»å¡é»"""
        blocking_points = []
        
        for i, frame in enumerate(backtrace[:10]):
            if 'Native method' in frame or 'transactNative' in frame:
                blocking_points.append({
                    'level': i,
                    'type': 'Native é˜»å¡',
                    'description': 'åœ¨ Native å±¤ç­‰å¾…',
                    'severity': 'high'
                })
            elif 'wait' in frame.lower() or 'park' in frame.lower():
                blocking_points.append({
                    'level': i,
                    'type': 'ç·šç¨‹ç­‰å¾…',
                    'description': 'ç·šç¨‹è¢«æ›èµ·ç­‰å¾…',
                    'severity': 'medium'
                })
        
        return blocking_points
    
    def _analyze_service_interactions(self, backtrace: List[str]) -> List[Dict]:
        """åˆ†ææœå‹™äº¤äº’"""
        interactions = []
        
        # åˆ†æ Binder èª¿ç”¨éˆ
        service_chain = []
        for frame in backtrace:
            if 'Service' in frame or 'Manager' in frame:
                service = re.search(r'(\w+(?:Service|Manager))', frame)
                if service and service.group(1) not in service_chain:
                    service_chain.append(service.group(1))
        
        # å»ºç«‹äº¤äº’é—œä¿‚
        for i in range(len(service_chain) - 1):
            interactions.append({
                'from': service_chain[i],
                'to': service_chain[i + 1],
                'type': 'Binder IPC'
            })
        
        return interactions
    
    def match_known_patterns(self, anr_info: ANRInfo) -> List[Dict]:
        """åŒ¹é…å·²çŸ¥å•é¡Œæ¨¡å¼"""
        matches = []
        
        if not anr_info.main_thread:
            return matches
        
        # å°‡å †ç–Šè½‰ç‚ºå­—ä¸²ä¾¿æ–¼åŒ¹é…
        stack_str = '\n'.join(anr_info.main_thread.backtrace)
        
        # æª¢æŸ¥é€šç”¨æ¨¡å¼ï¼ˆä¸æ˜¯è¨­å‚™ç‰¹å®šçš„ï¼‰
        for category, patterns in self.analysis_patterns.items():
            for pattern_name, pattern_info in patterns.items():
                # åªæª¢æŸ¥æ¨¡å¼ï¼Œä¸æª¢æŸ¥ç‰¹å®šè¨­å‚™
                if 'patterns' in pattern_info:  # æ–°çš„çµæ§‹
                    match_count = sum(1 for pattern in pattern_info['patterns']
                                    if re.search(pattern, stack_str, re.IGNORECASE))
                    
                    if match_count > 0:
                        matches.append({
                            'pattern': pattern_name,
                            'confidence': match_count / len(pattern_info['patterns']),
                            'description': pattern_info.get('description', ''),
                            'workarounds': pattern_info.get('workarounds', [])
                        })
        
        return sorted(matches, key=lambda x: x['confidence'], reverse=True)
    
    def _init_analysis_patterns(self) -> Dict:
        """åˆå§‹åŒ–åˆ†ææ¨¡å¼åº« - åªåŒ…å«é€šç”¨æ¨¡å¼"""
        return {
            'binder_patterns': {
                'binder_timeout': {
                    'signatures': [
                        'BinderProxy.transactNative',
                        'transact.*timed out',
                        'Binder.*block'
                    ],
                    'description': 'Binder IPC è¶…æ™‚',
                    'common_causes': [
                        'ç›®æ¨™æœå‹™ç¹å¿™',
                        'ç³»çµ±è³‡æºä¸è¶³',
                        'æ­»é–æˆ–å¾ªç’°ç­‰å¾…'
                    ]
                }
            },
            'thread_patterns': {
                'main_thread_blocked': {
                    'signatures': [
                        'main.*BLOCKED',
                        'tid=1.*waiting',
                        'main.*Native'
                    ],
                    'description': 'ä¸»ç·šç¨‹é˜»å¡',
                    'common_causes': [
                        'åŒæ­¥æ“ä½œåœ¨ä¸»ç·šç¨‹',
                        'I/O æ“ä½œåœ¨ä¸»ç·šç¨‹',
                        'ç­‰å¾…å…¶ä»–ç·šç¨‹æˆ–æœå‹™'
                    ]
                }
            },
            'system_patterns': {
                'high_cpu_usage': {
                    'signatures': [
                        'CPU.*9[0-9]%',
                        'load average.*[4-9]\\.',
                    ],
                    'description': 'é«˜ CPU ä½¿ç”¨ç‡',
                    'common_causes': [
                        'ç„¡é™å¾ªç’°',
                        'éåº¦çš„è¨ˆç®—',
                        'é »ç¹çš„ GC'
                    ]
                }
            }
        }

    def analyze_crash_pattern(self, tombstone_info: TombstoneInfo) -> Dict:
        """åˆ†æå´©æ½°æ¨¡å¼ - å°ˆé–€ç‚º Tombstone"""
        analysis = {
            'crash_flow': [],
            'memory_context': [],
            'crash_signature': [],
            'similar_crashes': []
        }
        
        # åˆ†æå´©æ½°æµç¨‹
        if tombstone_info.crash_backtrace:
            for i, frame in enumerate(tombstone_info.crash_backtrace[:10]):
                frame_analysis = {
                    'level': i,
                    'pc': frame.get('pc', 'Unknown'),
                    'location': frame.get('location', 'Unknown'),
                    'symbol': frame.get('symbol'),
                    'analysis': self._analyze_crash_frame(frame)
                }
                analysis['crash_flow'].append(frame_analysis)
        
        # åˆ†æè¨˜æ†¶é«”ä¸Šä¸‹æ–‡
        if tombstone_info.fault_addr:
            analysis['memory_context'] = self._analyze_memory_context(
                tombstone_info.fault_addr,
                tombstone_info.memory_map
            )
        
        # ç”Ÿæˆå´©æ½°ç°½åï¼ˆç”¨æ–¼ç›¸ä¼¼å´©æ½°åŒ¹é…ï¼‰
        analysis['crash_signature'] = self._generate_crash_signature(tombstone_info)
        
        return analysis

    def _analyze_crash_frame(self, frame: Dict) -> str:
        """åˆ†æå´©æ½°å¹€"""
        location = frame.get('location', '')
        symbol = frame.get('symbol', '')
        
        if 'libc.so' in location:
            if 'malloc' in symbol or 'free' in symbol:
                return 'è¨˜æ†¶é«”ç®¡ç†æ“ä½œ'
            elif 'strlen' in symbol or 'strcpy' in symbol:
                return 'å­—ä¸²æ“ä½œ'
            else:
                return 'ç³»çµ± C åº«èª¿ç”¨'
        elif 'libandroid_runtime.so' in location:
            return 'Android Runtime å±¤'
        elif 'art::' in symbol:
            return 'ART è™›æ“¬æ©Ÿ'
        elif '.so' in location and 'vendor' in location:
            return 'å» å•†åº«'
        elif '.apk' in location or '.dex' in location:
            return 'æ‡‰ç”¨å±¤ä»£ç¢¼'
        
        return 'æœªçŸ¥'

    def _analyze_memory_context(self, fault_addr: str, memory_map: List[str]) -> Dict:
        """åˆ†æè¨˜æ†¶é«”ä¸Šä¸‹æ–‡"""
        context = {
            'fault_location': None,
            'nearby_regions': [],
            'analysis': None
        }
        
        try:
            fault_int = int(fault_addr, 16)
            
            # ç‰¹æ®Šåœ°å€åˆ†æ
            if fault_int == 0:
                context['analysis'] = 'ç©ºæŒ‡é‡è¨ªå•'
            elif fault_int < 0x1000:
                context['analysis'] = 'ä½åœ°å€è¨ªå•ï¼Œå¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»'
            elif fault_int == 0xdeadbaad:
                context['analysis'] = 'Android libc abort æ¨™è¨˜'
            elif fault_int == 0xdeadbeef:
                context['analysis'] = 'èª¿è©¦æ¨™è¨˜åœ°å€'
            
            # æŸ¥æ‰¾æ‰€åœ¨è¨˜æ†¶é«”å€åŸŸ
            for mem_line in memory_map[:50]:
                if '-' in mem_line:
                    parts = mem_line.split()
                    if parts:
                        addr_range = parts[0]
                        if '-' in addr_range:
                            start_str, end_str = addr_range.split('-')
                            try:
                                start = int(start_str, 16)
                                end = int(end_str, 16)
                                
                                if start <= fault_int <= end:
                                    context['fault_location'] = mem_line
                                    context['analysis'] = self._analyze_memory_region(parts)
                                elif abs(fault_int - start) < 0x1000 or abs(fault_int - end) < 0x1000:
                                    context['nearby_regions'].append(mem_line)
                            except:
                                pass
        except:
            pass
        
        return context

    def _analyze_memory_region(self, parts: List[str]) -> str:
        """åˆ†æè¨˜æ†¶é«”å€åŸŸé¡å‹"""
        if len(parts) > 6:
            region_name = parts[6]
            if '[stack]' in region_name:
                return 'å †ç–Šå€åŸŸ - å¯èƒ½æ˜¯å †ç–Šæº¢å‡º'
            elif '[heap]' in region_name:
                return 'å †å€åŸŸ - å¯èƒ½æ˜¯å †æå£'
            elif '.so' in region_name:
                return f'å…±äº«åº«å€åŸŸ: {region_name}'
            elif '.apk' in region_name:
                return 'APK ä»£ç¢¼å€åŸŸ'
        
        permissions = parts[1] if len(parts) > 1 else ''
        if 'r-x' in permissions:
            return 'ä»£ç¢¼æ®µ'
        elif 'rw-' in permissions:
            return 'æ•¸æ“šæ®µ'
        
        return 'æœªçŸ¥å€åŸŸ'

    def _generate_crash_signature(self, tombstone_info: TombstoneInfo) -> str:
        """ç”Ÿæˆå´©æ½°ç°½åç”¨æ–¼ç›¸ä¼¼å´©æ½°åŒ¹é…"""
        signature_parts = []
        
        # ä¿¡è™Ÿé¡å‹
        signature_parts.append(f"sig_{tombstone_info.signal.name}")
        
        # æ•…éšœåœ°å€ç‰¹å¾µ
        if tombstone_info.fault_addr in ['0x0', '0']:
            signature_parts.append("null_ptr")
        elif tombstone_info.fault_addr.startswith('0xdead'):
            signature_parts.append("debug_marker")
        
        # é ‚å±¤å †ç–Šç‰¹å¾µ
        if tombstone_info.crash_backtrace:
            for frame in tombstone_info.crash_backtrace[:3]:
                if frame.get('symbol'):
                    # æå–å‡½æ•¸å
                    func_name = frame['symbol'].split('(')[0].split()[-1]
                    signature_parts.append(func_name)
        
        return "_".join(signature_parts[:5])  # é™åˆ¶é•·åº¦

    def match_tombstone_patterns(self, tombstone_info: TombstoneInfo) -> List[Dict]:
        """åŒ¹é… Tombstone å·²çŸ¥æ¨¡å¼"""
        matches = []
        
        # æº–å‚™åŒ¹é…æ•¸æ“š
        crash_str = f"{tombstone_info.signal.name} {tombstone_info.fault_addr}"
        if tombstone_info.crash_backtrace:
            for frame in tombstone_info.crash_backtrace[:5]:
                crash_str += f" {frame.get('location', '')} {frame.get('symbol', '')}"
        
        # æª¢æŸ¥å´©æ½°æ¨¡å¼
        for pattern_name, pattern_info in self.analysis_patterns.get('tombstone_crash_patterns', {}).items():
            match_count = sum(1 for sig in pattern_info['signatures'] 
                            if sig.lower() in crash_str.lower())
            
            if match_count > 0:
                confidence = match_count / len(pattern_info['signatures'])
                if confidence >= 0.5:  # 50% åŒ¹é…åº¦
                    matches.append({
                        'pattern': pattern_name,
                        'confidence': confidence,
                        'root_cause': pattern_info['root_cause'],
                        'severity': pattern_info['severity'],
                        'solutions': pattern_info['solutions']
                    })
        
        return sorted(matches, key=lambda x: x['confidence'], reverse=True)

    def _detect_complex_deadlock(self, all_threads: List[ThreadInfo]) -> Dict:
        """è¤‡é›œæ­»é–æª¢æ¸¬ - åŒ…æ‹¬è·¨é€²ç¨‹æ­»é–"""
        deadlock_info = {
            'has_deadlock': False,
            'type': None,
            'cycles': [],
            'cross_process': False
        }
        
        # å»ºç«‹ç­‰å¾…åœ–
        wait_graph = {}
        lock_holders = {}
        thread_map = {t.tid: t for t in all_threads}
        
        for thread in all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                # è§£æç­‰å¾…è³‡è¨Š
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    wait_graph[thread.tid] = match.group(1)
                
                # æª¢æŸ¥æ˜¯å¦åœ¨ç­‰å¾…å…¶ä»–é€²ç¨‹
                cross_match = re.search(r'held by tid=(\d+) in process (\d+)', thread.waiting_info)
                if cross_match:
                    deadlock_info['cross_process'] = True
            
            # è¨˜éŒ„é–æŒæœ‰è€…
            for lock in thread.held_locks:
                lock_holders[lock] = thread.tid
        
        # ä½¿ç”¨ Tarjan ç®—æ³•æª¢æ¸¬å¼·é€£é€šåˆ†é‡ï¼ˆå¾ªç’°ï¼‰
        cycles = self._tarjan_scc(wait_graph)
        
        if cycles:
            deadlock_info['has_deadlock'] = True
            deadlock_info['type'] = 'circular_wait'
            
            # è½‰æ›å¾ªç’°ç‚ºç·šç¨‹è³‡è¨Š
            for cycle in cycles:
                cycle_info = []
                for tid in cycle:
                    if tid in thread_map:
                        thread = thread_map[tid]
                        cycle_info.append({
                            'tid': tid,
                            'name': thread.name,
                            'state': thread.state.value,
                            'waiting_on': thread.waiting_locks[0] if thread.waiting_locks else None
                        })
                
                if cycle_info:
                    deadlock_info['cycles'].append(cycle_info)
        
        # æª¢æŸ¥å…¶ä»–é¡å‹çš„æ­»é–
        # 1. å„ªå…ˆç´šåè½‰
        high_prio_waiting = []
        low_prio_holding = []
        
        for thread in all_threads:
            if thread.prio and thread.prio.isdigit():
                prio = int(thread.prio)
                if prio <= 5 and thread.waiting_locks:  # é«˜å„ªå…ˆç´šç­‰å¾…
                    high_prio_waiting.append(thread)
                elif prio >= 8 and thread.held_locks:  # ä½å„ªå…ˆç´šæŒæœ‰
                    low_prio_holding.append(thread)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å„ªå…ˆç´šåè½‰
        for high_thread in high_prio_waiting:
            for low_thread in low_prio_holding:
                if any(lock in low_thread.held_locks for lock in high_thread.waiting_locks):
                    if not deadlock_info['has_deadlock']:
                        deadlock_info['has_deadlock'] = True
                        deadlock_info['type'] = 'priority_inversion'
                    break
        
        return deadlock_info

    def _tarjan_scc(self, graph: Dict[str, str]) -> List[List[str]]:
        """ä½¿ç”¨ Tarjan ç®—æ³•å°‹æ‰¾å¼·é€£é€šåˆ†é‡ï¼ˆç”¨æ–¼æ­»é–æª¢æ¸¬ï¼‰"""
        index_counter = [0]
        stack = []
        lowlinks = {}
        index = {}
        on_stack = {}
        sccs = []
        
        def strongconnect(node):
            index[node] = index_counter[0]
            lowlinks[node] = index_counter[0]
            index_counter[0] += 1
            stack.append(node)
            on_stack[node] = True
            
            # è€ƒæ…®å¾Œç¹¼ç¯€é»
            if node in graph:
                successor = graph[node]
                if successor not in index:
                    strongconnect(successor)
                    lowlinks[node] = min(lowlinks[node], lowlinks[successor])
                elif on_stack.get(successor, False):
                    lowlinks[node] = min(lowlinks[node], index[successor])
            
            # å¦‚æœç¯€é»æ˜¯æ ¹ç¯€é»ï¼Œå‰‡å½ˆå‡ºå †ç–Šä¸¦ç”Ÿæˆ SCC
            if lowlinks[node] == index[node]:
                scc = []
                while True:
                    w = stack.pop()
                    on_stack[w] = False
                    scc.append(w)
                    if w == node:
                        break
                # åªè¿”å›åŒ…å«å¤šå€‹ç¯€é»çš„ SCCï¼ˆé€™äº›æ˜¯å¾ªç’°ï¼‰
                if len(scc) > 1:
                    sccs.append(scc)
        
        # å°åœ–ä¸­çš„æ¯å€‹ç¯€é»èª¿ç”¨ç®—æ³•
        for node in graph:
            if node not in index:
                strongconnect(node)
        
        return sccs
    
    def _detect_watchdog_timeout(self, content: str) -> Optional[Dict]:
        """æª¢æ¸¬ Watchdog è¶…æ™‚"""
        watchdog_patterns = [
            r'Watchdog.*detected.*deadlock',
            r'WATCHDOG.*TIMEOUT',
            r'system_server.*anr.*Trace\.txt'
        ]
        
        for pattern in watchdog_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return {
                    'type': 'Watchdog Timeout',
                    'severity': 'critical',
                    'description': 'System server å¯èƒ½ç™¼ç”Ÿæ­»é–æˆ–åš´é‡é˜»å¡'
                }
        
        return None

    def _identify_crashlytics_tags(self, thread_info: ThreadInfo) -> List[str]:
        """è­˜åˆ¥ Firebase Crashlytics é¢¨æ ¼çš„æ¨™ç±¤"""
        tags = []
        
        # Triggered ANR
        if thread_info.state == ThreadState.BLOCKED and thread_info.tid == "1":
            tags.append("Triggered ANR")
        
        # Root blocking
        if thread_info.held_locks and not thread_info.waiting_locks:
            tags.append("Root blocking")
        
        # IO Root blocking
        for frame in thread_info.backtrace[:5]:
            if any(io in frame for io in ['FileInputStream', 'FileOutputStream', 'fdatasync']):
                tags.append("IO Root blocking")
                break
        
        # Deadlocked
        if self._is_in_deadlock(thread_info):
            tags.append("Deadlocked")
        
        return tags

    def _is_in_deadlock(self, thread_info: ThreadInfo) -> bool:
        """æª¢æŸ¥ç·šç¨‹æ˜¯å¦åœ¨æ­»é–ä¸­"""
        # å¦‚æœç·šç¨‹åœ¨ç­‰å¾…é–ï¼Œä¸”è©²é–è¢«å…¶ä»–ç·šç¨‹æŒæœ‰
        if thread_info.waiting_info and 'held by' in thread_info.waiting_info:
            # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœç­‰å¾…è³‡è¨Šä¸­åŒ…å«æ­»é–ç›¸é—œé—œéµå­—
            deadlock_keywords = ['deadlock', 'circular', 'cycle']
            if any(keyword in thread_info.waiting_info.lower() for keyword in deadlock_keywords):
                return True
            
            # å¦‚æœæœ‰ç­‰å¾…é–ä¸”ç‹€æ…‹æ˜¯ BLOCKED
            if thread_info.state == ThreadState.BLOCKED and thread_info.waiting_locks:
                return True
        
        return False
    
    def _detect_strictmode_violations(self, content: str) -> List[Dict]:
        """æª¢æ¸¬ StrictMode é•è¦"""
        violations = []
        
        strictmode_patterns = {
            'DiskReadViolation': 'ä¸»ç·šç¨‹ç£ç¢Ÿè®€å–',
            'DiskWriteViolation': 'ä¸»ç·šç¨‹ç£ç¢Ÿå¯«å…¥',
            'NetworkViolation': 'ä¸»ç·šç¨‹ç¶²è·¯æ“ä½œ',
            'CustomSlowCallViolation': 'è‡ªå®šç¾©æ…¢èª¿ç”¨',
            'ResourceMismatchViolation': 'è³‡æºä¸åŒ¹é…'
        }
        
        for violation_type, description in strictmode_patterns.items():
            if violation_type in content:
                violations.append({
                    'type': violation_type,
                    'description': description,
                    'suggestion': 'å°‡æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹'
                })
        
        return violations

    def _analyze_gc_impact(self, content: str) -> Dict:
        """åˆ†æåƒåœ¾å›æ”¶çš„å½±éŸ¿"""
        gc_info = {
            'gc_count': 0,
            'total_pause_time': 0,
            'concurrent_gc': 0,
            'explicit_gc': 0,
            'alloc_gc': 0,
            'impact': 'low'
        }
        
        # è§£æ GC æ—¥èªŒ
        gc_patterns = [
            r'GC_FOR_ALLOC.*?paused\s+(\d+)ms',
            r'GC_CONCURRENT.*?paused\s+(\d+)ms\+(\d+)ms',
            r'GC_EXPLICIT.*?paused\s+(\d+)ms',
            r'Clamp target GC heap'
        ]
        
        for pattern in gc_patterns:
            matches = re.findall(pattern, content)
            gc_info['gc_count'] += len(matches)
            
            # è¨ˆç®—ç¸½æš«åœæ™‚é–“
            for match in matches:
                if isinstance(match, tuple):
                    gc_info['total_pause_time'] += sum(int(x) for x in match)
                else:
                    gc_info['total_pause_time'] += int(match)
        
        # è©•ä¼°å½±éŸ¿
        if gc_info['total_pause_time'] > 1000:  # è¶…é1ç§’
            gc_info['impact'] = 'high'
        elif gc_info['total_pause_time'] > 500:  # è¶…é500ms
            gc_info['impact'] = 'medium'
        
        return gc_info

    def _calculate_system_health_score(self, anr_info: ANRInfo) -> Dict:
        """è¨ˆç®—ç³»çµ±å¥åº·åº¦è©•åˆ†"""
        score = 100
        factors = []
        
        # CPU ä½¿ç”¨ç‡
        if anr_info.cpu_usage:
            cpu_total = anr_info.cpu_usage.get('total', 0)
            if cpu_total > 90:
                score -= 30
                factors.append(f"CPU éè¼‰ ({cpu_total}%)")
            elif cpu_total > 70:
                score -= 15
                factors.append(f"CPU åé«˜ ({cpu_total}%)")
        
        # è¨˜æ†¶é«”å£“åŠ›
        if anr_info.memory_info:
            available = anr_info.memory_info.get('available', 0)
            if available < 100 * 1024:  # å°æ–¼ 100MB
                score -= 25
                factors.append("è¨˜æ†¶é«”åš´é‡ä¸è¶³")
        
        # ç·šç¨‹æ•¸é‡
        thread_count = len(anr_info.all_threads)
        if thread_count > 200:
            score -= 20
            factors.append(f"ç·šç¨‹éå¤š ({thread_count})")
        
        # é˜»å¡ç·šç¨‹
        blocked_count = sum(1 for t in anr_info.all_threads if t.state == ThreadState.BLOCKED)
        if blocked_count > 10:
            score -= 20
            factors.append(f"å¤§é‡é˜»å¡ç·šç¨‹ ({blocked_count})")
        
        return {
            'score': max(0, score),
            'factors': factors,
            'recommendation': self._get_health_recommendation(score)
        }

    def _analyze_fortify_failure(self, content: str) -> Optional[Dict]:
        """åˆ†æ FORTIFY å¤±æ•—"""
        fortify_match = re.search(r'FORTIFY:\s*(.+)', content)
        if fortify_match:
            return {
                'type': 'FORTIFY Protection',
                'message': fortify_match.group(1),
                'severity': 'security',
                'suggestion': 'æª¢æŸ¥ç·©è¡å€å¤§å°å’Œå­—ä¸²æ“ä½œå®‰å…¨æ€§'
            }
                
def main():
    """ä¸»å‡½æ•¸"""
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python3 vp_analyze_logs.py <è¼¸å…¥è³‡æ–™å¤¾> <è¼¸å‡ºè³‡æ–™å¤¾>")
        print("ç¯„ä¾‹: python3 vp_analyze_logs.py logs/ output/")
        print("\nç‰¹é»:")
        print("  â€¢ ä½¿ç”¨ç‰©ä»¶å°å‘è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•å’Œç¶­è­·")
        print("  â€¢ æ”¯æ´æ‰€æœ‰ Android ç‰ˆæœ¬çš„ ANR å’Œ Tombstone æ ¼å¼")
        print("  â€¢ åŸºæ–¼å¤§é‡çœŸå¯¦æ¡ˆä¾‹çš„æ™ºèƒ½åˆ†æ")
        print("  â€¢ æä¾›è©³ç´°çš„æ ¹æœ¬åŸå› åˆ†æå’Œè§£æ±ºå»ºè­°")
        sys.exit(1)
    
    input_folder = sys.argv[1]
    output_folder = sys.argv[2]
    
    # å‰µå»ºåˆ†æç³»çµ±ä¸¦åŸ·è¡Œ
    analyzer = LogAnalyzerSystem(input_folder, output_folder)
    analyzer.analyze()


if __name__ == "__main__":
    main()