#!/usr/bin/env python3
"""
é€²éšç‰ˆ Android ANR/Tombstone åˆ†æå™¨ v4
æ”¯æ´æ‰€æœ‰ Android ç‰ˆæœ¬çš„ ANR å’Œ Tombstone æ ¼å¼
ä½¿ç”¨ç‰©ä»¶å°å‘è¨­è¨ˆï¼ŒåŸºæ–¼å¤§é‡çœŸå¯¦æ¡ˆä¾‹çš„æ™ºèƒ½åˆ†æ
"""

import os
import re
import sys
import html
import shutil
import time
import json
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Set
from enum import Enum
import traceback
import base64

# å°å…¥åŸºç¤é¡åˆ¥
from vp_analyze_logs_base import (
    SourceLink, SourceLinker, ANRTimeouts, ThreadInfo, ANRType, CrashSignal, ThreadState, ANRInfo, TombstoneInfo
)

from vp_analyze_logs_ext import PerformanceBottleneckDetector, BinderCallChainAnalyzer, ThreadDependencyAnalyzer, TimelineAnalyzer,CrossProcessAnalyzer,MLAnomalyDetector,RootCausePredictor,RiskAssessmentEngine,TrendAnalyzer,SystemMetricsIntegrator,SourceCodeAnalyzer,CodeFixGenerator,ConfigurationOptimizer,ComparativeAnalyzer,ParallelAnalyzer,IncrementalAnalyzer,VisualizationGenerator,ExecutiveSummaryGenerator

# ============= å·¥å…·å‡½æ•¸ =============

def time_tracker(func_name: str):
    """æ™‚é–“è¿½è¹¤è£é£¾å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            print(f"â±ï¸  {func_name} åŸ·è¡Œæ™‚é–“: {elapsed_time:.3f} ç§’")
            return result
        return wrapper
    return decorator

# ============= åŸºç¤åˆ†æå™¨é¡åˆ¥ =============

class BaseAnalyzer(ABC):
    """åŸºç¤åˆ†æå™¨æŠ½è±¡é¡åˆ¥"""
    
    def __init__(self):
        self.patterns = self._init_patterns()
    
    @abstractmethod
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ–åˆ†ææ¨¡å¼"""
        pass
    
    @abstractmethod
    def analyze(self, file_path: str) -> str:
        """åˆ†ææª”æ¡ˆ"""
        pass

# ============= ANR åˆ†æå™¨ =============
class ANRAnalyzer(BaseAnalyzer):
    """ANR åˆ†æå™¨"""
    
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ– ANR åˆ†ææ¨¡å¼"""
        return {
            'thread_patterns': [
                # æ¨™æº–æ ¼å¼ (Android 4.x - 13)
                r'"([^"]+)"\s+(?:daemon\s+)?prio=(\d+)\s+tid=(\d+)\s+(\w+)',
                # ç°¡åŒ–æ ¼å¼
                r'"([^"]+)".*?tid=(\d+).*?(\w+)',
                # Thread dump æ ¼å¼
                r'Thread-(\d+)\s+"([^"]+)".*?tid=(\d+).*?(\w+)',
                # ART æ ¼å¼ (Android 5.0+)
                r'"([^"]+)".*?\|\s+group="([^"]+)".*?tid=(\d+).*?\|\s+state=(\w)',
                # ç³»çµ±æœå‹™æ ¼å¼
                r'([a-zA-Z0-9._]+)\s+prio=(\d+)\s+tid=(\d+)\s+(\w+)',
                # Native thread æ ¼å¼
                r'Thread\s+(\d+)\s+\(([^)]+)\).*?State:\s+(\w)',
            ],
            'anr_trigger_patterns': [
                r'Input event dispatching timed out.*?Waited\s+(\d+)ms\s+for\s+(.+)',
                r'Reason:\s*Input dispatching timed out.*?Waited\s+(\d+)ms',
                r'executing service\s+([^\s]+).*?timeout=(\d+)ms',
                r'Broadcast of Intent.*?timed out.*?receiver=([^\s]+)',
                r'ContentProvider.*?not responding.*?provider=([^\s]+)',
                r'ANR in\s+([^,\s]+).*?PID:\s*(\d+)',
                r'Subject:\s*ANR.*?Process:\s*([^\s]+)',
                r'Cmd line:\s*([^\s]+)',
                # æ–°å¢çš„æ¨¡å¼
                r'JobScheduler.*?timed out.*?job=([^\s]+)',
                r'Foreground service.*?timed out.*?service=([^\s]+)',
                r'JobService.*?did not return.*?from.*?(\w+)',
            ],
            'lock_patterns': [
                r'waiting to lock\s+<([^>]+)>.*?held by thread\s+(\d+)',
                r'locked\s+<([^>]+)>',
                r'waiting on\s+<([^>]+)>',
                r'- locked\s+<0x([0-9a-f]+)>\s+\(a\s+([^)]+)\)',
                r'heldby=(\d+)',
                # æ–°å¢è·¨é€²ç¨‹é–æ¨¡å¼
                r'held by tid=(\d+) in process (\d+)',
                r'waiting for monitor entry',
                r'waiting for ownable synchronizer',
            ],
            'binder_patterns': [
                r'BinderProxy\.transact',
                r'Binder\.transact',
                r'IPCThreadState::transact',
                r'android\.os\.BinderProxy\.transactNative',
                r'android\.os\.Binder\.execTransact',
                r'oneway\s+transaction',
            ],
            'watchdog_patterns': [
                r'Watchdog.*detected.*deadlock',
                r'WATCHDOG.*TIMEOUT',
                r'system_server.*anr.*Trace\.txt',
                r'com\.android\.server\.Watchdog',
                r'watchdog.*kill.*system_server',
            ],
            'gc_patterns': [
                r'GC_FOR_ALLOC.*?freed.*?paused\s+(\d+)ms',
                r'GC_CONCURRENT.*?freed.*?paused\s+(\d+)ms\+(\d+)ms',
                r'GC_EXPLICIT.*?freed.*?paused\s+(\d+)ms',
                r'Clamp target GC heap',
                r'Alloc.*?concurrent.*?GC',
                r'Starting a blocking GC',
            ],
            'strictmode_patterns': [
                r'StrictMode.*?violation',
                r'DiskReadViolation',
                r'DiskWriteViolation',
                r'NetworkViolation',
                r'CustomSlowCallViolation',
                r'ResourceMismatchViolation',
            ],
        }
    
    @time_tracker("è§£æ ANR æª”æ¡ˆ")
    def analyze(self, file_path: str) -> str:
        """åˆ†æ ANR æª”æ¡ˆ"""
        try:
            print(f"é–‹å§‹åˆ†ææª”æ¡ˆ: {file_path}")
            
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            
            print(f"æª”æ¡ˆå¤§å°: {len(content)} å­—ç¬¦")
            
            # è§£æ ANR è³‡è¨Š
            anr_info = self._parse_anr_info(content)
            
            print(f"è§£æçµæœ - é€²ç¨‹å: {anr_info.process_name}, PID: {anr_info.pid}")
            print(f"ANR é¡å‹: {anr_info.anr_type.value}")
            print(f"ç·šç¨‹æ•¸é‡: {len(anr_info.all_threads)}")
            
            # å‰µå»ºæ™ºèƒ½åˆ†æå¼•æ“ - ä¿®æ­£é€™è£¡
            try:
                from vp_analyze_logs_ext import (
                    TimelineAnalyzer, CrossProcessAnalyzer, MLAnomalyDetector,
                    RootCausePredictor, RiskAssessmentEngine, TrendAnalyzer,
                    SystemMetricsIntegrator, SourceCodeAnalyzer, CodeFixGenerator,
                    ConfigurationOptimizer, ComparativeAnalyzer, ParallelAnalyzer,
                    IncrementalAnalyzer, VisualizationGenerator, ExecutiveSummaryGenerator
                )
                
                intelligent_engine = IntelligentAnalysisEngine()
            except Exception as e:
                print(f"å‰µå»ºæ™ºèƒ½åˆ†æå¼•æ“å¤±æ•—: {e}")
                intelligent_engine = None
            
            # ç”Ÿæˆåˆ†æå ±å‘Š
            report = self._generate_report(anr_info, content, intelligent_engine)
            
            return report
            
        except Exception as e:
            error_msg = f"âŒ åˆ†æ ANR æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
            print(error_msg)
            return error_msg
    
    def _parse_anr_info(self, content: str) -> ANRInfo:
        """è§£æ ANR è³‡è¨Š"""
        lines = content.splitlines()
        
        # è­˜åˆ¥ ANR é¡å‹å’ŒåŸºæœ¬è³‡è¨Š
        anr_type = self._identify_anr_type(content)
        process_info = self._extract_process_info(content)
        
        # è§£ææ‰€æœ‰ç·šç¨‹è³‡è¨Š
        all_threads = self._extract_all_threads(lines, content)
        
        # æ‰¾å‡ºä¸»ç·šç¨‹
        main_thread = self._find_main_thread(all_threads)
        
        # è§£æé¡å¤–è³‡è¨Š
        cpu_usage = self._extract_cpu_usage(content)
        memory_info = self._extract_memory_info(content)
        
        # æ–°å¢ï¼šè§£æ ANR è¶…æ™‚æ™‚é–“
        timeout_info = self._extract_timeout_info(content)
        
        anr_info = ANRInfo(
            anr_type=anr_type,
            process_name=process_info.get('process_name', 'Unknown'),
            pid=process_info.get('pid', 'Unknown'),
            timestamp=process_info.get('timestamp'),
            reason=process_info.get('reason'),
            main_thread=main_thread,
            all_threads=all_threads,
            cpu_usage=cpu_usage,
            memory_info=memory_info
        )
        
        # æ–°å¢ï¼šå°‡è¶…æ™‚è³‡è¨ŠåŠ å…¥ ANRInfo
        anr_info.timeout_info = timeout_info
        
        return anr_info
    
    def _identify_anr_type(self, content: str) -> ANRType:
        """è­˜åˆ¥ ANR é¡å‹ - å¢å¼·ç‰ˆ"""
        type_mappings = {
            # åŸæœ‰çš„æ˜ å°„
            "Input dispatching timed out": ANRType.INPUT_DISPATCHING,
            "Input event dispatching timed out": ANRType.INPUT_DISPATCHING,
            "executing service": ANRType.SERVICE,
            "Broadcast of Intent": ANRType.BROADCAST,
            "BroadcastReceiver": ANRType.BROADCAST,
            "ContentProvider": ANRType.CONTENT_PROVIDER,
            "Activity": ANRType.ACTIVITY,
            "Foreground service": ANRType.FOREGROUND_SERVICE,
            # æ–°å¢çš„é¡å‹æª¢æ¸¬
            "JobScheduler": ANRType.SERVICE,
            "JobService": ANRType.SERVICE,
            "startForeground": ANRType.FOREGROUND_SERVICE,
        }
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Watchdog è¶…æ™‚
        if any(re.search(pattern, content) for pattern in self.patterns['watchdog_patterns']):
            # Watchdog é€šå¸¸æ˜¯ç³»çµ±æœå‹™å•é¡Œ
            return ANRType.SERVICE
        
        for pattern, anr_type in type_mappings.items():
            if pattern in content:
                return anr_type
        
        return ANRType.UNKNOWN
    
    def _extract_process_info(self, content: str) -> Dict:
        """æå–é€²ç¨‹è³‡è¨Š"""
        info = {}
        
        # ç‰¹åˆ¥è™•ç†æ‚¨çš„æ—¥èªŒæ ¼å¼
        # 1. æå– PID å’Œæ™‚é–“æˆ³
        pid_patterns = [
            r'----- pid (\d+) at ([\d-]+\s+[\d:.]+[\+\-]\d+)',  # å®Œæ•´æ ¼å¼
            r'----- dumping pid:\s*(\d+)',  # dumping æ ¼å¼
        ]
        
        for pattern in pid_patterns:
            match = re.search(pattern, content)
            if match:
                info['pid'] = match.group(1)
                if len(match.groups()) > 1:  # å¦‚æœæœ‰æ™‚é–“æˆ³
                    timestamp = match.group(2)
                    # ç§»é™¤æ™‚å€ï¼Œä¿ç•™ä¸»è¦æ™‚é–“
                    info['timestamp'] = re.sub(r'[\+\-]\d+$', '', timestamp).strip()
                break
        
        # 2. æå–é€²ç¨‹åï¼ˆå¾ Cmd lineï¼‰
        cmdline_match = re.search(r'Cmd line:\s*([^\s\n]+)', content)
        if cmdline_match:
            info['process_name'] = cmdline_match.group(1)
        
        # 3. æå– Build fingerprint
        fingerprint_match = re.search(r"Build fingerprint:\s*'([^']+)'", content)
        if fingerprint_match:
            info['build_fingerprint'] = fingerprint_match.group(1)
        
        # 4. æå– ABI
        abi_match = re.search(r"ABI:\s*'([^']+)'", content)
        if abi_match:
            info['abi'] = abi_match.group(1)
        
        # å¦‚æœä¸Šé¢çš„ç‰¹æ®Šè™•ç†å·²ç¶“æ‰¾åˆ°äº†åŸºæœ¬è³‡è¨Šï¼Œå¯ä»¥è¿”å›
        if 'pid' in info and 'process_name' in info:
            print(f"æå–çš„é€²ç¨‹è³‡è¨Š: {info}")
            return info
        
        # å¦å‰‡å˜—è©¦å…¶ä»–æ¨™æº–æ ¼å¼
        patterns = [
            # æ¨™æº– ANR æ ¼å¼
            r'ANR in\s+([^\s,]+).*?(?:PID:\s*(\d+))?',
            r'Process:\s*([^\s,]+).*?(?:PID:\s*(\d+))?',
            r'ProcessRecord\{[^}]+\s+(\d+):([^/]+)',
            # Subject è¡Œæ ¼å¼
            r'Subject:\s*ANR.*?Process:\s*([^\s]+)',
            # æ–°æ ¼å¼
            r'pid:\s*(\d+),.*?name:\s*([^\s]+)',
            # Executing service
            r'executing service\s+([^/]+)/([^\s]+)',
            # Input dispatching
            r'Input event dispatching timed out.*?([^\s]+)\s+\(server\)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.MULTILINE)
            if match:
                groups = match.groups()
                if len(groups) >= 2:
                    # æ ¹æ“šæ¨¡å¼è™•ç†ä¸åŒçš„åŒ¹é…çµæœ
                    if pattern.startswith(r'pid:'):
                        info['pid'] = groups[0]
                        info['process_name'] = groups[1]
                    elif pattern.startswith(r'ProcessRecord'):
                        info['pid'] = groups[0]
                        info['process_name'] = groups[1]
                    elif pattern.startswith(r'executing service'):
                        info['process_name'] = groups[0]
                    else:
                        info['process_name'] = groups[0]
                        if len(groups) > 1 and groups[1]:
                            info['pid'] = groups[1]
                elif len(groups) == 1:
                    info['process_name'] = groups[0]
                
                # å¦‚æœæ‰¾åˆ°é€²ç¨‹åï¼Œå°±è·³å‡ºå¾ªç’°
                if 'process_name' in info:
                    break
        
        # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦å¾å…§å®¹ä¸­æå–
        if 'process_name' not in info:
            # å˜—è©¦æ‰¾åŒ…åæ ¼å¼ (com.example.app)
            package_match = re.search(r'(com\.[a-zA-Z0-9._]+)', content)
            if package_match:
                info['process_name'] = package_match.group(1)
        
        # æå–æ™‚é–“æˆ³ï¼ˆå¦‚æœé‚„æ²’æœ‰ï¼‰
        if 'timestamp' not in info:
            timestamp_patterns = [
                r'(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+)',
                r'(\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+)',
                r'Time:\s*(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})',
            ]
            
            for pattern in timestamp_patterns:
                timestamp_match = re.search(pattern, content)
                if timestamp_match:
                    info['timestamp'] = timestamp_match.group(1)
                    break
        
        # æå–åŸå› 
        reason_patterns = [
            r'Reason:\s*(.+?)(?:\n|$)',
            r'Input event dispatching timed out.*?\.\s*(.+?)(?:\n|$)',
            r'executing service\s+(.+?)(?:\n|$)',
        ]
        
        for pattern in reason_patterns:
            reason_match = re.search(pattern, content)
            if reason_match:
                info['reason'] = reason_match.group(1).strip()
                break
        
        print(f"æå–çš„é€²ç¨‹è³‡è¨Š: {info}")
        return info
    
    def _extract_timeout_info(self, content: str) -> Dict:
        """æå– ANR è¶…æ™‚è³‡è¨Š"""
        timeout_info = {
            'wait_time': None,
            'timeout_threshold': None,
            'is_foreground': True
        }
        
        # æå–ç­‰å¾…æ™‚é–“
        wait_match = re.search(r'Waited\s+(\d+)ms', content)
        if wait_match:
            timeout_info['wait_time'] = int(wait_match.group(1))
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºå‰å°/èƒŒæ™¯
        if 'background' in content.lower() or 'bg anr' in content.lower():
            timeout_info['is_foreground'] = False
        
        # æ ¹æ“š ANR é¡å‹è¨­å®šé–¾å€¼
        if 'Input' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.INPUT_DISPATCHING
        elif 'Service' in content:
            if timeout_info['is_foreground']:
                timeout_info['timeout_threshold'] = ANRTimeouts.SERVICE_TIMEOUT
            else:
                timeout_info['timeout_threshold'] = ANRTimeouts.SERVICE_BACKGROUND_TIMEOUT
        elif 'Broadcast' in content:
            if timeout_info['is_foreground']:
                timeout_info['timeout_threshold'] = ANRTimeouts.BROADCAST_TIMEOUT
            else:
                timeout_info['timeout_threshold'] = ANRTimeouts.BROADCAST_BACKGROUND_TIMEOUT
        elif 'JobScheduler' in content or 'JobService' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.JOB_SCHEDULER_TIMEOUT
        elif 'ContentProvider' in content:
            timeout_info['timeout_threshold'] = ANRTimeouts.CONTENT_PROVIDER_TIMEOUT
        
        return timeout_info
    
    def _extract_all_threads(self, lines: List[str], content: str) -> List[ThreadInfo]:
        """æå–æ‰€æœ‰ç·šç¨‹è³‡è¨Š - å¢å¼·ç‰ˆ"""
        threads = []
        
        for idx, line in enumerate(lines):
            thread_info = self._try_parse_thread(line, idx, lines)
            if thread_info:
                # æå–å †ç–Šè³‡è¨Š
                thread_info.backtrace = self._extract_backtrace(lines, idx)
                
                # æå–é–è³‡è¨Š
                self._extract_lock_info(thread_info, lines, idx)
                
                # æ–°å¢ï¼šæª¢æ¸¬è·¨é€²ç¨‹é–
                self._extract_cross_process_lock_info(thread_info, lines, idx)
                
                # æ–°å¢ï¼šæå–ç·šç¨‹ CPU æ™‚é–“
                self._extract_thread_cpu_time(thread_info, lines, idx)
                
                threads.append(thread_info)
        
        return threads
    
    def _try_parse_thread(self, line: str, idx: int, lines: List[str]) -> Optional[ThreadInfo]:
        """å˜—è©¦è§£æç·šç¨‹è³‡è¨Š"""
        # æ‚¨çš„æ—¥èªŒæ ¼å¼: "GmsDynamite" prio=5 tid=46 Waiting
        thread_match = re.match(r'"([^"]+)"\s+prio=(\d+)\s+tid=(\d+)\s+(\w+)', line)
        if thread_match:
            name = thread_match.group(1)
            prio = thread_match.group(2)
            tid = thread_match.group(3)
            state_str = thread_match.group(4)
            
            thread_info = ThreadInfo(
                name=name,
                tid=tid,
                prio=prio,
                state=self._parse_thread_state(state_str)
            )
            
            # å¾å¾ŒçºŒè¡Œæå– sysTid å’Œå…¶ä»–è³‡è¨Š
            for i in range(idx + 1, min(idx + 5, len(lines))):
                next_line = lines[i]
                
                # æå– sysTid
                systid_match = re.search(r'sysTid=(\d+)', next_line)
                if systid_match:
                    thread_info.sysTid = systid_match.group(1)
                
                # æå– state (æ›´è©³ç´°çš„ç‹€æ…‹)
                state_match = re.search(r'\|\s+state=([A-Z])', next_line)
                if state_match:
                    # å¦‚æœæœ‰æ›´è©³ç´°çš„ç‹€æ…‹ï¼Œæ›´æ–°å®ƒ
                    detailed_state = self._parse_thread_state(state_match.group(1))
                    if detailed_state != ThreadState.UNKNOWN:
                        thread_info.state = detailed_state
                
                # æå– utm å’Œ stm
                utm_match = re.search(r'utm=(\d+)', next_line)
                stm_match = re.search(r'stm=(\d+)', next_line)
                if utm_match:
                    thread_info.utm = utm_match.group(1)
                if stm_match:
                    thread_info.stm = stm_match.group(1)
                
                # æå– schedstat
                schedstat_match = re.search(r'schedstat=\(\s*(\d+)\s+(\d+)\s+(\d+)\s*\)', next_line)
                if schedstat_match:
                    runtime = int(schedstat_match.group(1)) / 1000000  # è½‰æ›ç‚ºæ¯«ç§’
                    waittime = int(schedstat_match.group(2)) / 1000000
                    thread_info.schedstat = f"é‹è¡Œ:{runtime:.1f}ms ç­‰å¾…:{waittime:.1f}ms"
                
                # å¦‚æœé‡åˆ°ä¸‹ä¸€å€‹ç·šç¨‹ï¼Œåœæ­¢
                if re.match(r'"[^"]+".*tid=\d+', next_line):
                    break
            
            return thread_info
        
        # å˜—è©¦å…¶ä»–æ ¼å¼
        for pattern in self.patterns['thread_patterns']:
            match = re.search(pattern, line)
            if match:
                groups = match.groups()
                
                # æ ¹æ“šä¸åŒæ¨¡å¼è§£æ
                if len(groups) == 4 and 'daemon' not in pattern:
                    name, prio, tid, state = groups
                    return ThreadInfo(
                        name=name,
                        tid=tid,
                        prio=prio,
                        state=self._parse_thread_state(state)
                    )
                elif len(groups) == 3:
                    name, tid, state = groups
                    return ThreadInfo(
                        name=name,
                        tid=tid,
                        state=self._parse_thread_state(state)
                    )
                
        return None
    
    def _parse_thread_state(self, state_str: str) -> ThreadState:
        """è§£æç·šç¨‹ç‹€æ…‹"""
        state_mappings = {
            'R': ThreadState.RUNNABLE,
            'S': ThreadState.SLEEPING,
            'D': ThreadState.WAIT,
            'T': ThreadState.SUSPENDED,
            'Z': ThreadState.ZOMBIE,
            'RUNNABLE': ThreadState.RUNNABLE,
            'TIMED_WAIT': ThreadState.TIMED_WAIT,
            'TIMED_WAITING': ThreadState.TIMED_WAIT,
            'WAIT': ThreadState.WAIT,
            'WAITING': ThreadState.WAIT,
            'BLOCKED': ThreadState.BLOCKED,
            'SUSPENDED': ThreadState.SUSPENDED,
            'NATIVE': ThreadState.NATIVE,
            'MONITOR': ThreadState.MONITOR,
            'SLEEPING': ThreadState.SLEEPING,
            'ZOMBIE': ThreadState.ZOMBIE,
        }
        
        return state_mappings.get(state_str.upper(), ThreadState.UNKNOWN)
    
    def _extract_backtrace(self, lines: List[str], start_idx: int) -> List[str]:
        """æå–å †ç–Šè¿½è¹¤"""
        backtrace = []
        
        for i in range(start_idx + 1, len(lines)):
            line = lines[i]
            
            # æª¢æ¸¬ä¸‹ä¸€å€‹ç·šç¨‹æˆ–çµæŸ
            if self._is_thread_start(line):
                break
            
            # æå–å †ç–Šè¡Œ
            if self._is_stack_frame(line):
                frame = self._clean_stack_frame(line)
                if frame:
                    backtrace.append(frame)
        
        return backtrace
    
    def _is_thread_start(self, line: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºç·šç¨‹é–‹å§‹"""
        return any(re.search(pattern, line) for pattern in self.patterns['thread_patterns'][:3])
    
    def _is_stack_frame(self, line: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚ºå †ç–Šæ¡†æ¶"""
        patterns = [
            r'^\s*at\s+',
            r'^\s*#\d+\s+',
            r'\([^)]+\.java:\d+\)',
            r'\([^)]+\.kt:\d+\)',
            r'^\s*-\s+(locked|waiting)',
            r'Native Method',
        ]
        return any(re.search(pattern, line) for pattern in patterns)
    
    def _clean_stack_frame(self, line: str) -> str:
        """æ¸…ç†å †ç–Šæ¡†æ¶"""
        # ç§»é™¤å‰ç¶´
        line = re.sub(r'^\s*at\s+', '', line)
        line = re.sub(r'^\s*#\d+\s+', '', line)
        return line.strip()
    
    def _extract_lock_info(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–é–è³‡è¨Š"""
        for i in range(start_idx + 1, min(start_idx + 20, len(lines))):
            line = lines[i]
            
            # æª¢æŸ¥æŒæœ‰çš„é–
            locked_match = re.search(r'- locked\s+<([^>]+)>', line)
            if locked_match:
                thread.held_locks.append(locked_match.group(1))
            
            # æª¢æŸ¥ç­‰å¾…çš„é–
            waiting_match = re.search(r'- waiting (?:on|to lock)\s+<([^>]+)>', line)
            if waiting_match:
                thread.waiting_locks.append(waiting_match.group(1))
                
                # æå–ç­‰å¾…è³‡è¨Š
                held_by_match = re.search(r'held by (?:thread\s+)?(\d+)', line)
                if held_by_match:
                    thread.waiting_info = f"ç­‰å¾…é– {waiting_match.group(1)}ï¼Œè¢«ç·šç¨‹ {held_by_match.group(1)} æŒæœ‰"
            
            # æª¢æŸ¥ parking ç‹€æ…‹
            if 'parking to wait for' in line:
                park_match = re.search(r'parking to wait for\s+<([^>]+)>', line)
                if park_match:
                    thread.waiting_info = f"Parking ç­‰å¾…: {park_match.group(1)}"
    
    def _extract_cross_process_lock_info(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–è·¨é€²ç¨‹é–è³‡è¨Š"""
        for i in range(start_idx + 1, min(start_idx + 20, len(lines))):
            line = lines[i]
            
            # æª¢æŸ¥è·¨é€²ç¨‹ç­‰å¾…
            cross_process_match = re.search(r'held by tid=(\d+) in process (\d+)', line)
            if cross_process_match:
                thread.waiting_info = f"ç­‰å¾…è·¨é€²ç¨‹é–ï¼Œè¢«é€²ç¨‹ {cross_process_match.group(2)} çš„ç·šç¨‹ {cross_process_match.group(1)} æŒæœ‰"
                break
    
    def _extract_thread_cpu_time(self, thread: ThreadInfo, lines: List[str], start_idx: int) -> None:
        """æå–ç·šç¨‹ CPU æ™‚é–“"""
        # æŸ¥æ‰¾ schedstat è³‡è¨Š
        for i in range(start_idx, min(start_idx + 5, len(lines))):
            line = lines[i]
            
            # schedstat æ ¼å¼: schedstat=( é‹è¡Œæ™‚é–“ ç­‰å¾…æ™‚é–“ æ™‚é–“ç‰‡æ¬¡æ•¸ )
            schedstat_match = re.search(r'schedstat=\(\s*(\d+)\s+(\d+)\s+(\d+)\s*\)', line)
            if schedstat_match:
                thread.schedstat = f"é‹è¡Œ:{int(schedstat_match.group(1))/1000000:.1f}ms " \
                                  f"ç­‰å¾…:{int(schedstat_match.group(2))/1000000:.1f}ms"
            
            # utm/stm æ ¼å¼
            utm_match = re.search(r'utm=(\d+)', line)
            stm_match = re.search(r'stm=(\d+)', line)
            if utm_match:
                thread.utm = utm_match.group(1)
            if stm_match:
                thread.stm = stm_match.group(1)
    
    def _find_main_thread(self, threads: List[ThreadInfo]) -> Optional[ThreadInfo]:
        """æ‰¾å‡ºä¸»ç·šç¨‹"""
        # å„ªå…ˆæŸ¥æ‰¾åç‚º "main" çš„ç·šç¨‹
        for thread in threads:
            if thread.name.lower() == "main":
                return thread
        
        # æŸ¥æ‰¾ tid=1 çš„ç·šç¨‹
        for thread in threads:
            if thread.tid == "1":
                return thread
        
        # æŸ¥æ‰¾åŒ…å« ActivityThread çš„ç·šç¨‹
        for thread in threads:
            if any('ActivityThread' in frame for frame in thread.backtrace):
                return thread
        
        return None
    
    def _extract_cpu_usage(self, content: str) -> Optional[Dict]:
        """æå– CPU ä½¿ç”¨ç‡è³‡è¨Š"""
        cpu_info = {}
        
        # æŸ¥æ‰¾ CPU ä½¿ç”¨ç‡æ¨¡å¼
        cpu_patterns = [
            r'CPU:\s*([\d.]+)%\s*usr\s*\+\s*([\d.]+)%\s*sys',
            r'Load:\s*([\d.]+)\s*/\s*([\d.]+)\s*/\s*([\d.]+)',
            r'cpu\s+(\d+)\s+(\d+)\s+(\d+)\s+(\d+)',
        ]
        
        for pattern in cpu_patterns:
            match = re.search(pattern, content)
            if match:
                if 'usr' in pattern:
                    cpu_info['user'] = float(match.group(1))
                    cpu_info['system'] = float(match.group(2))
                    cpu_info['total'] = cpu_info['user'] + cpu_info['system']
                elif 'Load' in pattern:
                    cpu_info['load_1min'] = float(match.group(1))
                    cpu_info['load_5min'] = float(match.group(2))
                    cpu_info['load_15min'] = float(match.group(3))
                break
        
        return cpu_info if cpu_info else None
    
    def _extract_memory_info(self, content: str) -> Optional[Dict]:
        """æå–è¨˜æ†¶é«”è³‡è¨Š"""
        memory_info = {}
        
        # æŸ¥æ‰¾è¨˜æ†¶é«”è³‡è¨Šæ¨¡å¼
        patterns = {
            'total': r'MemTotal:\s*(\d+)\s*kB',
            'free': r'MemFree:\s*(\d+)\s*kB',
            'available': r'MemAvailable:\s*(\d+)\s*kB',
            'buffers': r'Buffers:\s*(\d+)\s*kB',
            'cached': r'Cached:\s*(\d+)\s*kB',
            'swap_total': r'SwapTotal:\s*(\d+)\s*kB',
            'swap_free': r'SwapFree:\s*(\d+)\s*kB',
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, content)
            if match:
                memory_info[key] = int(match.group(1))
        
        # è¨ˆç®—ä½¿ç”¨ç‡
        if 'total' in memory_info and 'available' in memory_info:
            used = memory_info['total'] - memory_info['available']
            memory_info['used_percent'] = (used / memory_info['total']) * 100
        
        return memory_info if memory_info else None
    
    def _generate_report(self, anr_info: ANRInfo, content: str, intelligent_engine=None) -> str:
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        try:
            analyzer = ANRReportGenerator(anr_info, content, intelligent_engine)
            return analyzer.generate()
        except Exception as e:
            # å¦‚æœå ±å‘Šç”Ÿæˆå¤±æ•—ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
            import traceback
            error_trace = traceback.format_exc()
            
            basic_report = [
                "ğŸ¯ ANR åˆ†æå ±å‘Š",
                "=" * 60,
                f"ğŸ“Š ANR é¡å‹: {anr_info.anr_type.value}",
                f"ğŸ“± é€²ç¨‹åç¨±: {anr_info.process_name}",
                f"ğŸ†” é€²ç¨‹ ID: {anr_info.pid}",
                "",
                "âŒ è©³ç´°åˆ†æç”Ÿæˆå¤±æ•—",
                f"éŒ¯èª¤ä¿¡æ¯: {str(e)}",
                "",
                "éŒ¯èª¤è©³æƒ…:",
                error_trace,
                "",
                "åŸºæœ¬ä¿¡æ¯:",
                f"- ç·šç¨‹ç¸½æ•¸: {len(anr_info.all_threads)}",
                f"- ä¸»ç·šç¨‹ç‹€æ…‹: {anr_info.main_thread.state.value if anr_info.main_thread else 'Unknown'}",
            ]
            
            if anr_info.cpu_usage:
                basic_report.append(f"- CPU ä½¿ç”¨ç‡: {anr_info.cpu_usage.get('total', 'N/A')}%")
            
            if anr_info.memory_info:
                available_mb = anr_info.memory_info.get('available', 0) / 1024
                basic_report.append(f"- å¯ç”¨è¨˜æ†¶é«”: {available_mb:.1f} MB")
            
            return "\n".join(basic_report)

class ANRReportGenerator:
    """ANR å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, anr_info: ANRInfo, content: str, intelligent_engine=None, 
                 output_format: str = 'text', source_linker: Optional[SourceLinker] = None):
        self.anr_info = anr_info
        self.content = content
        self.report_lines = []
        self.intelligent_engine = intelligent_engine or IntelligentAnalysisEngine()
        self.output_format = output_format
        self.source_linker = source_linker
        
        # å¦‚æœæ˜¯ HTML æ ¼å¼ï¼Œå‰µå»º HTML ç”Ÿæˆå™¨
        if output_format == 'html' and source_linker:
            self.html_generator = HTMLReportGenerator(source_linker)
    
    def generate(self) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        try:
            if self.output_format == 'html':
                return self._generate_html_report()
            else:
                return self._generate_text_report()
        except Exception as e:
            # ç¢ºä¿ç¸½æ˜¯è¿”å›ä¸€äº›å…§å®¹
            error_msg = f"å ±å‘Šç”Ÿæˆå¤±æ•—: {str(e)}\n"
            error_msg += f"ANR é¡å‹: {self.anr_info.anr_type.value}\n"
            error_msg += f"é€²ç¨‹: {self.anr_info.process_name}\n"
            error_msg += f"ç·šç¨‹æ•¸: {len(self.anr_info.all_threads)}\n"
            
            # å˜—è©¦è‡³å°‘ç”ŸæˆåŸºæœ¬çš„æ–‡å­—å ±å‘Š
            try:
                self.report_lines = [error_msg]
                self._add_summary()
                self._add_basic_info()
                return "\n".join(self.report_lines)
            except:
                return error_msg

    def _generate_text_report(self) -> str:
        self._add_summary()
        self._add_basic_info()
        self._add_main_thread_analysis()
        self._add_root_cause_analysis()
        self._add_intelligent_analysis()
        self._add_thread_analysis()
        self._add_deadlock_detection()
        self._add_binder_chain_analysis()      # æ–°å¢
        self._add_thread_dependency_graph()    # æ–°å¢
        self._add_performance_bottleneck()     # æ–°å¢        
        self._add_watchdog_analysis()      # æ–°å¢
        self._add_strictmode_analysis()    # æ–°å¢
        self._add_gc_analysis()            # æ–°å¢
        self._add_performance_analysis()
        self._add_system_health_score()    # æ–°å¢
        self._add_suggestions()
        
        return "\n".join(self.report_lines)

    def _generate_html_report(self) -> str:
        """ç”Ÿæˆ HTML å ±å‘Š"""
        # ç”Ÿæˆ HTML é ­éƒ¨
        html_content = f'''<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ANR åˆ†æå ±å‘Š - {self.anr_info.process_name}</title>
    <style>
        {self._get_report_css()}
    </style>
</head>
<body>
    <div class="container">
        <header class="report-header">
            <h1>ğŸ¯ ANR åˆ†æå ±å‘Š</h1>
            <div class="report-meta">
                <span class="process-name">{html.escape(self.anr_info.process_name)}</span>
                <span class="pid">PID: {self.anr_info.pid}</span>
                <span class="anr-type">{self.anr_info.anr_type.value}</span>
            </div>
        </header>
        
        <div class="report-content">
        '''

        # æ·»åŠ æ™‚é–“ç·šåˆ†æ
        self._add_html_timeline_analysis()
        
        # æ·»åŠ  AI ç•°å¸¸æª¢æ¸¬
        self._add_html_anomaly_detection()
        
        # æ·»åŠ é¢¨éšªè©•ä¼°
        self._add_html_risk_assessment()
        
        # æ·»åŠ ä»£ç¢¼ä¿®å¾©å»ºè­°
        self._add_html_code_fix_suggestions()
        
        # æ·»åŠ åŸ·è¡Œæ‘˜è¦ï¼ˆæ”¾åœ¨æœ€å‰é¢ï¼‰
        executive_summary = self._generate_executive_summary()

        # æ·»åŠ æ‘˜è¦
        self._add_html_summary()
        
        # æ·»åŠ ä¸»ç·šç¨‹åˆ†æ
        self._add_html_main_thread_analysis()
        
        # æ·»åŠ  Binder åˆ†æ
        self._add_html_binder_analysis()
        
        # æ·»åŠ ç·šç¨‹ä¾è³´åœ–
        self._add_html_thread_dependency()
        
        # æ·»åŠ æ€§èƒ½ç“¶é ¸
        self._add_html_performance_bottleneck()
        
        # æ·»åŠ å»ºè­°
        self._add_html_suggestions()
        
        html_content += self.html_generator.generate_html()
        
        html_content += '''
        </div>
        
        <footer class="report-footer">
            <p>ç”Ÿæˆæ™‚é–“: ''' + time.strftime('%Y-%m-%d %H:%M:%S') + '''</p>
        </footer>
    </div>
    
    <script>
        ''' + self._get_report_javascript() + '''
    </script>
</body>
</html>'''
        
        return html_content
    
    def _get_report_css(self) -> str:
        """ç²å–å ±å‘Šçš„ CSS æ¨£å¼"""
        return '''
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        :root {
            --primary-color: #10a37f;
            --primary-hover: #0d8f6f;
            --background: #ffffff;
            --surface: #f7f7f8;
            --border: #e5e5e5;
            --text-primary: #2d2d2d;
            --text-secondary: #666666;
            --text-muted: #999999;
            --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px rgba(0, 0, 0, 0.07);
            --shadow-lg: 0 10px 15px rgba(0, 0, 0, 0.1);
            --radius: 8px;
            --transition: all 0.2s ease;
            --anr-color: #dc3545;
            --anr-bg: #fff5f5;
            --anr-bg-hover: #fee0e0;
            --anr-border: #feb2b2;
            --tombstone-color: #6f42c1;
            --tombstone-bg: #f7f3ff;
            --tombstone-bg-hover: #ebe0ff;
            --tombstone-border: #d6bcfa;
        }
        
        @media (prefers-color-scheme: dark) {
            :root {
                --background: #1a1a1a;
                --surface: #2a2a2a;
                --border: #404040;
                --text-primary: #ffffff;
                --text-secondary: #c5c5c5;
                --text-muted: #8e8e8e;
                --anr-bg: #3a1f23;
                --anr-bg-hover: #4a2833;
                --anr-border: #9b2c2c;
                --tombstone-bg: #2d2440;
                --tombstone-bg-hover: #3d3050;
                --tombstone-border: #553c9a;
            }
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
            background: var(--background);
            color: var(--text-primary);
            line-height: 1.6;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        /* Header */
        .header {
            padding: 40px 0;
            border-bottom: 1px solid var(--border);
            margin-bottom: 32px;
        }
        
        .header h1 {
            font-size: 32px;
            font-weight: 600;
            margin-bottom: 8px;
            color: var(--text-primary);
        }
        
        .header .subtitle {
            font-size: 16px;
            color: var(--text-secondary);
            margin-bottom: 24px;
        }
        
        /* Stats Grid */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 16px;
            margin-bottom: 40px;
        }
        
        .stat-card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: var(--radius);
            padding: 20px;
            transition: var(--transition);
        }
        
        .stat-card:hover {
            box-shadow: var(--shadow-md);
            border-color: var(--primary-color);
        }
        
        .stat-card .label {
            font-size: 14px;
            color: var(--text-secondary);
            margin-bottom: 4px;
        }
        
        .stat-card .value {
            font-size: 28px;
            font-weight: 600;
            color: var(--primary-color);
        }
        
        /* Main Content */
        .main-content {
            margin-bottom: 40px;
        }
        
        .section-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 24px;
        }
        
        .section-header h2 {
            font-size: 24px;
            font-weight: 600;
            color: var(--text-primary);
        }
        
        /* File Browser */
        .file-browser {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: var(--radius);
            overflow: hidden;
        }
        
        .file-item, .folder-item {
            border-bottom: 1px solid var(--border);
            transition: var(--transition);
        }
        
        .file-item:last-child, .folder-item:last-child {
            border-bottom: none;
        }
        
        .file-item:hover {
            box-shadow: inset 0 0 0 1px var(--border);
        }
        
        /* ANR å’Œ Tombstone æª”æ¡ˆçš„ä¸åŒé¡è‰² - å¢å¼·ç‰ˆ */
        .anr-item {
            background-color: var(--anr-bg);
            border-left: 4px solid var(--anr-color);
            position: relative;
        }
        
        .anr-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(90deg, 
                rgba(220, 53, 69, 0.1) 0%, 
                transparent 100%);
            opacity: 0;
            transition: opacity 0.2s ease;
        }
        
        .anr-item:hover {
            background-color: var(--anr-bg-hover);
            border-left-width: 6px;
        }
        
        .anr-item:hover::before {
            opacity: 1;
        }
        
        .tombstone-item {
            background-color: var(--tombstone-bg);
            border-left: 4px solid var(--tombstone-color);
            position: relative;
        }
        
        .tombstone-item::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(90deg, 
                rgba(111, 66, 193, 0.1) 0%, 
                transparent 100%);
            opacity: 0;
            transition: opacity 0.2s ease;
        }
        
        .tombstone-item:hover {
            background-color: var(--tombstone-bg-hover);
            border-left-width: 6px;
        }
        
        .tombstone-item:hover::before {
            opacity: 1;
        }
        
        .file-content {
            padding: 16px 20px;
            display: flex;
            align-items: center;
            gap: 12px;
        }
        
        .file-icon {
            font-size: 24px;
            flex-shrink: 0;
            filter: drop-shadow(0 1px 2px rgba(0, 0, 0, 0.1));
        }
        
        .anr-item .file-icon {
            color: var(--anr-color);
        }
        
        .tombstone-item .file-icon {
            color: var(--tombstone-color);
        }
        
        .file-info {
            flex: 1;
            min-width: 0;
        }
        
        .file-name {
            font-size: 15px;
            font-weight: 500;
            color: var(--text-primary);
            text-decoration: none;
            display: block;
            margin-bottom: 4px;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
            transition: var(--transition);
        }
        
        .file-name:hover {
            color: var(--primary-color);
        }
        
        .file-meta {
            display: flex;
            align-items: center;
            gap: 12px;
            font-size: 13px;
        }
        
        .file-type {
            padding: 3px 10px;
            border-radius: 4px;
            font-weight: 600;
            font-size: 12px;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            color: white;
        }
        
        .file-type-anr {
            background: var(--anr-color);
            box-shadow: 0 2px 4px rgba(220, 53, 69, 0.2);
        }
        
        .file-type-tombstone {
            background: var(--tombstone-color);
            box-shadow: 0 2px 4px rgba(111, 66, 193, 0.2);
        }
        
        .source-link {
            color: var(--text-secondary);
            text-decoration: none;
            transition: var(--transition);
        }
        
        .source-link:hover {
            color: var(--primary-color);
            text-decoration: underline;
        }
        
        /* Folder */
        .folder-header {
            padding: 16px 20px;
            display: flex;
            align-items: center;
            gap: 12px;
            cursor: pointer;
            user-select: none;
            transition: var(--transition);
        }
        
        .folder-header:hover {
            background: var(--background);
        }
        
        .folder-arrow {
            color: var(--text-secondary);
            transition: transform 0.2s ease;
            flex-shrink: 0;
        }
        
        .folder-arrow.open {
            transform: rotate(180deg);
        }
        
        .folder-icon {
            font-size: 20px;
            flex-shrink: 0;
        }
        
        .folder-name {
            font-size: 15px;
            font-weight: 500;
            color: var(--text-primary);
            flex: 1;
        }
        
        .folder-count {
            font-size: 13px;
            color: var(--text-muted);
        }
        
        .folder-content {
            background: var(--background);
            border-top: 1px solid var(--border);
            padding-left: 20px;
        }
        
        /* Features */
        .features {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: var(--radius);
            padding: 24px;
            margin-bottom: 32px;
        }
        
        .features h3 {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 16px;
            color: var(--text-primary);
        }
        
        .features ul {
            list-style: none;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 12px;
        }
        
        .features li {
            display: flex;
            align-items: flex-start;
            gap: 8px;
            font-size: 14px;
            color: var(--text-secondary);
        }
        
        .features li::before {
            content: "âœ“";
            color: var(--primary-color);
            font-weight: bold;
            flex-shrink: 0;
        }
        
        /* Footer */
        .footer {
            padding: 32px 0;
            border-top: 1px solid var(--border);
            text-align: center;
            color: var(--text-secondary);
            font-size: 14px;
        }
        
        /* Responsive */
        @media (max-width: 768px) {
            .header h1 {
                font-size: 24px;
            }
            
            .stats-grid {
                grid-template-columns: repeat(2, 1fr);
            }
            
            .features ul {
                grid-template-columns: 1fr;
            }
            
            .file-meta {
                flex-wrap: wrap;
                gap: 8px;
            }
        }
        '''

    def _get_report_javascript(self) -> str:
        """ç²å–å ±å‘Šçš„ JavaScript"""
        return '''
        // è™•ç†é€£çµé»æ“Š
        document.addEventListener('click', function(e) {
            if (e.target.classList.contains('source-link') || 
                e.target.classList.contains('frame-link')) {
                e.preventDefault();
                
                const href = e.target.getAttribute('href');
                const lineNumber = e.target.getAttribute('data-line');
                
                // å‰µå»ºä¸¦é¡¯ç¤ºæµ®å‹•è¦–çª—
                showSourceViewer(href, lineNumber);
            }
        });
        
        // é¡¯ç¤ºæºç¢¼æŸ¥çœ‹å™¨
        function showSourceViewer(filePath, lineNumber) {
            // å¦‚æœå·²å­˜åœ¨æŸ¥çœ‹å™¨ï¼Œå…ˆç§»é™¤
            const existingViewer = document.getElementById('source-viewer');
            if (existingViewer) {
                existingViewer.remove();
            }
            
            // å‰µå»ºæŸ¥çœ‹å™¨
            const viewer = document.createElement('div');
            viewer.id = 'source-viewer';
            viewer.className = 'source-viewer';
            viewer.innerHTML = `
                <div class="viewer-header">
                    <span class="viewer-title">${filePath} - Line ${lineNumber}</span>
                    <button class="viewer-close" onclick="closeSourceViewer()">âœ•</button>
                </div>
                <div class="viewer-content">
                    <iframe src="${filePath}#L${lineNumber}" 
                            onload="scrollToLine(this, ${lineNumber})"></iframe>
                </div>
            `;
            
            document.body.appendChild(viewer);
            
            // æ·»åŠ æ¨£å¼
            addViewerStyles();
        }
        
        function closeSourceViewer() {
            const viewer = document.getElementById('source-viewer');
            if (viewer) {
                viewer.remove();
            }
        }
        
        function scrollToLine(iframe, lineNumber) {
            try {
                const doc = iframe.contentDocument || iframe.contentWindow.document;
                const lineElement = doc.getElementById('L' + lineNumber);
                if (lineElement) {
                    lineElement.scrollIntoView({ behavior: 'smooth', block: 'center' });
                    lineElement.style.backgroundColor = '#ffffcc';
                }
            } catch (e) {
                console.error('Unable to scroll to line:', e);
            }
        }
        
        function addViewerStyles() {
            if (document.getElementById('viewer-styles')) return;
            
            const style = document.createElement('style');
            style.id = 'viewer-styles';
            style.textContent = `
                .source-viewer {
                    position: fixed;
                    top: 50%;
                    left: 50%;
                    transform: translate(-50%, -50%);
                    width: 80%;
                    height: 80%;
                    background: white;
                    border-radius: 8px;
                    box-shadow: 0 10px 30px rgba(0,0,0,0.3);
                    z-index: 10000;
                    display: flex;
                    flex-direction: column;
                }
                
                .viewer-header {
                    display: flex;
                    justify-content: space-between;
                    align-items: center;
                    padding: 15px 20px;
                    background: #f5f5f5;
                    border-bottom: 1px solid #ddd;
                    border-radius: 8px 8px 0 0;
                }
                
                .viewer-title {
                    font-weight: bold;
                    font-size: 16px;
                }
                
                .viewer-close {
                    background: none;
                    border: none;
                    font-size: 24px;
                    cursor: pointer;
                    color: #666;
                    padding: 0 5px;
                }
                
                .viewer-close:hover {
                    color: #333;
                }
                
                .viewer-content {
                    flex: 1;
                    overflow: hidden;
                }
                
                .viewer-content iframe {
                    width: 100%;
                    height: 100%;
                    border: none;
                }
            `;
            document.head.appendChild(style);
        }
        
        // æ·»åŠ è¡Œè™Ÿæç¤º
        let tooltip = null;
        
        document.addEventListener('mouseover', function(e) {
            if (e.target.classList.contains('source-link') || 
                e.target.classList.contains('frame-link')) {
                const lineNumber = e.target.getAttribute('data-line');
                if (lineNumber) {
                    showLineTooltip(e.target, lineNumber);
                }
            }
        });
        
        document.addEventListener('mouseout', function(e) {
            if (e.target.classList.contains('source-link') || 
                e.target.classList.contains('frame-link')) {
                hideLineTooltip();
            }
        });
        
        function showLineTooltip(element, lineNumber) {
            if (!tooltip) {
                tooltip = document.createElement('div');
                tooltip.className = 'line-tooltip';
                document.body.appendChild(tooltip);
            }
            
            tooltip.textContent = `Line ${lineNumber}`;
            
            const rect = element.getBoundingClientRect();
            tooltip.style.left = rect.left + 'px';
            tooltip.style.top = (rect.top - 30) + 'px';
            
            setTimeout(() => {
                tooltip.classList.add('show');
            }, 10);
        }
        
        function hideLineTooltip() {
            if (tooltip) {
                tooltip.classList.remove('show');
            }
        }
        '''
    
    def _add_html_summary(self):
        """æ·»åŠ  HTML æ ¼å¼çš„æ‘˜è¦"""
        severity = self._assess_severity()
        root_cause = self._quick_root_cause()
        
        severity_class = 'critical' if 'æ¥µå…¶åš´é‡' in severity else 'warning' if 'åš´é‡' in severity else 'info'
        
        content = f'''
        <div class="summary-grid">
            <div class="summary-item {severity_class}">
                <h3>åš´é‡ç¨‹åº¦</h3>
                <p>{severity}</p>
            </div>
            <div class="summary-item">
                <h3>å¯èƒ½åŸå› </h3>
                <p>{root_cause}</p>
            </div>
            <div class="summary-item">
                <h3>ç™¼ç”Ÿæ™‚é–“</h3>
                <p>{self.anr_info.timestamp or 'Unknown'}</p>
            </div>
        </div>
        '''
        
        self.html_generator.add_section('æ‘˜è¦', content, 'summary-section')
    
    def _add_html_main_thread_analysis(self):
        """æ·»åŠ  HTML æ ¼å¼çš„ä¸»ç·šç¨‹åˆ†æ"""
        if not self.anr_info.main_thread:
            self.html_generator.add_section('ä¸»ç·šç¨‹åˆ†æ', '<p>æœªæ‰¾åˆ°ä¸»ç·šç¨‹è³‡è¨Š</p>')
            return
        
        # æ·»åŠ ä¸»ç·šç¨‹å †ç–Š
        self.html_generator.add_backtrace(
            'ä¸»ç·šç¨‹å †ç–Šè¿½è¹¤',
            self.anr_info.main_thread.backtrace
        )

    def _add_binder_chain_analysis(self):
        """æ·»åŠ  Binder èª¿ç”¨éˆåˆ†æ"""
        self.report_lines.append("\nğŸ”— Binder èª¿ç”¨éˆè©³ç´°åˆ†æ")
        
        # å‰µå»ºåˆ†æå™¨
        binder_analyzer = BinderCallChainAnalyzer()
        
        if self.anr_info.main_thread:
            chain_analysis = binder_analyzer.analyze_binder_chain(
                self.anr_info.main_thread.backtrace
            )
            
            if chain_analysis['call_sequence']:
                self.report_lines.append(f"\nğŸ“Š Binder èª¿ç”¨åºåˆ— (å…± {len(chain_analysis['call_sequence'])} æ¬¡è·¨é€²ç¨‹èª¿ç”¨):")
                
                for i, call in enumerate(chain_analysis['call_sequence'], 1):
                    self.report_lines.append(
                        f"  {i}. {call['service']}.{call['method']} "
                        f"(é ä¼°å»¶é²: {call['estimated_latency']}ms)"
                    )
                    if call.get('transaction_code'):
                        self.report_lines.append(f"      äº‹å‹™ç¢¼: {call['transaction_code']}")
                
                self.report_lines.append(f"\nâ±ï¸ ç¸½å»¶é²: {chain_analysis['total_latency']}ms")
                
                if chain_analysis['bottlenecks']:
                    self.report_lines.append("\nğŸš« è­˜åˆ¥çš„ç“¶é ¸:")
                    for bottleneck in chain_analysis['bottlenecks']:
                        self.report_lines.append(
                            f"  â€¢ {bottleneck['service']}.{bottleneck['method']} "
                            f"({bottleneck['latency']}ms)"
                        )
                        self.report_lines.append(f"    åŸå› : {bottleneck['reason']}")
                
                if chain_analysis['recommendation']:
                    self.report_lines.append(f"\nğŸ’¡ å„ªåŒ–å»ºè­°: {chain_analysis['recommendation']}")
            else:
                self.report_lines.append("  âœ… æœªæª¢æ¸¬åˆ° Binder èª¿ç”¨")

    def _add_thread_dependency_graph(self):
        """æ·»åŠ ç·šç¨‹ä¾è³´é—œä¿‚åœ–"""
        self.report_lines.append("\nğŸ•¸ï¸ ç·šç¨‹ä¾è³´é—œä¿‚åˆ†æ")
        
        # å‰µå»ºåˆ†æå™¨
        dependency_analyzer = ThreadDependencyAnalyzer()
        
        dep_analysis = dependency_analyzer.analyze_thread_dependencies(
            self.anr_info.all_threads
        )
        
        # é¡¯ç¤º ASCII åœ–
        if dep_analysis.get('visualization'):
            viz = dep_analysis['visualization']
            # æª¢æŸ¥æ˜¯å¦çœŸçš„åŒ…å«åœ–å½¢å…ƒç´ ï¼ˆå¦‚ â†’ æˆ–å…¶ä»–åœ–å½¢å­—ç¬¦ï¼‰
            if any(char in viz for char in ['â†’', 'â†', 'â†”', 'â”€', 'â”‚', 'â”Œ', 'â””', 'â”œ', 'â”¤']):
                self.report_lines.append("\n\nç·šç¨‹ä¾è³´é—œä¿‚åœ–:")
                self.report_lines.append(viz)
            else:
                # å¦‚æœåªæ˜¯æ–‡æœ¬ï¼Œç›´æ¥é¡¯ç¤º
                self.report_lines.append(viz)
                self.report_lines.append("\n\n  â„¹ï¸ æœªç”Ÿæˆä¾è³´é—œä¿‚è¦–è¦ºåŒ–åœ–è¡¨")
        else:
            # å¦‚æœæ²’æœ‰è¦–è¦ºåŒ–ï¼Œé¡¯ç¤ºåŸºæœ¬ä¿¡æ¯
            self.report_lines.append("  â„¹ï¸ æœªç”Ÿæˆä¾è³´é—œä¿‚åœ–")
        
        # é¡¯ç¤ºæ­»é–è©³æƒ…ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰- é€™éƒ¨åˆ†ä¿æŒä¸è®Š
        if dep_analysis.get('deadlock_cycles'):
            self.report_lines.append("\nğŸ”´ æ­»é–è©³ç´°åˆ†æ:")
            for i, cycle in enumerate(dep_analysis['deadlock_cycles'], 1):
                self.report_lines.append(f"  æ­»é–å¾ªç’° {i}:")
                for thread_info in cycle:
                    self.report_lines.append(
                        f"    â€¢ ç·šç¨‹ {thread_info['tid']} ({thread_info['name']}) "
                        f"- {thread_info['state']}"
                    )
                    if thread_info.get('waiting_on'):
                        self.report_lines.append(f"      ç­‰å¾…: {thread_info['waiting_on']}")
        else:
            self.report_lines.append("  âœ… æœªæª¢æ¸¬åˆ°æ­»é–")
        
        # ç¢ºä¿é¡¯ç¤ºé˜»å¡éˆ
        if dep_analysis.get('blocking_chains'):
            self.report_lines.append("\nğŸŸ¡ ä¸»è¦é˜»å¡éˆ:")
            for chain in dep_analysis['blocking_chains'][:3]:
                self.report_lines.append(
                    f"  â€¢ {chain['blocker_name']} (tid={chain['blocker']}) "
                    f"é˜»å¡äº† {chain['impact']} å€‹ç·šç¨‹"
                )
                self.report_lines.append(f"    åš´é‡æ€§: {chain['severity']}")
        else:
            self.report_lines.append("\n  â„¹ï¸ æœªç™¼ç¾æ˜é¡¯çš„é˜»å¡éˆ")
        
        # ç¢ºä¿é¡¯ç¤ºé—œéµè·¯å¾‘
        if dep_analysis.get('critical_paths'):
            self.report_lines.append("\nğŸ”µ é—œéµé˜»å¡è·¯å¾‘:")
            for path_info in dep_analysis['critical_paths'][:3]:
                path_str = " â†’ ".join(path_info['path'][:5])
                if len(path_info['path']) > 5:
                    path_str += f" â†’ ... ({len(path_info['path'])-5} more)"
                self.report_lines.append(
                    f"  â€¢ {path_info['type']}: {path_str}"
                )
                self.report_lines.append(f"    åš´é‡æ€§: {path_info['severity']}")
        else:
            self.report_lines.append("\n  â„¹ï¸ æœªç™¼ç¾é—œéµé˜»å¡è·¯å¾‘")

    def _add_performance_bottleneck(self):
        """æ·»åŠ æ€§èƒ½ç“¶é ¸è‡ªå‹•è­˜åˆ¥"""
        self.report_lines.append("\nğŸ¯ æ€§èƒ½ç“¶é ¸è‡ªå‹•è­˜åˆ¥")
        
        # å‰µå»ºæª¢æ¸¬å™¨
        bottleneck_detector = PerformanceBottleneckDetector()
        
        bottleneck_analysis = bottleneck_detector.detect_bottlenecks(
            self.anr_info,
            self.content
        )
        
        # é¡¯ç¤ºæ•´é«”è©•åˆ†
        score = bottleneck_analysis['overall_score']
        score_emoji = "ğŸŸ¢" if score >= 80 else "ğŸŸ¡" if score >= 60 else "ğŸŸ " if score >= 40 else "ğŸ”´"
        self.report_lines.append(f"\n{score_emoji} æ€§èƒ½è©•åˆ†: {score}/100")
        
        # é¡¯ç¤ºä¸»è¦å•é¡Œ
        if bottleneck_analysis['top_issues']:
            self.report_lines.append("\nğŸš¨ è­˜åˆ¥çš„ä¸»è¦ç“¶é ¸:")
            for i, issue in enumerate(bottleneck_analysis['top_issues'], 1):
                severity_emoji = {
                    'critical': 'ğŸ”´',
                    'high': 'ğŸŸ ',
                    'medium': 'ğŸŸ¡',
                    'low': 'ğŸŸ¢'
                }.get(issue['severity'], 'âšª')
                
                self.report_lines.append(
                    f"\n  {i}. {severity_emoji} {issue['description']}"
                )
                self.report_lines.append(f"     å½±éŸ¿: {issue['impact']}")
                
                # é¡¯ç¤ºè©³ç´°æ•¸æ“š
                if issue.get('gc_stats'):
                    stats = issue['gc_stats']
                    self.report_lines.append(
                        f"     GC çµ±è¨ˆ: {stats['count']} æ¬¡, "
                        f"å¹³å‡ {stats['avg_pause']}ms, æœ€å¤§ {stats['max_pause']}ms"
                    )
                elif issue.get('lock_analysis'):
                    analysis = issue['lock_analysis']
                    self.report_lines.append(
                        f"     é–åˆ†æ: {analysis['total_waiting']} å€‹ç­‰å¾…, "
                        f"{analysis['unique_locks']} å€‹ç¨ç‰¹é–"
                    )
                
                # é¡¯ç¤ºè§£æ±ºæ–¹æ¡ˆ
                if issue.get('solutions'):
                    self.report_lines.append("     è§£æ±ºæ–¹æ¡ˆ:")
                    for solution in issue['solutions'][:3]:
                        self.report_lines.append(f"       â€¢ {solution}")
        
        # é¡¯ç¤ºç¸½é«”å»ºè­°
        if bottleneck_analysis['recommendations']:
            self.report_lines.append("\nğŸ“‹ å„ªåŒ–å»ºè­°å„ªå…ˆç´š:")
            for i, rec in enumerate(bottleneck_analysis['recommendations'], 1):
                self.report_lines.append(f"  {i}. {rec}")
                
    def _add_performance_analysis(self):
        """æ·»åŠ æ€§èƒ½åˆ†æ"""
        self.report_lines.append("\nâš¡ æ€§èƒ½åˆ†æ")
        
        perf_issues = []
        
        # åˆå§‹åŒ–è®Šæ•¸
        available_mb = float('inf')  # é è¨­ç‚ºç„¡é™å¤§
        total_cpu = 0
        
        # 1. ç·šç¨‹æ•¸é‡åˆ†æ
        thread_count = len(self.anr_info.all_threads)
        if thread_count > 200:
            perf_issues.append(f"ç·šç¨‹æ•¸é‡éå¤š: {thread_count} å€‹ (å»ºè­°: < 100)")
            perf_issues.append("  å¯èƒ½åŸå› : ç·šç¨‹æ´©æ¼ã€éåº¦ä½¿ç”¨ç·šç¨‹æ± ")
        elif thread_count > 100:
            perf_issues.append(f"ç·šç¨‹æ•¸é‡è¼ƒå¤š: {thread_count} å€‹")
        
        # 2. èª¿ç”¨æ·±åº¦åˆ†æ
        if self.anr_info.main_thread and len(self.anr_info.main_thread.backtrace) > 50:
            depth = len(self.anr_info.main_thread.backtrace)
            perf_issues.append(f"ä¸»ç·šç¨‹èª¿ç”¨éˆéæ·±: {depth} å±¤")
            perf_issues.append("  å¯èƒ½åŸå› : éè¿´èª¿ç”¨ã€éåº¦çš„æ–¹æ³•åµŒå¥—")
        
        # 3. Binder ç·šç¨‹åˆ†æ
        binder_threads = [t for t in self.anr_info.all_threads if 'Binder' in t.name]
        if len(binder_threads) > 0:
            binder_busy = sum(1 for t in binder_threads if t.state != ThreadState.WAIT)
            if binder_busy == len(binder_threads):
                perf_issues.append(f"æ‰€æœ‰ Binder ç·šç¨‹éƒ½åœ¨å¿™ç¢Œ ({binder_busy}/{len(binder_threads)})")
                perf_issues.append("  å¯èƒ½å°è‡´ IPC è«‹æ±‚æ’éšŠ")
        
        # 4. é–ç«¶çˆ­åˆ†æ
        blocked_on_locks = sum(1 for t in self.anr_info.all_threads 
                              if t.state == ThreadState.BLOCKED or t.waiting_locks)
        if blocked_on_locks > 5:
            perf_issues.append(f"å¤§é‡ç·šç¨‹åœ¨ç­‰å¾…é–: {blocked_on_locks} å€‹")
            perf_issues.append("  å»ºè­°: å„ªåŒ–é–çš„ç²’åº¦ï¼Œä½¿ç”¨ç„¡é–æ•¸æ“šçµæ§‹")
        
        # 5. è¨˜æ†¶é«”å£“åŠ›å°æ€§èƒ½çš„å½±éŸ¿
        if self.anr_info.memory_info:
            available_mb = self.anr_info.memory_info.get('available', float('inf')) / 1024
            if available_mb < 100:
                perf_issues.append(f"ä½è¨˜æ†¶é«”å¯èƒ½å½±éŸ¿æ€§èƒ½: {available_mb:.1f} MB")
                perf_issues.append("  å½±éŸ¿: é »ç¹ GCã€é é¢äº¤æ›")
        
        # 6. CPU åˆ†æ
        if self.anr_info.cpu_usage:
            total_cpu = self.anr_info.cpu_usage.get('total', 0)
            if total_cpu > 80:
                perf_issues.append(f"CPU ä½¿ç”¨ç‡é«˜: {total_cpu:.1f}%")
                
                # åˆ†æ load average
                load_1 = self.anr_info.cpu_usage.get('load_1min', 0)
                if load_1 > 4.0:
                    perf_issues.append(f"  ç³»çµ±è² è¼‰éé«˜: {load_1}")
        
        # 7. GC å½±éŸ¿åˆ†æ
        gc_pause_pattern = r'paused\s+(\d+)ms'
        gc_pauses = re.findall(gc_pause_pattern, self.content)
        if gc_pauses:
            total_pause = sum(int(pause) for pause in gc_pauses)
            max_pause = max(int(pause) for pause in gc_pauses)
            if total_pause > 500:
                perf_issues.append(f"GC æš«åœæ™‚é–“éé•·: ç¸½è¨ˆ {total_pause}ms, æœ€å¤§ {max_pause}ms")
        
        # 8. ç·šç¨‹å„ªå…ˆç´šåˆ†æ
        high_prio_blocked = 0
        for thread in self.anr_info.all_threads:
            if thread.prio and thread.prio.isdigit() and int(thread.prio) <= 5:
                if thread.state == ThreadState.BLOCKED or thread.waiting_locks:
                    high_prio_blocked += 1
        
        if high_prio_blocked > 0:
            perf_issues.append(f"é«˜å„ªå…ˆç´šç·šç¨‹è¢«é˜»å¡: {high_prio_blocked} å€‹")
            perf_issues.append("  å¯èƒ½å­˜åœ¨å„ªå…ˆç´šåè½‰å•é¡Œ")
        
        # é¡¯ç¤ºçµæœ
        if perf_issues:
            self.report_lines.extend(f"  â€¢ {issue}" for issue in perf_issues)
        else:
            self.report_lines.append("  âœ… æœªç™¼ç¾æ˜é¡¯æ€§èƒ½å•é¡Œ")
        
        # æ€§èƒ½è©•åˆ†
        perf_score = 100
        perf_score -= min(thread_count // 50, 20)  # ç·šç¨‹æ•¸æ‰£åˆ†
        perf_score -= min(blocked_on_locks * 2, 20)  # é–ç«¶çˆ­æ‰£åˆ†
        if available_mb < 100:
            perf_score -= 20  # è¨˜æ†¶é«”æ‰£åˆ†
        if total_cpu > 90:
            perf_score -= 20  # CPU æ‰£åˆ†
        
        perf_score = max(perf_score, 0)
        
        self.report_lines.append(f"\n  æ€§èƒ½è©•åˆ†: {perf_score}/100")
        if perf_score < 60:
            self.report_lines.append("  âš ï¸ æ€§èƒ½å•é¡Œéœ€è¦ç«‹å³è™•ç†")
    
    def _add_suggestions(self):
        """æ·»åŠ è§£æ±ºå»ºè­°"""
        self.report_lines.append("\nğŸ’¡ è§£æ±ºå»ºè­°")
        
        suggestions = self._generate_suggestions()
        
        # ç«‹å³è¡Œå‹•é …
        if suggestions['immediate']:
            self.report_lines.append("\nğŸš¨ ç«‹å³è¡Œå‹•:")
            for i, suggestion in enumerate(suggestions['immediate'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # å„ªåŒ–å»ºè­°
        if suggestions['optimization']:
            self.report_lines.append("\nğŸ”§ å„ªåŒ–å»ºè­°:")
            for i, suggestion in enumerate(suggestions['optimization'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # èª¿æŸ¥æ–¹å‘
        if suggestions['investigation']:
            self.report_lines.append("\nğŸ” èª¿æŸ¥æ–¹å‘:")
            for i, suggestion in enumerate(suggestions['investigation'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # é é˜²æªæ–½
        self.report_lines.append("\nğŸ›¡ï¸ é é˜²æªæ–½:")
        prevention_suggestions = [
            "å®šæœŸä½¿ç”¨ Android Studio Profiler ç›£æ§æ‡‰ç”¨æ€§èƒ½",
            "åœ¨é–‹ç™¼éšæ®µå•Ÿç”¨ StrictMode æª¢æ¸¬é•è¦æ“ä½œ",
            "å¯¦æ–½ CI/CD ä¸­çš„æ€§èƒ½æ¸¬è©¦",
            "ç›£æ§ç”Ÿç”¢ç’°å¢ƒçš„ ANR ç‡ (ç›®æ¨™ < 0.47%)",
            "å»ºç«‹ ANR é è­¦æ©Ÿåˆ¶å’Œè‡ªå‹•åŒ–åˆ†æ",
        ]
        
        for i, suggestion in enumerate(prevention_suggestions, 1):
            self.report_lines.append(f"  {i}. {suggestion}")
        
        # å·¥å…·æ¨è–¦
        self.report_lines.append("\nğŸ”¨ æ¨è–¦å·¥å…·:")
        tools = [
            "Systrace - ç³»çµ±ç´šæ€§èƒ½åˆ†æ",
            "Method Tracing - æ–¹æ³•ç´šæ€§èƒ½åˆ†æ",
            "Android Studio Profiler - CPUã€è¨˜æ†¶é«”ã€ç¶²è·¯åˆ†æ",
            "Firebase Performance Monitoring - ç”Ÿç”¢ç’°å¢ƒç›£æ§",
            "Perfetto - æ–°ä¸€ä»£è¿½è¹¤å·¥å…·",
        ]
        
        for tool in tools:
            self.report_lines.append(f"  â€¢ {tool}")
        
        # ç›¸é—œæ–‡æª”
        self.report_lines.append("\nğŸ“š ç›¸é—œæ–‡æª”:")
        docs = [
            "Android å®˜æ–¹ ANR æ–‡æª”: https://developer.android.com/topic/performance/vitals/anr",
            "Thread å’Œ Process æŒ‡å—: https://developer.android.com/guide/components/processes-and-threads",
            "æ€§èƒ½å„ªåŒ–æœ€ä½³å¯¦è¸: https://developer.android.com/topic/performance/",
        ]
        
        for doc in docs:
            self.report_lines.append(f"  â€¢ {doc}")

    def _add_summary(self):
        """æ·»åŠ æ‘˜è¦"""
        self.report_lines.extend([
            "ğŸ¯ ANR åˆ†æå ±å‘Š",
            "=" * 60,
            f"ğŸ“Š ANR é¡å‹: {self.anr_info.anr_type.value}",
            f"ğŸ“± é€²ç¨‹åç¨±: {self.anr_info.process_name}",
            f"ğŸ†” é€²ç¨‹ ID: {self.anr_info.pid}",
        ])
        
        if self.anr_info.timestamp:
            self.report_lines.append(f"ğŸ• ç™¼ç”Ÿæ™‚é–“: {self.anr_info.timestamp}")
        
        # é¡¯ç¤ºè¶…æ™‚è³‡è¨Š
        if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info:
            timeout_info = self.anr_info.timeout_info
            if timeout_info.get('wait_time'):
                self.report_lines.append(
                    f"â±ï¸ ç­‰å¾…æ™‚é–“: {timeout_info['wait_time']}ms "
                    f"(é–¾å€¼: {timeout_info.get('timeout_threshold', 'N/A')}ms)"
                )
        
        # å¿«é€Ÿåˆ¤æ–·åš´é‡ç¨‹åº¦
        severity = self._assess_severity()
        self.report_lines.append(f"ğŸš¨ åš´é‡ç¨‹åº¦: {severity}")
        
        # æ ¹æœ¬åŸå› å¿«é€Ÿå®šä½
        root_cause = self._quick_root_cause()
        self.report_lines.append(f"ğŸ¯ å¯èƒ½åŸå› : {root_cause}")
        
        self.report_lines.extend(["", "=" * 60, ""])
        
    def _assess_severity(self) -> str:
        """è©•ä¼°åš´é‡ç¨‹åº¦"""
        score = 0
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            score += 5
        
        # æª¢æŸ¥ç³»çµ±æœå‹™
        if "system_server" in self.anr_info.process_name:
            score += 3
        elif any(svc in self.anr_info.process_name for svc in 
                ['launcher', 'systemui', 'phone', 'bluetooth']):
            score += 2
        
        # æª¢æŸ¥é˜»å¡ç·šç¨‹æ•¸é‡
        blocked_count = sum(1 for t in self.anr_info.all_threads if t.state == ThreadState.BLOCKED)
        score += min(blocked_count // 3, 3)
        
        # æª¢æŸ¥ CPU ä½¿ç”¨ç‡
        if self.anr_info.cpu_usage and self.anr_info.cpu_usage.get('total', 0) > 90:
            score += 2
        
        # æª¢æŸ¥è¨˜æ†¶é«”å£“åŠ›
        if self.anr_info.memory_info:
            available = self.anr_info.memory_info.get('available', float('inf'))
            if available < 50 * 1024:  # å°æ–¼ 50MB
                score += 3
            elif available < 100 * 1024:  # å°æ–¼ 100MB
                score += 2
        
        # æª¢æŸ¥ä¸»ç·šç¨‹ç‹€æ…‹
        if self.anr_info.main_thread:
            if self.anr_info.main_thread.state == ThreadState.BLOCKED:
                score += 2
            elif self.anr_info.main_thread.waiting_locks:
                score += 1
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Watchdog
        if any(re.search(pattern, self.content) for pattern in 
               ['Watchdog', 'WATCHDOG', 'watchdog']):
            score += 3
        
        # è¿”å›è©•ç´š
        if score >= 8:
            return "ğŸ”´ æ¥µå…¶åš´é‡ (ç³»çµ±ç´šå•é¡Œ/æ­»é–)"
        elif score >= 5:
            return "ğŸŸ  åš´é‡ (å¤šç·šç¨‹é˜»å¡/ç³»çµ±æœå‹™å•é¡Œ)"
        elif score >= 3:
            return "ğŸŸ¡ ä¸­ç­‰ (éœ€è¦ç«‹å³è™•ç†)"
        else:
            return "ğŸŸ¢ è¼•å¾® (æ‡‰ç”¨å±¤å•é¡Œ)"
    
    def _quick_root_cause(self) -> str:
        """å¿«é€Ÿå®šä½æ ¹æœ¬åŸå› """
        causes = []
        
        if self.anr_info.main_thread:
            # æª¢æŸ¥ä¸»ç·šç¨‹å †ç–Šå‰5å¹€
            for i, frame in enumerate(self.anr_info.main_thread.backtrace[:5]):
                frame_lower = frame.lower()
                
                # Binder IPC
                if any(keyword in frame for keyword in ['BinderProxy', 'Binder.transact']):
                    service = self._identify_binder_service(self.anr_info.main_thread.backtrace[i:i+5])
                    if service:
                        causes.append(f"Binder IPC é˜»å¡ ({service})")
                    else:
                        causes.append("Binder IPC é˜»å¡")
                    break
                    
                # åŒæ­¥é–
                elif any(keyword in frame_lower for keyword in ['synchronized', 'lock', 'monitor']):
                    causes.append("åŒæ­¥é–ç­‰å¾…")
                    break
                    
                # ç¶²è·¯æ“ä½œ
                elif any(keyword in frame for keyword in ['Socket', 'Http', 'Network', 'URL']):
                    causes.append("ç¶²è·¯æ“ä½œé˜»å¡")
                    break
                    
                # I/O æ“ä½œ
                elif any(keyword in frame for keyword in ['File', 'read', 'write', 'SQLite']):
                    causes.append("I/O æ“ä½œé˜»å¡")
                    break
                    
                # ä¼‘çœ 
                elif 'sleep' in frame_lower:
                    causes.append("ä¸»ç·šç¨‹ä¼‘çœ ")
                    break
                    
                # SharedPreferences
                elif 'SharedPreferences' in frame and 'commit' in frame:
                    causes.append("SharedPreferences.commit() é˜»å¡")
                    break
                    
                # ContentProvider
                elif 'ContentResolver' in frame or 'ContentProvider' in frame:
                    causes.append("ContentProvider æ“ä½œé˜»å¡")
                    break
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            causes.append("å¯èƒ½å­˜åœ¨æ­»é–")
        
        # æª¢æŸ¥ CPU
        if self.anr_info.cpu_usage and self.anr_info.cpu_usage.get('total', 0) > 90:
            causes.append("CPU ä½¿ç”¨ç‡éé«˜")
        
        # æª¢æŸ¥è¨˜æ†¶é«”
        if self.anr_info.memory_info:
            available = self.anr_info.memory_info.get('available', float('inf'))
            if available < 100 * 1024:
                causes.append("è¨˜æ†¶é«”åš´é‡ä¸è¶³")
        
        # æª¢æŸ¥ç·šç¨‹æ•¸
        if len(self.anr_info.all_threads) > 150:
            causes.append("ç·šç¨‹æ•¸éå¤š")
        
        # åŸºæ–¼ ANR é¡å‹
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            if not causes:
                causes.append("ä¸»ç·šç¨‹ç„¡éŸ¿æ‡‰")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            if not causes:
                causes.append("Service ç”Ÿå‘½é€±æœŸæ–¹æ³•è¶…æ™‚")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            if not causes:
                causes.append("BroadcastReceiver.onReceive è¶…æ™‚")
        
        return " / ".join(causes) if causes else "éœ€é€²ä¸€æ­¥åˆ†æ"
    
    def _has_deadlock(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰æ­»é–"""
        # ç°¡å–®çš„æ­»é–æª¢æ¸¬ï¼šæª¢æŸ¥å¾ªç’°ç­‰å¾…
        waiting_graph = {}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æª¢æŸ¥å¾ªç’°
        visited = set()
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    return True  # ç™¼ç¾å¾ªç’°
                if current in visited:
                    break
                path.append(current)
            
            visited.update(path)
        
        return False
    
    def _add_basic_info(self):
        """æ·»åŠ åŸºæœ¬è³‡è¨Š"""
        self.report_lines.append("ğŸ“‹ è©³ç´°åˆ†æ")
        
        if self.anr_info.reason:
            self.report_lines.append(f"\nâš¡ è§¸ç™¼åŸå› : {self.anr_info.reason}")
        
        # æ·»åŠ è¶…æ™‚è©³æƒ…
        if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info:
            timeout_info = self.anr_info.timeout_info
            if timeout_info.get('wait_time') and timeout_info.get('timeout_threshold'):
                ratio = timeout_info['wait_time'] / timeout_info['timeout_threshold']
                self.report_lines.append(
                    f"â±ï¸ è¶…æ™‚è©³æƒ…: ç­‰å¾…äº† {timeout_info['wait_time']}ms "
                    f"(è¶…éé–¾å€¼ {ratio:.1f} å€)"
                )
        
        # æ·»åŠ é€²ç¨‹è©³æƒ…
        self.report_lines.append(f"\nğŸ“± é€²ç¨‹è©³æƒ…:")
        self.report_lines.append(f"  â€¢ é€²ç¨‹å: {self.anr_info.process_name}")
        self.report_lines.append(f"  â€¢ PID: {self.anr_info.pid}")
        if self.anr_info.timestamp:
            self.report_lines.append(f"  â€¢ æ™‚é–“: {self.anr_info.timestamp}")
    
    def _add_main_thread_analysis(self):
        """æ·»åŠ ä¸»ç·šç¨‹åˆ†æ"""
        self.report_lines.append("\nğŸ” ä¸»ç·šç¨‹åˆ†æ")
        
        if not self.anr_info.main_thread:
            self.report_lines.append("âŒ æœªæ‰¾åˆ°ä¸»ç·šç¨‹è³‡è¨Š")
            return
        
        main = self.anr_info.main_thread
        self.report_lines.extend([
            f"ğŸ§µ ç·šç¨‹åç¨±: {main.name}",
            f"ğŸ”¢ ç·šç¨‹ ID: {main.tid}",
            f"ğŸ“Š ç·šç¨‹ç‹€æ…‹: {main.state.value}",
            f"ğŸ¯ å„ªå…ˆç´š: {main.prio}",
        ])
        
        # åˆ†æç·šç¨‹ç‹€æ…‹
        state_analysis = self._analyze_thread_state(main.state)
        self.report_lines.append(f"ğŸ’¡ ç‹€æ…‹åˆ†æ: {state_analysis}")
        
        # åˆ†æå †ç–Š
        if main.backtrace:
            # æ·±åº¦åˆ†æå †ç–Š
            stack_analysis = self._deep_analyze_stack(main.backtrace)
            
            self.report_lines.append(f"\nğŸ“š å †ç–Šåˆ†æ (å…± {len(main.backtrace)} å±¤):")
            
            # é¡¯ç¤ºåˆ†æçµæœ
            if stack_analysis['root_cause']:
                self.report_lines.append(f"  ğŸ¯ æ ¹æœ¬åŸå› : {stack_analysis['root_cause']}")
            
            if stack_analysis['blocking_operation']:
                self.report_lines.append(f"  â° é˜»å¡æ“ä½œ: {stack_analysis['blocking_operation']}")
            
            if stack_analysis['target_service']:
                self.report_lines.append(f"  ğŸ”— ç›®æ¨™æœå‹™: {stack_analysis['target_service']}")
            
            if stack_analysis['key_findings']:
                for finding in stack_analysis['key_findings']:
                    self.report_lines.append(f"  â€¢ {finding}")
            
            # é¡¯ç¤ºå¸¶å„ªå…ˆç´šæ¨™è¨˜çš„å †ç–Š
            self.report_lines.append("\nğŸ” é—œéµå †ç–Š (æ¨™è¨˜é‡è¦å¹€):")
            
            # åˆ†ææ¯ä¸€å¹€çš„é‡è¦æ€§
            frame_importances = self._analyze_frame_importance(main.backtrace)
            
            for i, (frame, importance) in enumerate(zip(main.backtrace[:20], frame_importances[:20])):
                priority_marker = importance['marker']
                explanation = importance['explanation']
                
                # æ ¹æ“šé‡è¦æ€§é¡¯ç¤ºä¸åŒé¡è‰²çš„æ¨™è¨˜
                if importance['level'] == 'critical':
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
                    if explanation:
                        self.report_lines.append(f"        â””â”€ {explanation}")
                elif importance['level'] == 'important':
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
                    if explanation:
                        self.report_lines.append(f"        â””â”€ {explanation}")
                elif importance['level'] == 'normal' and i < 10:  # åªé¡¯ç¤ºå‰10å€‹æ™®é€šå¹€
                    self.report_lines.append(f"  {priority_marker} #{i:02d} {frame}")
        
        # é¡¯ç¤ºé–è³‡è¨Š
        if main.held_locks:
            self.report_lines.append(f"\nğŸ”’ æŒæœ‰çš„é–: {', '.join(main.held_locks)}")
        
        if main.waiting_locks:
            self.report_lines.append(f"â° ç­‰å¾…çš„é–: {', '.join(main.waiting_locks)}")
        
        if main.waiting_info:
            self.report_lines.append(f"â³ ç­‰å¾…è³‡è¨Š: {main.waiting_info}")
    
    def _analyze_thread_state(self, state: ThreadState) -> str:
        """åˆ†æç·šç¨‹ç‹€æ…‹"""
        analyses = {
            ThreadState.BLOCKED: "ç·šç¨‹è¢«åŒæ­¥é–é˜»å¡ âš ï¸ [å¯èƒ½æ˜¯ ANR ä¸»å› ]",
            ThreadState.WAIT: "ç·šç¨‹åœ¨ç­‰å¾…æ¢ä»¶ â° [éœ€æª¢æŸ¥ç­‰å¾…åŸå› ]",
            ThreadState.TIMED_WAIT: "ç·šç¨‹åœ¨å®šæ™‚ç­‰å¾… â° [æª¢æŸ¥ç­‰å¾…æ™‚é•·]",
            ThreadState.SUSPENDED: "ç·šç¨‹è¢«æš«åœ âš ï¸ [ç•°å¸¸ç‹€æ…‹]",
            ThreadState.RUNNABLE: "ç·šç¨‹å¯é‹è¡Œ âœ… [æ­£å¸¸ç‹€æ…‹ï¼Œä½†å¯èƒ½åœ¨åŸ·è¡Œè€—æ™‚æ“ä½œ]",
            ThreadState.NATIVE: "åŸ·è¡ŒåŸç”Ÿä»£ç¢¼ ğŸ“± [æª¢æŸ¥ JNI èª¿ç”¨]",
            ThreadState.SLEEPING: "ç·šç¨‹ä¼‘çœ  ğŸ˜´ [ä¸æ‡‰åœ¨ä¸»ç·šç¨‹]",
        }
        
        return analyses.get(state, "æœªçŸ¥ç‹€æ…‹")
    
    def _deep_analyze_stack(self, backtrace: List[str]) -> Dict:
        """æ·±åº¦åˆ†æå †ç–Š"""
        analysis = {
            'root_cause': None,
            'blocking_operation': None,
            'target_service': None,
            'key_findings': []
        }
        
        if not backtrace:
            return analysis
        
        # åˆ†æå‰10å¹€æ‰¾å‡ºé—œéµå•é¡Œ
        for i, frame in enumerate(backtrace[:10]):
            frame_lower = frame.lower()
            
            # Binder IPC åˆ†æ
            if any(keyword in frame for keyword in ['BinderProxy.transact', 'Binder.transact', 'IPCThreadState::transact']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "Binder IPC èª¿ç”¨é˜»å¡"
                
                # å˜—è©¦è­˜åˆ¥ç›®æ¨™æœå‹™
                service = self._identify_binder_service(backtrace[i:i+5])
                if service:
                    analysis['target_service'] = service
                    
                # è­˜åˆ¥å…·é«”çš„ Binder æ–¹æ³•
                method = self._identify_binder_method(backtrace[i:i+5])
                if method:
                    analysis['blocking_operation'] = f"Binder æ–¹æ³•: {method}"
                else:
                    analysis['blocking_operation'] = "Binder IPC èª¿ç”¨"
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° Binder IPC èª¿ç”¨")
            
            # åŒæ­¥é–åˆ†æ
            elif 'synchronized' in frame_lower or any(lock in frame_lower for lock in ['lock', 'monitor', 'mutex']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "åŒæ­¥é–ç­‰å¾…"
                
                lock_type = self._identify_lock_type([frame])
                if lock_type:
                    analysis['blocking_operation'] = lock_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°é–æ“ä½œ")
            
            # I/O æ“ä½œåˆ†æ
            elif any(io_op in frame for io_op in ['FileInputStream', 'FileOutputStream', 'RandomAccessFile', 'read', 'write']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "I/O æ“ä½œé˜»å¡"
                    
                io_type = self._identify_io_type([frame])
                if io_type:
                    analysis['blocking_operation'] = io_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° I/O æ“ä½œ")
            
            # è³‡æ–™åº«æ“ä½œ
            elif any(db in frame for db in ['SQLite', 'database', 'Cursor', 'ContentProvider']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "è³‡æ–™åº«æ“ä½œé˜»å¡"
                    
                analysis['blocking_operation'] = "è³‡æ–™åº«æ“ä½œ"
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°è³‡æ–™åº«æ“ä½œ")
            
            # ç¶²è·¯æ“ä½œ
            elif any(net in frame for net in ['Socket', 'HttpURLConnection', 'URLConnection', 'OkHttp']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "ç¶²è·¯è«‹æ±‚é˜»å¡"
                    
                network_type = self._identify_network_type([frame])
                if network_type:
                    analysis['blocking_operation'] = network_type
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ°ç¶²è·¯æ“ä½œ")
            
            # UI æ¸²æŸ“
            elif any(ui in frame for ui in ['onDraw', 'onMeasure', 'onLayout', 'inflate', 'measure']):
                if not analysis['root_cause']:
                    analysis['root_cause'] = "UI æ¸²æŸ“é˜»å¡"
                    
                ui_operation = self._identify_ui_operation([frame])
                if ui_operation:
                    analysis['blocking_operation'] = ui_operation
                    
                analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° UI æ“ä½œ")
            
            # ä¼‘çœ æ“ä½œ
            elif 'sleep' in frame_lower:
                analysis['root_cause'] = "ä¸»ç·šç¨‹ä¼‘çœ  (åš´é‡å•é¡Œ)"
                analysis['blocking_operation'] = "Thread.sleep()"
                analysis['key_findings'].append(f"âš ï¸ åœ¨ç¬¬ {i} å±¤æª¢æ¸¬åˆ° sleep æ“ä½œ")
            
            # Native æ–¹æ³•
            elif 'native' in frame_lower or 'Native Method' in frame:
                if i < 3:  # åªæœ‰åœ¨é ‚å±¤å¹¾å¹€æ‰èªç‚ºæ˜¯ Native é˜»å¡
                    if not analysis['root_cause']:
                        analysis['root_cause'] = "Native æ–¹æ³•é˜»å¡"
                    analysis['key_findings'].append(f"åœ¨ç¬¬ {i} å±¤é€²å…¥ Native æ–¹æ³•")
        
        # æª¢æŸ¥ç‰¹æ®Šæ¨¡å¼
        if len(backtrace) > 50:
            analysis['key_findings'].append(f"èª¿ç”¨éˆéæ·± ({len(backtrace)} å±¤)ï¼Œå¯èƒ½æœ‰éè¿´")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ Handler/Looper æ¨¡å¼
        if any('Handler' in frame or 'Looper' in frame for frame in backtrace[:5]):
            analysis['key_findings'].append("æ¶‰åŠ Handler/Looper æ¶ˆæ¯è™•ç†")
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ˜ç¢ºåŸå› ï¼Œé€²è¡Œæ›´æ·±å…¥åˆ†æ
        if not analysis['root_cause']:
            if any('wait' in frame.lower() or 'park' in frame.lower() for frame in backtrace[:5]):
                analysis['root_cause'] = "ç·šç¨‹ç­‰å¾…"
                analysis['blocking_operation'] = "ç­‰å¾…æ¢ä»¶æˆ–äº‹ä»¶"
            else:
                analysis['root_cause'] = "æœªçŸ¥é˜»å¡åŸå› "
        
        return analysis
    
    def _analyze_frame_importance(self, backtrace: List[str]) -> List[Dict]:
        """åˆ†ææ¯ä¸€å¹€çš„é‡è¦æ€§"""
        importances = []
        
        for i, frame in enumerate(backtrace):
            importance = {
                'level': 'normal',
                'marker': 'âšª',
                'explanation': None
            }
            
            frame_lower = frame.lower()
            
            # æœ€é«˜å„ªå…ˆç´š - ç´…è‰²æ¨™è¨˜
            if any(critical in frame for critical in [
                'BinderProxy.transact', 'Binder.transact', 'IPCThreadState::transact'
            ]):
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'Binder IPC èª¿ç”¨é˜»å¡'
            
            elif 'sleep' in frame_lower:
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'ä¸»ç·šç¨‹ä¼‘çœ  - åš´é‡å•é¡Œï¼'
            
            elif 'synchronized' in frame_lower or 'lock' in frame_lower:
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'åŒæ­¥é–ç­‰å¾…'
            
            elif any(io in frame for io in ['Socket', 'Http', 'URLConnection']):
                importance['level'] = 'critical'
                importance['marker'] = 'ğŸ”´'
                importance['explanation'] = 'ç¶²è·¯æ“ä½œåœ¨ä¸»ç·šç¨‹'
            
            # ä¸­ç­‰å„ªå…ˆç´š - é»ƒè‰²æ¨™è¨˜
            elif any(io in frame for io in ['FileInputStream', 'FileOutputStream', 'read', 'write']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'I/O æ“ä½œ'
            
            elif any(db in frame for db in ['SQLite', 'database', 'Cursor']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'è³‡æ–™åº«æ“ä½œ'
            
            elif any(ui in frame for ui in ['onDraw', 'onMeasure', 'onLayout']):
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'UI æ¸²æŸ“æ“ä½œ'
            
            elif 'wait' in frame_lower or 'park' in frame_lower:
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'ç­‰å¾…æ“ä½œ'
            
            elif i == 0:  # ç¬¬ä¸€å¹€ç¸½æ˜¯é‡è¦çš„
                importance['level'] = 'important'
                importance['marker'] = 'ğŸŸ¡'
                importance['explanation'] = 'é ‚å±¤èª¿ç”¨'
            
            # Native æ–¹æ³•
            elif 'native' in frame_lower or 'Native Method' in frame:
                if i < 3:
                    importance['level'] = 'important'
                    importance['marker'] = 'ğŸŸ¡'
                    importance['explanation'] = 'Native æ–¹æ³•'
                else:
                    importance['marker'] = 'âšª'
            
            importances.append(importance)
        
        return importances
    
    def _identify_binder_method(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ Binder æ–¹æ³•"""
        # æŸ¥æ‰¾å…·é«”çš„æ–¹æ³•èª¿ç”¨
        for frame in frames:
            # åŒ¹é…æ¨™æº– Java æ–¹æ³•æ ¼å¼
            match = re.search(r'\.(\w+)\([^)]*\)', frame)
            if match:
                method = match.group(1)
                # éæ¿¾æ‰ä¸€äº›é€šç”¨æ–¹æ³•
                if method not in ['transact', 'onTransact', 'execTransact', 'invoke']:
                    return method
        
        return None
    
    def _identify_lock_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥é–é¡å‹"""
        for frame in frames:
            if 'synchronized' in frame:
                # å˜—è©¦æå–åŒæ­¥çš„å°è±¡
                match = re.search(r'synchronized\s*\(([^)]+)\)', frame)
                if match:
                    return f"synchronized ({match.group(1)})"
                return "synchronized åŒæ­¥é–"
            elif 'ReentrantLock' in frame:
                return "ReentrantLock å¯é‡å…¥é–"
            elif 'ReadWriteLock' in frame:
                return "ReadWriteLock è®€å¯«é–"
            elif 'Semaphore' in frame:
                return "Semaphore ä¿¡è™Ÿé‡"
            elif 'CountDownLatch' in frame:
                return "CountDownLatch å€’è¨ˆæ™‚é–"
            elif 'CyclicBarrier' in frame:
                return "CyclicBarrier å¾ªç’°å±éšœ"
            elif 'monitor' in frame.lower():
                return "Monitor ç›£è¦–å™¨é–"
        
        return "æœªçŸ¥é¡å‹çš„é–"
    
    def _identify_io_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ I/O é¡å‹"""
        for frame in frames:
            if 'FileInputStream' in frame or 'FileReader' in frame:
                return "æ–‡ä»¶è®€å–"
            elif 'FileOutputStream' in frame or 'FileWriter' in frame:
                return "æ–‡ä»¶å¯«å…¥"
            elif 'RandomAccessFile' in frame:
                return "éš¨æ©Ÿæ–‡ä»¶è¨ªå•"
            elif 'BufferedReader' in frame or 'BufferedWriter' in frame:
                return "ç·©è¡ I/O"
            elif 'SharedPreferences' in frame:
                return "SharedPreferences è®€å¯«"
            elif 'SQLite' in frame or 'database' in frame:
                return "è³‡æ–™åº« I/O"
            elif 'ContentResolver' in frame:
                return "ContentProvider è¨ªå•"
            elif 'AssetManager' in frame:
                return "Asset è³‡æºè®€å–"
        
        return "æ–‡ä»¶ I/O"
    
    def _identify_network_type(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ç¶²è·¯é¡å‹"""
        for frame in frames:
            if 'HttpURLConnection' in frame:
                return "HttpURLConnection è«‹æ±‚"
            elif 'Socket' in frame:
                return "Socket é€£æ¥"
            elif 'OkHttp' in frame:
                return "OkHttp è«‹æ±‚"
            elif 'Volley' in frame:
                return "Volley ç¶²è·¯è«‹æ±‚"
            elif 'Retrofit' in frame:
                return "Retrofit API èª¿ç”¨"
            elif 'AsyncHttpClient' in frame:
                return "AsyncHttpClient è«‹æ±‚"
            elif 'HttpClient' in frame:
                return "HttpClient è«‹æ±‚"
        
        return "ç¶²è·¯è«‹æ±‚"
    
    def _identify_ui_operation(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ UI æ“ä½œ"""
        for frame in frames:
            if 'inflate' in frame:
                return "View å¸ƒå±€å¡«å……"
            elif 'onMeasure' in frame:
                return "View æ¸¬é‡"
            elif 'onDraw' in frame:
                return "View ç¹ªè£½"
            elif 'onLayout' in frame:
                return "View å¸ƒå±€"
            elif 'measure(' in frame:
                return "æ¸¬é‡æ“ä½œ"
            elif 'layout(' in frame:
                return "å¸ƒå±€æ“ä½œ"
            elif 'draw(' in frame:
                return "ç¹ªè£½æ“ä½œ"
            elif 'RecyclerView' in frame:
                return "RecyclerView æ“ä½œ"
            elif 'ListView' in frame:
                return "ListView æ“ä½œ"
            elif 'TextView' in frame and 'setText' in frame:
                return "TextView æ›´æ–°"
        
        return "UI æ“ä½œ"
    
    def _add_root_cause_analysis(self):
        """æ·»åŠ æ ¹æœ¬åŸå› åˆ†æ"""
        self.report_lines.append("\nğŸ¯ æ ¹æœ¬åŸå› åˆ†æ")
        
        # Binder åˆ†æ
        binder_issues = self._analyze_binder_issues()
        if binder_issues:
            self.report_lines.append("\nğŸ”— Binder IPC å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in binder_issues)
        
        # é–åˆ†æ
        lock_issues = self._analyze_lock_issues()
        if lock_issues:
            self.report_lines.append("\nğŸ”’ é–ç«¶çˆ­å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in lock_issues)
        
        # I/O åˆ†æ
        io_issues = self._analyze_io_issues()
        if io_issues:
            self.report_lines.append("\nğŸ’¾ I/O å•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in io_issues)
        
        # ç³»çµ±è³‡æºåˆ†æ
        resource_issues = self._analyze_resource_issues()
        if resource_issues:
            self.report_lines.append("\nğŸ–¥ï¸ ç³»çµ±è³‡æºå•é¡Œ:")
            self.report_lines.extend(f"  â€¢ {issue}" for issue in resource_issues)
        
 
    def _add_intelligent_analysis(self):
        """æ·»åŠ æ™ºèƒ½åˆ†æ - å•é¡Œä¾†é¾å»è„ˆ"""
        self.report_lines.append("\nğŸ§  æ™ºèƒ½åˆ†æ - å•é¡Œä¾†é¾å»è„ˆ")
        
        # åˆ†æèª¿ç”¨éˆ
        if self.anr_info.main_thread:
            call_chain = self.intelligent_engine.analyze_call_chain(
                self.anr_info.main_thread.backtrace
            )
            
            # é¡¯ç¤ºèª¿ç”¨æµç¨‹
            if call_chain['call_flow']:
                self.report_lines.append("\nğŸ“Š èª¿ç”¨æµç¨‹åˆ†æ:")
                for i, flow in enumerate(call_chain['call_flow']):
                    indent = "  " * (i + 1)
                    marker = "â†’" if i < len(call_chain['call_flow']) - 1 else "âœ˜"
                    self.report_lines.append(
                        f"{indent}{marker} {flow['type']}: {flow['detail']}"
                    )
                    if 'target' in flow:
                        self.report_lines.append(f"{indent}  ç›®æ¨™: {flow['target']}")
                    if 'method' in flow:
                        self.report_lines.append(f"{indent}  æ–¹æ³•: {flow['method']}")
            
            # é¡¯ç¤ºé˜»å¡é»
            if call_chain['blocking_points']:
                self.report_lines.append("\nğŸš« è­˜åˆ¥çš„é˜»å¡é»:")
                for point in call_chain['blocking_points']:
                    self.report_lines.append(
                        f"  â€¢ ç¬¬ {point['level']} å±¤: {point['description']} "
                        f"[{point['type']}]"
                    )
            
            # é¡¯ç¤ºæœå‹™äº¤äº’
            if call_chain['service_interactions']:
                self.report_lines.append("\nğŸ”„ æœå‹™äº¤äº’éˆ:")
                for interaction in call_chain['service_interactions']:
                    self.report_lines.append(
                        f"  â€¢ {interaction['from']} â†’ {interaction['to']} "
                        f"({interaction['type']})"
                    )
        
        # åŒ¹é…å·²çŸ¥æ¨¡å¼
        known_patterns = self.intelligent_engine.match_known_patterns(self.anr_info)
        if known_patterns:
            self.report_lines.append("\nğŸ¯ åŒ¹é…çš„å·²çŸ¥å•é¡Œæ¨¡å¼:")
            for pattern in known_patterns[:3]:
                # è™•ç†å…©ç¨®ä¸åŒçš„æ¨¡å¼æ ¼å¼
                if 'root_cause' in pattern:
                    # analysis_patterns æ ¼å¼
                    self.report_lines.append(
                        f"\n  ğŸ“Œ {pattern['root_cause']} "
                        f"(ä¿¡å¿ƒåº¦: {pattern['confidence']*100:.0f}%)"
                    )
                    self.report_lines.append(f"     åš´é‡æ€§: {pattern.get('severity', 'æœªçŸ¥')}")
                    self.report_lines.append("     è§£æ±ºæ–¹æ¡ˆ:")
                    solutions = pattern.get('solutions', [])
                    for solution in solutions:
                        self.report_lines.append(f"       â€¢ {solution}")
                else:
                    # known_issues_db æ ¼å¼
                    self.report_lines.append(
                        f"\n  ğŸ“Œ {pattern.get('description', 'å·²çŸ¥å•é¡Œ')} "
                        f"(ä¿¡å¿ƒåº¦: {pattern['confidence']*100:.0f}%)"
                    )
                    if 'workarounds' in pattern:
                        self.report_lines.append("     è™•ç†æ–¹æ³•:")
                        for workaround in pattern['workarounds']:
                            self.report_lines.append(f"       â€¢ {workaround}")
        
        # æ™‚åºåˆ†æ
        self._add_timeline_analysis()
    
    def _add_timeline_analysis(self):
        """æ·»åŠ é€šç”¨çš„æ™‚åºåˆ†æ"""
        self.report_lines.append("\nâ±ï¸ äº‹ä»¶æ™‚åºåˆ†æ:")
        
        events = []
        
        # åŸºæ–¼ ANR é¡å‹æ§‹å»ºæ™‚åº
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            events.append("1. ç”¨æˆ¶è§¸ç™¼è¼¸å…¥äº‹ä»¶ï¼ˆè§¸æ‘¸/æŒ‰éµï¼‰")
            events.append("2. InputDispatcher å˜—è©¦åˆ†ç™¼äº‹ä»¶åˆ°æ‡‰ç”¨")
            events.append("3. æ‡‰ç”¨ä¸»ç·šç¨‹ç„¡éŸ¿æ‡‰")
            events.append("4. ç­‰å¾…è¶…é 5 ç§’")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            events.append("1. Service æ¥æ”¶åˆ°å•Ÿå‹•/ç¶å®šè«‹æ±‚")
            events.append("2. onCreate/onStartCommand é–‹å§‹åŸ·è¡Œ")
            events.append("3. ä¸»ç·šç¨‹è¢«é˜»å¡")
            timeout = ANRTimeouts.SERVICE_TIMEOUT if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info.get('is_foreground') else ANRTimeouts.SERVICE_BACKGROUND_TIMEOUT
            events.append(f"4. è¶…é {timeout/1000} ç§’æœªå®Œæˆ")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            events.append("1. ç³»çµ±/æ‡‰ç”¨ç™¼é€å»£æ’­")
            events.append("2. BroadcastReceiver.onReceive é–‹å§‹åŸ·è¡Œ")
            events.append("3. è™•ç†æ™‚é–“éé•·")
            timeout = ANRTimeouts.BROADCAST_TIMEOUT if hasattr(self.anr_info, 'timeout_info') and self.anr_info.timeout_info.get('is_foreground') else ANRTimeouts.BROADCAST_BACKGROUND_TIMEOUT
            events.append(f"4. è¶…é {timeout/1000} ç§’æœªå®Œæˆ")
            events.append("5. ç³»çµ±è§¸ç™¼ ANR")
        
        # åŸºæ–¼å †ç–Šåˆ†æè£œå……äº‹ä»¶
        if self.anr_info.main_thread:
            for i, frame in enumerate(self.anr_info.main_thread.backtrace[:5]):
                if 'Binder' in frame:
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: é€²è¡Œ Binder IPC èª¿ç”¨")
                elif 'wait' in frame.lower() or 'lock' in frame.lower():
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: ç·šç¨‹ç­‰å¾…/é–ç«¶çˆ­")
                elif any(io in frame for io in ['File', 'SQLite', 'Socket']):
                    events.insert(3, f"  â†’ ç¬¬ {i} å±¤: I/O æ“ä½œ")
        
        for event in events:
            self.report_lines.append(f"  {event}")
    
    def _add_watchdog_analysis(self):
        """æ·»åŠ  Watchdog åˆ†æ"""
        watchdog_info = self.intelligent_engine._detect_watchdog_timeout(self.content)
        if watchdog_info:
            self.report_lines.append("\nâš ï¸ Watchdog æª¢æ¸¬")
            self.report_lines.append(f"  é¡å‹: {watchdog_info['type']}")
            self.report_lines.append(f"  åš´é‡æ€§: {watchdog_info['severity']}")
            self.report_lines.append(f"  èªªæ˜: {watchdog_info['description']}")
            self.report_lines.append("  å»ºè­°:")
            self.report_lines.append("    â€¢ æª¢æŸ¥ system_server æ˜¯å¦æœ‰æ­»é–")
            self.report_lines.append("    â€¢ åˆ†æç³»çµ±æœå‹™çš„ CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨")
            self.report_lines.append("    â€¢ æŸ¥çœ‹ /data/anr/traces.txt ç²å–å®Œæ•´è³‡è¨Š")
    
    def _add_strictmode_analysis(self):
        """æ·»åŠ  StrictMode é•è¦åˆ†æ"""
        violations = self.intelligent_engine._detect_strictmode_violations(self.content)
        if violations:
            self.report_lines.append("\nğŸš« StrictMode é•è¦æª¢æ¸¬")
            for violation in violations:
                self.report_lines.append(f"  â€¢ {violation['type']}: {violation['description']}")
                self.report_lines.append(f"    å»ºè­°: {violation['suggestion']}")
    
    def _add_gc_analysis(self):
        """æ·»åŠ  GC åˆ†æ"""
        gc_info = self.intelligent_engine._analyze_gc_impact(self.content)
        if gc_info['gc_count'] > 0:
            self.report_lines.append("\nâ™»ï¸ åƒåœ¾å›æ”¶åˆ†æ")
            self.report_lines.append(f"  â€¢ GC æ¬¡æ•¸: {gc_info['gc_count']}")
            self.report_lines.append(f"  â€¢ ç¸½æš«åœæ™‚é–“: {gc_info['total_pause_time']}ms")
            self.report_lines.append(f"  â€¢ å½±éŸ¿è©•ä¼°: {gc_info['impact']}")
            
            if gc_info['impact'] in ['high', 'medium']:
                self.report_lines.append("  å»ºè­°:")
                self.report_lines.append("    â€¢ å„ªåŒ–è¨˜æ†¶é«”åˆ†é…ç­–ç•¥")
                self.report_lines.append("    â€¢ é¿å…å‰µå»ºå¤§é‡è‡¨æ™‚å°è±¡")
                self.report_lines.append("    â€¢ ä½¿ç”¨å°è±¡æ± é‡ç”¨å°è±¡")
    
    def _add_system_health_score(self):
        """æ·»åŠ ç³»çµ±å¥åº·åº¦è©•åˆ†"""
        health_score = self.intelligent_engine._calculate_system_health_score(self.anr_info)
        
        # å„²å­˜å¥åº·åˆ†æ•¸ä¾›å…¶ä»–æ–¹æ³•ä½¿ç”¨
        self._last_health_score = health_score['score']
        
        self.report_lines.append("\nğŸ¥ ç³»çµ±å¥åº·åº¦è©•ä¼°")
        
        # ä½¿ç”¨åœ–å½¢åŒ–é¡¯ç¤ºåˆ†æ•¸
        score = health_score['score']
        if score >= 80:
            score_display = f"ğŸŸ¢ {score}/100 (å¥åº·)"
        elif score >= 60:
            score_display = f"ğŸŸ¡ {score}/100 (ä¸€èˆ¬)"
        elif score >= 40:
            score_display = f"ğŸŸ  {score}/100 (è¼ƒå·®)"
        else:
            score_display = f"ğŸ”´ {score}/100 (åš´é‡)"
        
        self.report_lines.append(f"  ç¸½åˆ†: {score_display}")
        
        if health_score['factors']:
            self.report_lines.append("  æ‰£åˆ†å› ç´ :")
            for factor in health_score['factors']:
                self.report_lines.append(f"    â€¢ {factor}")
        
        if 'recommendation' in health_score:
            self.report_lines.append(f"  å»ºè­°: {health_score['recommendation']}")
    
    def _add_thread_analysis(self):
        """æ·»åŠ ç·šç¨‹åˆ†æ - å¢å¼·ç‰ˆ"""
        if len(self.anr_info.all_threads) == 0:
            return
        
        self.report_lines.append(f"\nğŸ§µ ç·šç¨‹åˆ†æ (å…± {len(self.anr_info.all_threads)} å€‹)")
        
        # ç·šç¨‹åˆ†é¡çµ±è¨ˆ
        thread_stats = self._get_thread_statistics()
        
        self.report_lines.append("\nğŸ“Š ç·šç¨‹ç‹€æ…‹çµ±è¨ˆ:")
        for state, count in thread_stats.items():
            if count > 0:
                self.report_lines.append(f"  â€¢ {state}: {count} å€‹")
        
        # é¡¯ç¤ºé‡è¦ç·šç¨‹
        important_threads = self._get_important_threads()
        if important_threads:
            self.report_lines.append("\nğŸ” é‡è¦ç·šç¨‹:")
            for thread in important_threads[:10]:
                summary = self._summarize_thread(thread)
                self.report_lines.append(f"  â€¢ {summary}")
                
                # æ–°å¢ï¼šé¡¯ç¤º Crashlytics é¢¨æ ¼æ¨™ç±¤
                tags = self.intelligent_engine._identify_crashlytics_tags(thread)
                if tags:
                    self.report_lines.append(f"    æ¨™ç±¤: {', '.join(tags)}")

    def _summarize_thread(self, thread: ThreadInfo) -> str:
        """ç¸½çµç·šç¨‹è³‡è¨Š"""
        summary_parts = [f"{thread.name} (tid={thread.tid}"]
        
        # æ·»åŠ ç³»çµ±ç·šç¨‹ ID
        if thread.sysTid:
            summary_parts.append(f"sysTid={thread.sysTid}")
        
        # æ·»åŠ å„ªå…ˆç´š
        if thread.prio and thread.prio != "N/A":
            summary_parts.append(f"prio={thread.prio}")
        
        # æ·»åŠ ç‹€æ…‹
        summary_parts.append(f"{thread.state.value})")
        
        summary = ", ".join(summary_parts)
        
        # æ·»åŠ é¡å¤–è³‡è¨Š
        extra_info = []
        
        if thread.waiting_info:
            extra_info.append(thread.waiting_info)
        elif thread.waiting_locks:
            if len(thread.waiting_locks) == 1:
                extra_info.append(f"ç­‰å¾…é–: {thread.waiting_locks[0]}")
            else:
                extra_info.append(f"ç­‰å¾… {len(thread.waiting_locks)} å€‹é–")
        elif thread.held_locks:
            if len(thread.held_locks) == 1:
                extra_info.append(f"æŒæœ‰é–: {thread.held_locks[0]}")
            else:
                extra_info.append(f"æŒæœ‰ {len(thread.held_locks)} å€‹é–")
        
        # æ·»åŠ  CPU æ™‚é–“è³‡è¨Š
        if thread.schedstat:
            extra_info.append(thread.schedstat)
        elif thread.utm and thread.stm:
            utm_ms = int(thread.utm) * 10  # jiffies to ms (å‡è¨­ HZ=100)
            stm_ms = int(thread.stm) * 10
            extra_info.append(f"CPU: usr={utm_ms}ms sys={stm_ms}ms")
        
        # æª¢æŸ¥æ˜¯å¦åœ¨åŸ·è¡Œç‰¹å®šæ“ä½œ
        if thread.backtrace:
            for frame in thread.backtrace[:3]:
                if 'sleep' in frame.lower():
                    extra_info.append("ğŸ›Œ ä¼‘çœ ä¸­")
                    break
                elif 'wait' in frame.lower() or 'park' in frame.lower():
                    extra_info.append("â° ç­‰å¾…ä¸­")
                    break
                elif any(io in frame for io in ['File', 'SQLite', 'Socket']):
                    extra_info.append("ğŸ’¾ I/O æ“ä½œ")
                    break
                elif 'Binder' in frame:
                    extra_info.append("ğŸ”— Binder IPC")
                    break
        
        if extra_info:
            summary += " - " + ", ".join(extra_info)
        
        return summary
        
    def _get_important_threads(self) -> List[ThreadInfo]:
            """ç²å–é‡è¦ç·šç¨‹"""
            important = []
            seen_threads = set()
            
            # 1. ä¸»ç·šç¨‹ç¸½æ˜¯é‡è¦çš„
            if self.anr_info.main_thread:
                important.append(self.anr_info.main_thread)
                seen_threads.add(self.anr_info.main_thread.tid)
            
            # 2. é˜»å¡çš„ç·šç¨‹
            blocked_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.state == ThreadState.BLOCKED:
                    blocked_threads.append(thread)
            
            # æŒ‰å„ªå…ˆç´šæ’åºé˜»å¡çš„ç·šç¨‹
            blocked_threads.sort(key=lambda t: int(t.prio) if t.prio.isdigit() else 999)
            important.extend(blocked_threads[:5])
            seen_threads.update(t.tid for t in blocked_threads[:5])
            
            # 3. ç­‰å¾…é–çš„ç·šç¨‹
            waiting_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.waiting_locks:
                    waiting_threads.append(thread)
            
            important.extend(waiting_threads[:5])
            seen_threads.update(t.tid for t in waiting_threads[:5])
            
            # 4. ç³»çµ±é—œéµç·šç¨‹
            critical_thread_names = [
                'Binder:', 'FinalizerDaemon', 'FinalizerWatchdogDaemon',
                'ReferenceQueueDaemon', 'HeapTaskDaemon', 'RenderThread',
                'UI Thread', 'AsyncTask', 'OkHttp', 'grpc', 'Retrofit'
            ]
            
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads:
                    for critical_name in critical_thread_names:
                        if critical_name in thread.name:
                            important.append(thread)
                            seen_threads.add(thread.tid)
                            break
            
            # 5. åŸ·è¡Œ Binder èª¿ç”¨çš„ç·šç¨‹
            binder_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads:
                    if any('Binder' in frame for frame in thread.backtrace[:3]):
                        binder_threads.append(thread)
            
            important.extend(binder_threads[:3])
            seen_threads.update(t.tid for t in binder_threads[:3])
            
            # 6. Native ç‹€æ…‹çš„ç·šç¨‹ï¼ˆå¯èƒ½åœ¨åŸ·è¡Œ JNIï¼‰
            native_threads = []
            for thread in self.anr_info.all_threads:
                if thread.tid not in seen_threads and thread.state == ThreadState.NATIVE:
                    native_threads.append(thread)
            
            important.extend(native_threads[:3])
            
            return important[:20]  # æœ€å¤šè¿”å›20å€‹é‡è¦ç·šç¨‹
    
    def _get_thread_statistics(self) -> Dict[str, int]:
        """ç²å–ç·šç¨‹çµ±è¨ˆ"""
        stats = {}
        
        for thread in self.anr_info.all_threads:
            state_name = thread.state.value
            stats[state_name] = stats.get(state_name, 0) + 1
        
        # æŒ‰æ•¸é‡æ’åº
        sorted_stats = dict(sorted(stats.items(), key=lambda x: x[1], reverse=True))
        
        return sorted_stats
        
    def _add_deadlock_detection(self):
        """æ·»åŠ æ­»é–æª¢æ¸¬ - å¢å¼·ç‰ˆ"""
        # ä½¿ç”¨å¢å¼·çš„æ­»é–æª¢æ¸¬
        deadlock_info = self.intelligent_engine._detect_complex_deadlock(self.anr_info.all_threads)
        
        if deadlock_info['has_deadlock']:
            self.report_lines.append("\nğŸ’€ æ­»é–æª¢æ¸¬")
            
            if deadlock_info['cross_process']:
                self.report_lines.append("  âš ï¸ æª¢æ¸¬åˆ°è·¨é€²ç¨‹æ­»é–!")
            
            if deadlock_info['cycles']:
                for i, cycle in enumerate(deadlock_info['cycles'], 1):
                    self.report_lines.append(f"  æ­»é–å¾ªç’° {i}:")
                    for thread_info in cycle:
                        self.report_lines.append(f"    â€¢ {thread_info}")
    
    def _generate_suggestions(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå»ºè­° - å¢å¼·ç‰ˆ"""
        suggestions = {
            'immediate': [],
            'optimization': [],
            'investigation': []
        }
        
        # åŸºæ–¼ä¸»ç·šç¨‹ç‹€æ…‹
        if self.anr_info.main_thread:
            # æª¢æŸ¥å †ç–Š
            for frame in self.anr_info.main_thread.backtrace[:5]:
                if 'sleep' in frame.lower():
                    suggestions['immediate'].append("ç«‹å³ç§»é™¤ä¸»ç·šç¨‹ä¸­çš„ sleep æ“ä½œ")
                elif any(keyword in frame for keyword in ['File', 'SQLite', 'SharedPreferences']):
                    suggestions['immediate'].append("å°‡ I/O æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹ (ä½¿ç”¨ Kotlin å”ç¨‹æˆ– ExecutorService)")
                elif any(keyword in frame for keyword in ['Http', 'Socket', 'URL']):
                    suggestions['immediate'].append("å°‡ç¶²è·¯è«‹æ±‚ç§»è‡³èƒŒæ™¯ç·šç¨‹")
                elif 'synchronized' in frame:
                    suggestions['optimization'].append("æª¢æŸ¥åŒæ­¥é–çš„ä½¿ç”¨ï¼Œè€ƒæ…®ä½¿ç”¨ç„¡é–æ•¸æ“šçµæ§‹æˆ– ReadWriteLock")
        
        # åŸºæ–¼ ANR é¡å‹
        if self.anr_info.anr_type == ANRType.INPUT_DISPATCHING:
            suggestions['immediate'].append("æª¢æŸ¥ UI ç·šç¨‹æ˜¯å¦æœ‰è€—æ™‚æ“ä½œ")
            suggestions['optimization'].append("ä½¿ç”¨ Systrace åˆ†æ UI æ€§èƒ½")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ Choreographer ç›£æ§å¹€ç‡")
        elif self.anr_info.anr_type == ANRType.SERVICE:
            suggestions['immediate'].append("Service çš„ onStartCommand æ‡‰å¿«é€Ÿè¿”å›")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ JobIntentService æˆ– WorkManager")
            suggestions['investigation'].append("æª¢æŸ¥æ˜¯å¦éœ€è¦å‰å°æœå‹™")
        elif self.anr_info.anr_type == ANRType.BROADCAST:
            suggestions['immediate'].append("BroadcastReceiver çš„ onReceive æ‡‰åœ¨ 10 ç§’å…§å®Œæˆ")
            suggestions['optimization'].append("ä½¿ç”¨ goAsync() è™•ç†è€—æ™‚æ“ä½œ")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ LocalBroadcastManager æ¸›å°‘é–‹éŠ·")
        
        # åŸºæ–¼å•é¡Œé¡å‹
        if self._has_deadlock():
            suggestions['immediate'].append("é‡æ–°è¨­è¨ˆé–çš„ç²å–é †åºï¼Œé¿å…å¾ªç’°ç­‰å¾…")
            suggestions['investigation'].append("ä½¿ç”¨ Android Studio çš„ CPU Profiler åˆ†ææ­»é–")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ java.util.concurrent åŒ…ä¸­çš„é«˜ç´šåŒæ­¥å·¥å…·")
        
        if any('Binder' in frame for frame in (self.anr_info.main_thread.backtrace[:5] if self.anr_info.main_thread else [])):
            suggestions['investigation'].append("æª¢æŸ¥ system_server çš„å¥åº·ç‹€æ…‹")
            suggestions['investigation'].append("ä½¿ç”¨ 'dumpsys activity' æŸ¥çœ‹ç³»çµ±ç‹€æ…‹")
            suggestions['optimization'].append("è€ƒæ…®ä½¿ç”¨ç•°æ­¥ Binder èª¿ç”¨ (oneway)")
        
        # åŸºæ–¼ç³»çµ±å¥åº·åº¦
        if hasattr(self, '_last_health_score') and self._last_health_score < 60:
            suggestions['immediate'].append("ç³»çµ±è³‡æºç·Šå¼µï¼Œè€ƒæ…®å„ªåŒ–æ‡‰ç”¨è¨˜æ†¶é«”ä½¿ç”¨")
            suggestions['optimization'].append("å¯¦æ–½è¨˜æ†¶é«”å¿«å–ç­–ç•¥")
        
        # é€šç”¨å»ºè­°
        suggestions['investigation'].extend([
            "æ”¶é›†æ›´å¤š ANR traces ç¢ºèªå•é¡Œé‡ç¾æ€§",
            "ä½¿ç”¨ Android Studio Profiler åˆ†æ CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨",
            "æª¢æŸ¥ç›¸é—œæ™‚é–“æ®µçš„ logcat (ç‰¹åˆ¥æ˜¯ system_server)",
            "é–‹å•Ÿ StrictMode æª¢æ¸¬æ½›åœ¨å•é¡Œ",
        ])
        
        suggestions['optimization'].extend([
            "ä½¿ç”¨ Kotlin Coroutines æˆ– RxJava è™•ç†ç•°æ­¥æ“ä½œ",
            "å¯¦æ–½é©ç•¶çš„ç·šç¨‹æ± ç®¡ç† (é¿å…å‰µå»ºéå¤šç·šç¨‹)",
            "è€ƒæ…®ä½¿ç”¨ Android Jetpack çš„ WorkManager",
            "å®šæœŸ review ä¸»ç·šç¨‹çš„æ‰€æœ‰æ“ä½œ",
        ])
        
        return suggestions

    def _analyze_binder_issues(self) -> List[str]:
            """åˆ†æ Binder å•é¡Œ"""
            issues = []
            
            if not self.anr_info.main_thread:
                return issues
            
            # æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦åœ¨ç­‰å¾… Binder
            for frame in self.anr_info.main_thread.backtrace[:10]:
                if 'BinderProxy' in frame or 'Binder.transact' in frame:
                    issues.append("ä¸»ç·šç¨‹æ­£åœ¨ç­‰å¾… Binder IPC éŸ¿æ‡‰")
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰ system_server å•é¡Œ
                    if 'system_server' in self.content:
                        issues.append("æª¢æ¸¬åˆ° system_server ç›¸é—œè³‡è¨Šï¼Œå¯èƒ½æ˜¯ç³»çµ±æœå‹™å•é¡Œ")
                    
                    # å˜—è©¦è­˜åˆ¥ç›®æ¨™æœå‹™
                    service = self._identify_binder_service(self.anr_info.main_thread.backtrace[:10])
                    if service:
                        issues.append(f"ç›®æ¨™æœå‹™: {service}")
                    
                    break
            
            # æª¢æŸ¥å…¶ä»–ç·šç¨‹çš„ Binder ç‹€æ…‹
            binder_waiting_threads = 0
            for thread in self.anr_info.all_threads:
                if thread != self.anr_info.main_thread:
                    for frame in thread.backtrace[:5]:
                        if 'Binder' in frame:
                            binder_waiting_threads += 1
                            break
            
            if binder_waiting_threads > 3:
                issues.append(f"ç™¼ç¾ {binder_waiting_threads} å€‹ç·šç¨‹åœ¨ç­‰å¾… Binder èª¿ç”¨")
                issues.append("å¯èƒ½å­˜åœ¨ Binder ç·šç¨‹æ± è€—ç›¡å•é¡Œ")
            
            return issues
        
    def _analyze_lock_issues(self) -> List[str]:
        """åˆ†æé–å•é¡Œ"""
        issues = []
        
        # çµ±è¨ˆé˜»å¡ç·šç¨‹
        blocked_threads = [t for t in self.anr_info.all_threads if t.state == ThreadState.BLOCKED]
        if len(blocked_threads) > 3:
            issues.append(f"ç™¼ç¾ {len(blocked_threads)} å€‹ç·šç¨‹è™•æ–¼ BLOCKED ç‹€æ…‹")
            issues.append("å¯èƒ½å­˜åœ¨åš´é‡çš„é–ç«¶çˆ­")
            
            # åˆ—å‡ºå‰3å€‹é˜»å¡çš„ç·šç¨‹
            for thread in blocked_threads[:3]:
                if thread.waiting_info:
                    issues.append(f"  - {thread.name}: {thread.waiting_info}")
        
        # æª¢æŸ¥æ­»é–
        if self._has_deadlock():
            issues.append("âš ï¸ æª¢æ¸¬åˆ°å¯èƒ½çš„æ­»é–æƒ…æ³")
            
            # æ‰¾å‡ºæ­»é–ç·šç¨‹
            deadlock_info = self._find_deadlock_threads()
            if deadlock_info:
                issues.extend(deadlock_info)
        
        # æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦æŒæœ‰é–
        if self.anr_info.main_thread and self.anr_info.main_thread.held_locks:
            issues.append(f"ä¸»ç·šç¨‹æŒæœ‰ {len(self.anr_info.main_thread.held_locks)} å€‹é–")
            for lock in self.anr_info.main_thread.held_locks[:3]:
                issues.append(f"  - {lock}")
        
        return issues
    
    def _analyze_io_issues(self) -> List[str]:
        """åˆ†æ I/O å•é¡Œ"""
        issues = []
        
        if not self.anr_info.main_thread:
            return issues
        
        io_keywords = [
            ('File', 'æ–‡ä»¶'),
            ('read', 'è®€å–'),
            ('write', 'å¯«å…¥'),
            ('SQLite', 'è³‡æ–™åº«'),
            ('database', 'è³‡æ–™åº«'),
            ('SharedPreferences', 'åå¥½è¨­å®š'),
            ('ContentResolver', 'ContentProvider'),
            ('AssetManager', 'Asset è³‡æº'),
        ]
        
        for frame in self.anr_info.main_thread.backtrace[:10]:
            for keyword, desc in io_keywords:
                if keyword in frame:
                    issues.append(f"ä¸»ç·šç¨‹æ­£åœ¨åŸ·è¡Œ {desc} ç›¸é—œçš„ I/O æ“ä½œ")
                    issues.append("å»ºè­°å°‡ I/O æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹")
                    
                    # ç‰¹å®šå»ºè­°
                    if 'SharedPreferences' in frame:
                        issues.append("è€ƒæ…®ä½¿ç”¨ apply() è€Œé commit()")
                    elif 'SQLite' in frame or 'database' in frame:
                        issues.append("ä½¿ç”¨ AsyncQueryHandler æˆ– Room çš„ç•°æ­¥ API")
                    
                    return issues
        
        # æª¢æŸ¥ç¶²è·¯ I/O
        network_keywords = ['Socket', 'Http', 'URL', 'Network', 'Download', 'Upload']
        for frame in self.anr_info.main_thread.backtrace[:10]:
            for keyword in network_keywords:
                if keyword in frame:
                    issues.append("ä¸»ç·šç¨‹æ­£åœ¨åŸ·è¡Œç¶²è·¯æ“ä½œ")
                    issues.append("åš´é‡é•å Android æœ€ä½³å¯¦è¸")
                    issues.append("ä½¿ç”¨ Retrofitã€OkHttp æˆ– Volley çš„ç•°æ­¥ API")
                    return issues
        
        return issues
    
    def _analyze_resource_issues(self) -> List[str]:
        """åˆ†æç³»çµ±è³‡æºå•é¡Œ"""
        issues = []
        
        # CPU åˆ†æ
        if self.anr_info.cpu_usage:
            total_cpu = self.anr_info.cpu_usage.get('total', 0)
            if total_cpu > 90:
                issues.append(f"CPU ä½¿ç”¨ç‡éé«˜: {total_cpu:.1f}%")
                issues.append("å¯èƒ½åŸå› : ç„¡é™å¾ªç’°ã€éåº¦è¨ˆç®—ã€é »ç¹ GC")
            elif total_cpu > 70:
                issues.append(f"CPU ä½¿ç”¨ç‡è¼ƒé«˜: {total_cpu:.1f}%")
            
            # æª¢æŸ¥è² è¼‰
            load_1min = self.anr_info.cpu_usage.get('load_1min', 0)
            if load_1min > 4.0:
                issues.append(f"ç³»çµ±è² è¼‰éé«˜: {load_1min}")
        
        # è¨˜æ†¶é«”åˆ†æ
        if self.anr_info.memory_info:
            if 'available' in self.anr_info.memory_info:
                available_mb = self.anr_info.memory_info['available'] / 1024
                if available_mb < 100:
                    issues.append(f"å¯ç”¨è¨˜æ†¶é«”åš´é‡ä¸è¶³: {available_mb:.1f} MB")
                    issues.append("å¯èƒ½è§¸ç™¼é »ç¹çš„ GC å’Œè¨˜æ†¶é«”å£“ç¸®")
                elif available_mb < 200:
                    issues.append(f"å¯ç”¨è¨˜æ†¶é«”è¼ƒä½: {available_mb:.1f} MB")
            
            # æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨ç‡
            if 'used_percent' in self.anr_info.memory_info:
                used_percent = self.anr_info.memory_info['used_percent']
                if used_percent > 90:
                    issues.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {used_percent:.1f}%")
        
        # GC åˆ†æ
        gc_count = self.content.count('GC_')
        if gc_count > 10:
            issues.append(f"é »ç¹çš„åƒåœ¾å›æ”¶: {gc_count} æ¬¡")
            issues.append("å»ºè­°å„ªåŒ–è¨˜æ†¶é«”åˆ†é…ç­–ç•¥")
        elif gc_count > 5:
            issues.append(f"åƒåœ¾å›æ”¶è¼ƒå¤š: {gc_count} æ¬¡")
        
        # æª¢æŸ¥ OutOfMemoryError
        if "OutOfMemoryError" in self.content:
            issues.append("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤ (OutOfMemoryError)")
            issues.append("æ‡‰ç”¨å¯èƒ½å­˜åœ¨è¨˜æ†¶é«”æ´©æ¼")
        
        # æª¢æŸ¥ç³»çµ±è² è¼‰
        if "load average" in self.content:
            load_match = re.search(r'load average:\s*([\d.]+),\s*([\d.]+),\s*([\d.]+)', self.content)
            if load_match:
                load1 = float(load_match.group(1))
                load5 = float(load_match.group(2))
                load15 = float(load_match.group(3))
                if load1 > 8.0:
                    issues.append(f"ç³»çµ±è² è¼‰æ¥µé«˜: 1åˆ†é˜å¹³å‡ {load1}")
                elif load1 > 4.0:
                    issues.append(f"ç³»çµ±è² è¼‰éé«˜: 1åˆ†é˜å¹³å‡ {load1}")
        
        # ç·šç¨‹æ•¸åˆ†æ
        thread_count = len(self.anr_info.all_threads)
        if thread_count > 200:
            issues.append(f"ç·šç¨‹æ•¸é‡éå¤š: {thread_count} å€‹")
            issues.append("å¯èƒ½å­˜åœ¨ç·šç¨‹æ´©æ¼")
        elif thread_count > 100:
            issues.append(f"ç·šç¨‹æ•¸é‡è¼ƒå¤š: {thread_count} å€‹")
        
        return issues
    
    def _has_deadlock(self) -> bool:
        """æª¢æŸ¥æ˜¯å¦æœ‰æ­»é–"""
        # ç°¡å–®çš„æ­»é–æª¢æ¸¬ï¼šæª¢æŸ¥å¾ªç’°ç­‰å¾…
        waiting_graph = {}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æª¢æŸ¥å¾ªç’°
        visited = set()
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    return True  # ç™¼ç¾å¾ªç’°
                if current in visited:
                    break
                path.append(current)
            
            visited.update(path)
        
        return False
    
    def _find_deadlock_threads(self) -> List[str]:
        """æ‰¾å‡ºæ­»é–ç·šç¨‹"""
        info = []
        
        # å»ºç«‹ç­‰å¾…åœ–
        waiting_graph = {}
        thread_map = {t.tid: t for t in self.anr_info.all_threads}
        
        for thread in self.anr_info.all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    waiting_graph[thread.tid] = match.group(1)
        
        # æ‰¾å‡ºå¾ªç’°
        visited = set()
        cycles_found = set()
        
        for start_tid in waiting_graph:
            if start_tid in visited:
                continue
            
            current = start_tid
            path = [current]
            
            while current in waiting_graph:
                current = waiting_graph[current]
                if current in path:
                    # æ‰¾åˆ°å¾ªç’°
                    cycle_start = path.index(current)
                    cycle = path[cycle_start:]
                    cycle_key = tuple(sorted(cycle))
                    
                    if cycle_key not in cycles_found:
                        cycles_found.add(cycle_key)
                        
                        cycle_info = []
                        for tid in cycle:
                            if tid in thread_map:
                                thread = thread_map[tid]
                                cycle_info.append(f"{thread.name} (tid={tid})")
                        
                        info.append(f"æ­»é–å¾ªç’°: {' -> '.join(cycle_info)} -> {cycle_info[0]}")
                    break
                    
                path.append(current)
            
            visited.update(path)
        
        return info
    
    def _identify_binder_service(self, frames: List[str]) -> Optional[str]:
        """è­˜åˆ¥ Binder ç›®æ¨™æœå‹™"""
        # æ“´å±•æœå‹™è­˜åˆ¥è¦å‰‡
        service_patterns = {
            'WindowManager': [
                'getWindowInsets', 'addWindow', 'removeWindow', 'updateViewLayout',
                'WindowManagerService', 'WindowManager$', 'IWindowManager',
                'ViewRootImpl', 'relayoutWindow', 'WindowSession'
            ],
            'ActivityManager': [
                'startActivity', 'bindService', 'getRunningTasks', 'getServices',
                'ActivityManagerService', 'ActivityManager$', 'IActivityManager',
                'broadcastIntent', 'startService', 'stopService'
            ],
            'PackageManager': [
                'getPackageInfo', 'queryIntentActivities', 'getApplicationInfo',
                'PackageManagerService', 'PackageManager$', 'IPackageManager',
                'getInstalledPackages', 'resolveActivity'
            ],
            'PowerManager': [
                'isScreenOn', 'goToSleep', 'wakeUp', 'PowerManagerService',
                'PowerManager$', 'IPowerManager', 'acquire', 'release'
            ],
            'InputManager': [
                'injectInputEvent', 'getInputDevice', 'InputManagerService',
                'InputManager$', 'IInputManager', 'InputMethodManager'
            ],
            'NotificationManager': [
                'notify', 'cancel', 'NotificationManagerService',
                'NotificationManager$', 'INotificationManager', 'enqueueNotification'
            ],
            'AudioManager': [
                'setStreamVolume', 'AudioService', 'AudioManager$', 'IAudioService',
                'playSoundEffect', 'setRingerMode'
            ],
            'TelephonyManager': [
                'getDeviceId', 'getNetworkType', 'TelephonyRegistry',
                'TelephonyManager$', 'ITelephony', 'getPhoneType'
            ],
            'LocationManager': [
                'getLastKnownLocation', 'requestLocationUpdates',
                'LocationManagerService', 'ILocationManager', 'removeUpdates'
            ],
            'SensorManager': [
                'registerListener', 'SensorService', 'ISensorService',
                'unregisterListener', 'getDefaultSensor'
            ],
            'ConnectivityManager': [
                'getActiveNetworkInfo', 'ConnectivityService', 'IConnectivityManager',
                'requestNetwork', 'getNetworkCapabilities'
            ],
            'WifiManager': [
                'getWifiState', 'WifiService', 'IWifiManager',
                'startScan', 'getConnectionInfo'
            ],
        }
        
        for service, patterns in service_patterns.items():
            for frame in frames:
                if any(pattern in frame for pattern in patterns):
                    return service
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…·é«”æœå‹™ï¼Œå˜—è©¦å¾ frame ä¸­æå–
        for frame in frames:
            if 'Service' in frame:
                match = re.search(r'(\w+Service)', frame)
                if match:
                    return match.group(1)
            elif 'Manager' in frame and 'Proxy' in frame:
                match = re.search(r'(\w+Manager)', frame)
                if match:
                    return match.group(1)
        
        return None

    def _add_html_timeline_analysis(self):
        """æ·»åŠ  HTML æ ¼å¼çš„æ™‚é–“ç·šåˆ†æ"""
        # å»¶é²å°å…¥é¿å…å¾ªç’°å¼•å…¥
        from vp_analyze_logs_ext import TimelineAnalyzer, VisualizationGenerator
        
        timeline_analyzer = TimelineAnalyzer()
        timeline_data = timeline_analyzer.analyze_timeline(self.content, self.anr_info)
        
        # ç”Ÿæˆæ™‚é–“ç·šè¦–è¦ºåŒ–
        viz_generator = VisualizationGenerator()
        timeline_viz = viz_generator.generate_timeline_visualization(timeline_data)
        
        content = f'''
        <div class="timeline-analysis">
            <h3>äº‹ä»¶æ™‚é–“ç·šåˆ†æ</h3>
            {timeline_viz}
            
            <div class="timeline-findings">
                <h4>é—œéµç™¼ç¾</h4>
                <ul>
                    {''.join(f"<li>{rec}</li>" for rec in timeline_data.get('recommendations', []))}
                </ul>
            </div>
            
            <div class="critical-period">
                <h4>é—œéµæ™‚æœŸ</h4>
                {self._format_critical_period(timeline_data.get('critical_period'))}
            </div>
        </div>
        '''
        
        self.html_generator.add_section('æ™‚é–“ç·šåˆ†æ', content, 'timeline-section')

    def _add_html_anomaly_detection(self):
        """æ·»åŠ  HTML æ ¼å¼çš„ç•°å¸¸æª¢æ¸¬"""
        from vp_analyze_logs_ext import MLAnomalyDetector
        
        detector = MLAnomalyDetector()
        anomalies = detector.detect_anomalies(self.anr_info)
        
        if anomalies:
            anomaly_html = '''
            <div class="anomaly-list">
            '''
            
            for anomaly in anomalies:
                severity_class = 'high' if anomaly['score'] > 0.8 else 'medium'
                anomaly_html += f'''
                <div class="anomaly-item {severity_class}">
                    <h4>{anomaly['type'].replace('_', ' ').title()}</h4>
                    <div class="anomaly-score">ç•°å¸¸åˆ†æ•¸: {anomaly['score']:.2f}</div>
                    <div class="anomaly-explanation">{anomaly['explanation']}</div>
                </div>
                '''
            
            anomaly_html += '</div>'
            
            self.html_generator.add_section('AI ç•°å¸¸æª¢æ¸¬', anomaly_html, 'anomaly-section')

    def _add_html_risk_assessment(self):
        """æ·»åŠ  HTML æ ¼å¼çš„é¢¨éšªè©•ä¼°"""
        from vp_analyze_logs_ext import RiskAssessmentEngine
        
        risk_engine = RiskAssessmentEngine()
        
        # æº–å‚™ç³»çµ±ç‹€æ…‹æ•¸æ“š
        system_state = {
            'thread_count': len(self.anr_info.all_threads),
            'blocked_threads': sum(1 for t in self.anr_info.all_threads if t.state == ThreadState.BLOCKED),
            'cpu_usage': self.anr_info.cpu_usage.get('total', 0) if self.anr_info.cpu_usage else 0,
            'memory_available_mb': self.anr_info.memory_info.get('available', 0) / 1024 if self.anr_info.memory_info else 0
        }
        
        risk_assessment = risk_engine.assess_anr_risk(system_state)
        
        risk_html = f'''
        <div class="risk-assessment">
            <div class="overall-risk risk-{risk_assessment['risk_level']}">
                <h3>æ•´é«”é¢¨éšªç­‰ç´š: {risk_assessment['risk_level'].upper()}</h3>
                <div class="risk-score">é¢¨éšªåˆ†æ•¸: {risk_assessment['overall_risk']:.2f}</div>
                <div class="anr-probability">é æ¸¬ ANR æ¦‚ç‡: {risk_assessment['predicted_anr_probability']:.1%}</div>
            </div>
            
            <div class="risk-factors">
                <h4>é¢¨éšªå› ç´ åˆ†æ</h4>
                {self._format_risk_factors(risk_assessment['factors'])}
            </div>
            
            <div class="preventive-actions">
                <h4>é é˜²æªæ–½</h4>
                {self._format_preventive_actions(risk_assessment['recommendations'])}
            </div>
        </div>
        '''
        
        self.html_generator.add_section('é¢¨éšªè©•ä¼°', risk_html, 'risk-section')

    def _add_html_code_fix_suggestions(self):
        """æ·»åŠ  HTML æ ¼å¼çš„ä»£ç¢¼ä¿®å¾©å»ºè­°"""
        from vp_analyze_logs_ext import CodeFixGenerator
        
        fix_generator = CodeFixGenerator()
        
        # åŸºæ–¼åˆ†æçµæœç”Ÿæˆä¿®å¾©å»ºè­°
        fix_suggestions = []
        
        if self.anr_info.main_thread:
            for frame in self.anr_info.main_thread.backtrace[:5]:
                if 'File' in frame or 'SQLite' in frame:
                    fix_suggestions.extend(
                        fix_generator.generate_fix_suggestions('main_thread_io', {'stack_frame': frame})
                    )
                    break
                elif 'SharedPreferences' in frame and 'commit' in frame:
                    fix_suggestions.extend(
                        fix_generator.generate_fix_suggestions('shared_preferences_commit', {})
                    )
                    break
        
        if fix_suggestions:
            fix_html = '<div class="code-fixes">'
            
            for i, suggestion in enumerate(fix_suggestions[:3]):  # æœ€å¤šé¡¯ç¤º3å€‹
                fix_html += f'''
                <div class="fix-suggestion">
                    <h4>{suggestion['title']}</h4>
                    <div class="difficulty-{suggestion['difficulty']}">
                        é›£åº¦: {suggestion['difficulty']} | å½±éŸ¿: {suggestion['impact']}
                    </div>
                    
                    <div class="code-comparison">
                        <div class="code-before">
                            <h5>ä¿®æ”¹å‰:</h5>
                            <pre><code>{html.escape(suggestion['before'])}</code></pre>
                        </div>
                        <div class="code-after">
                            <h5>ä¿®æ”¹å¾Œ:</h5>
                            <pre><code>{html.escape(suggestion['after'])}</code></pre>
                        </div>
                    </div>
                    
                    <div class="fix-explanation">
                        <p>{suggestion['explanation']}</p>
                    </div>
                </div>
                '''
            
            fix_html += '</div>'
            
            self.html_generator.add_section('ä»£ç¢¼ä¿®å¾©å»ºè­°', fix_html, 'fix-section')

    def _generate_executive_summary(self) -> str:
        """ç”ŸæˆåŸ·è¡Œæ‘˜è¦"""
        from vp_analyze_logs_ext import ExecutiveSummaryGenerator
        
        summary_generator = ExecutiveSummaryGenerator()
        
        # æº–å‚™åˆ†æçµæœ
        analysis_results = {
            'anr_type': self.anr_info.anr_type.value,
            'severity': self._assess_severity(),
            'root_cause': self._quick_root_cause(),
            'frequency': 1,  # å¯¦éš›æ‡‰å¾æ­·å²æ•¸æ“šç²å–
            'fix_complexity': 'medium'  # å¯¦éš›æ‡‰æ ¹æ“šå•é¡Œé¡å‹è©•ä¼°
        }
        
        return summary_generator.generate_summary(analysis_results)

    def _format_critical_period(self, critical_period: Optional[Dict]) -> str:
        """æ ¼å¼åŒ–é—œéµæ™‚æœŸ"""
        if not critical_period:
            return '<p>æœªè­˜åˆ¥åˆ°æ˜é¡¯çš„é—œéµæ™‚æœŸ</p>'
        
        return f'''
        <div class="critical-period-details">
            <p>æ™‚é–“ç¯„åœ: {critical_period['start']} - {critical_period['end']}</p>
            <p>äº‹ä»¶æ•¸é‡: {critical_period['event_count']}</p>
            <p>å¹³å‡åš´é‡æ€§: {critical_period['avg_severity']:.1f}/10</p>
        </div>
        '''

    def _format_risk_factors(self, factors: Dict) -> str:
        """æ ¼å¼åŒ–é¢¨éšªå› ç´ """
        html = '<div class="factor-grid">'
        
        for factor_name, factor_data in factors.items():
            if isinstance(factor_data, dict) and 'score' in factor_data:
                risk_class = factor_data['risk_level']
                html += f'''
                <div class="factor-item risk-{risk_class}">
                    <h5>{factor_name.replace('_', ' ').title()}</h5>
                    <div class="factor-score">{factor_data['score']:.2f}</div>
                    <div class="factor-details">{factor_data.get('details', '')}</div>
                </div>
                '''
        
        html += '</div>'
        return html

    def _format_preventive_actions(self, actions: List[Dict]) -> str:
        """æ ¼å¼åŒ–é é˜²æªæ–½"""
        if not actions:
            return '<p>æš«ç„¡ç‰¹å®šé é˜²æªæ–½å»ºè­°</p>'
        
        html = '<ul class="action-list">'
        
        for action in actions:
            priority_class = f"priority-{action['priority']}"
            html += f'''
            <li class="{priority_class}">
                <strong>{action['action']}</strong>
                <p>{action['description']}</p>
            </li>
            '''
        
        html += '</ul>'
        return html
        
# ============= Tombstone åˆ†æå™¨ =============
class TombstoneAnalyzer(BaseAnalyzer):
    """Tombstone åˆ†æå™¨"""
    
    def _init_patterns(self) -> Dict:
        """åˆå§‹åŒ– Tombstone åˆ†ææ¨¡å¼"""
        return {
            'signal_patterns': [
                r'signal\s+(\d+)\s+\((\w+)\)',
                r'si_signo=(\d+).*?si_code=(\d+)',
                r'Fatal signal\s+(\d+)\s+\((\w+)\)',
                r'terminating with uncaught exception',
                r'Abort message',
            ],
            'process_patterns': [
                r'pid:\s*(\d+),\s*tid:\s*(\d+),\s*name:\s*([^\s]+)',
                r'pid\s+(\d+)\s+tid\s+(\d+)\s+name\s+([^\s]+)',
                r'Process:\s*([^,\s]+).*?PID:\s*(\d+)',
                r'Cmdline:\s*(.+)',
                r'>>> ([^\s]+) <<<',
            ],
            'abort_patterns': [
                r'Abort message:\s*["\'](.+?)["\']',
                r'Abort message:\s*(.+?)(?:\n|$)',
                r'abort_message:\s*"(.+?)"',
                r'CHECK\s+failed:\s*(.+)',
                r'Fatal Exception:\s*(.+)',
            ],
            'backtrace_patterns': [
                r'#(\d+)\s+pc\s+([0-9a-fA-F]+)\s+([^\s]+)(?:\s+\((.+?)\))?',
                r'#(\d+)\s+([0-9a-fA-F]+)\s+([^\s]+)(?:\s+\((.+?)\))?',
                r'backtrace:\s*#(\d+)\s+pc\s+([0-9a-fA-F]+)',
                r'at\s+([^\(]+)\(([^\)]+)\)',
            ],
            'memory_patterns': [
                r'([0-9a-f]+)-([0-9a-f]+)\s+([rwxps-]+)\s+([0-9a-f]+)\s+([0-9a-f:]+)\s+(\d+)\s+(.*)',
                r'memory near',
                r'code around',
            ],
            'register_patterns': [
                r'(r\d+|x\d+|pc|sp|lr|fp)\s+([0-9a-fA-F]+)',
                r'(eax|ebx|ecx|edx|esi|edi|ebp|esp|eip)\s+([0-9a-fA-F]+)',
            ],
            'fortify_patterns': [
                r'FORTIFY:\s*(.+)',
                r'fortify_fatal:\s*(.+)',
                r'detected source and destination buffer overlap',
                r'buffer overflow detected',
            ],
            'seccomp_patterns': [
                r'seccomp prevented call to disallowed.*?system call\s+(\d+)',
                r'signal\s+31\s+\(SIGSYS\)',
                r'SYS_SECCOMP',
            ],
            'java_patterns': [
                r'java:\s*(.+)',
                r'at\s+([a-zA-Z0-9._$]+)\(([^)]+)\)',
                r'Caused by:\s*(.+)',
            ],
        }
    
    @time_tracker("è§£æ Tombstone æª”æ¡ˆ")
    def analyze(self, file_path: str) -> str:
        """åˆ†æ Tombstone æª”æ¡ˆ"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()
            
            # è§£æ Tombstone è³‡è¨Š
            tombstone_info = self._parse_tombstone_info(content)
            
            # ç”Ÿæˆåˆ†æå ±å‘Š
            report = self._generate_report(tombstone_info, content)
            
            return report
            
        except Exception as e:
            return f"âŒ åˆ†æ Tombstone æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{traceback.format_exc()}"
    
    def _parse_tombstone_info(self, content: str) -> TombstoneInfo:
        """è§£æ Tombstone è³‡è¨Š"""
        lines = content.splitlines()
        
        # è§£æåŸºæœ¬è³‡è¨Š
        signal_info = self._extract_signal_info(content)
        process_info = self._extract_process_info(content)
        abort_message = self._extract_abort_message(content)
        
        # è§£æå´©æ½°å †ç–Š
        crash_backtrace = self._extract_backtrace(content)
        
        # è§£æè¨˜æ†¶é«”æ˜ å°„
        memory_map = self._extract_memory_map(content)
        
        # è§£ææ‰“é–‹çš„æª”æ¡ˆ
        open_files = self._extract_open_files(content)
        
        # è§£æå¯„å­˜å™¨
        registers = self._extract_registers(content)
        
        # è§£ææ‰€æœ‰ç·šç¨‹
        all_threads = self._extract_all_threads_tombstone(lines, content)
        
        # æ–°å¢ï¼šè§£æ Java å †ç–Šï¼ˆå¦‚æœæœ‰ï¼‰
        java_stack = self._extract_java_stack(content)
        
        tombstone_info = TombstoneInfo(
            signal=signal_info.get('signal', CrashSignal.UNKNOWN),
            signal_code=signal_info.get('code', 'Unknown'),
            fault_addr=signal_info.get('fault_addr', 'Unknown'),
            process_name=process_info.get('process_name', 'Unknown'),
            pid=process_info.get('pid', 'Unknown'),
            tid=process_info.get('tid', 'Unknown'),
            thread_name=process_info.get('thread_name', 'Unknown'),
            abort_message=abort_message,
            crash_backtrace=crash_backtrace,
            all_threads=all_threads,
            memory_map=memory_map,
            open_files=open_files,
            registers=registers
        )
        
        # æ–°å¢ï¼šåŠ å…¥ Java å †ç–Š
        if hasattr(tombstone_info, 'java_stack'):
            tombstone_info.java_stack = java_stack
        
        return tombstone_info
    
    def _extract_signal_info(self, content: str) -> Dict:
        """æå–ä¿¡è™Ÿè³‡è¨Š"""
        info = {}
        
        # æå–ä¿¡è™Ÿ
        for pattern in self.patterns['signal_patterns']:
            match = re.search(pattern, content)
            if match:
                if 'signal' in pattern and len(match.groups()) >= 2:
                    signal_num = int(match.group(1))
                    signal_name = match.group(2) if len(match.groups()) >= 2 else None
                    
                    # åŒ¹é…ä¿¡è™Ÿæšèˆ‰
                    for signal in CrashSignal:
                        if signal.value[0] == signal_num:
                            info['signal'] = signal
                            break
                    else:
                        info['signal'] = CrashSignal.UNKNOWN
                    
                    info['signal_num'] = signal_num
                    info['signal_name'] = signal_name
                    break
        
        # ç‰¹æ®Šè™•ç† SIGSYS (seccomp)
        if any(re.search(pattern, content) for pattern in self.patterns['seccomp_patterns']):
            info['signal'] = CrashSignal.SIGSYS
            info['signal_num'] = 31
            info['signal_name'] = 'SIGSYS'
            
            # æå–è¢«é˜»æ­¢çš„ç³»çµ±èª¿ç”¨è™Ÿ
            syscall_match = re.search(r'system call\s+(\d+)', content)
            if syscall_match:
                info['blocked_syscall'] = syscall_match.group(1)
        
        # æå–ä¿¡è™Ÿç¢¼
        code_match = re.search(r'(?:si_code|code)[=:\s]+([0-9-]+)', content)
        if code_match:
            info['code'] = code_match.group(1)
            
            # è§£æä¿¡è™Ÿç¢¼å«ç¾©
            info['code_meaning'] = self._interpret_signal_code(
                info.get('signal', CrashSignal.UNKNOWN),
                info['code']
            )
        
        # æå–æ•…éšœåœ°å€
        fault_patterns = [
            r'fault addr\s+([0-9a-fxA-FX]+)',
            r'si_addr\s+([0-9a-fxA-FX]+)',
            r'Accessing address:\s*([0-9a-fxA-FX]+)',
            r'Cause:\s*null pointer dereference',
        ]
        
        for pattern in fault_patterns:
            match = re.search(pattern, content)
            if match:
                if 'null pointer' in pattern:
                    info['fault_addr'] = '0x0'
                else:
                    info['fault_addr'] = match.group(1)
                break
        else:
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ•…éšœåœ°å€ï¼Œè¨­ç‚º Unknown
            info['fault_addr'] = 'Unknown'
        
        # æª¢æŸ¥ç‰¹æ®Šæ•…éšœåœ°å€
        if info.get('fault_addr'):
            addr = info['fault_addr'].lower()
            if addr in ['0x0', '0', '00000000', '0000000000000000']:
                info['fault_type'] = 'null_pointer'
            elif addr == '0xdeadbaad':
                info['fault_type'] = 'abort_marker'
            elif addr.startswith('0xdead'):
                info['fault_type'] = 'debug_marker'
            elif addr == '0xdeadbeef':
                info['fault_type'] = 'uninitialized'
        
        return info
    
    def _interpret_signal_code(self, signal: CrashSignal, code: str) -> str:
        """è§£é‡‹ä¿¡è™Ÿç¢¼çš„å«ç¾©"""
        try:
            code_num = int(code)
        except:
            return "Unknown"
        
        if signal == CrashSignal.SIGSEGV:
            segv_codes = {
                1: "SEGV_MAPERR - åœ°å€æœªæ˜ å°„",
                2: "SEGV_ACCERR - ç„¡è¨ªå•æ¬Šé™",
                3: "SEGV_BNDERR - é‚Šç•Œæª¢æŸ¥å¤±æ•—",
                4: "SEGV_PKUERR - ä¿è­·éµéŒ¯èª¤",
            }
            return segv_codes.get(code_num, f"Unknown SIGSEGV code {code_num}")
        elif signal == CrashSignal.SIGBUS:
            bus_codes = {
                1: "BUS_ADRALN - åœ°å€å°é½ŠéŒ¯èª¤",
                2: "BUS_ADRERR - ä¸å­˜åœ¨çš„ç‰©ç†åœ°å€",
                3: "BUS_OBJERR - å°è±¡ç‰¹å®šç¡¬é«”éŒ¯èª¤",
            }
            return bus_codes.get(code_num, f"Unknown SIGBUS code {code_num}")
        elif signal == CrashSignal.SIGILL:
            ill_codes = {
                1: "ILL_ILLOPC - éæ³•æ“ä½œç¢¼",
                2: "ILL_ILLOPN - éæ³•æ“ä½œæ•¸",
                3: "ILL_ILLADR - éæ³•å°‹å€æ¨¡å¼",
                4: "ILL_ILLTRP - éæ³•é™·é˜±",
                5: "ILL_PRVOPC - ç‰¹æ¬Šæ“ä½œç¢¼",
                6: "ILL_PRVREG - ç‰¹æ¬Šå¯„å­˜å™¨",
                7: "ILL_COPROC - å”è™•ç†å™¨éŒ¯èª¤",
                8: "ILL_BADSTK - å…§éƒ¨å †ç–ŠéŒ¯èª¤",
            }
            return ill_codes.get(code_num, f"Unknown SIGILL code {code_num}")
        
        return f"Signal code {code_num}"
    
    def _extract_process_info(self, content: str) -> Dict:
        """æå–é€²ç¨‹è³‡è¨Š"""
        info = {}
        
        for pattern in self.patterns['process_patterns']:
            match = re.search(pattern, content)
            if match:
                groups = match.groups()
                if 'pid:' in pattern and len(groups) >= 3:
                    info['pid'] = groups[0]
                    info['tid'] = groups[1]
                    info['process_name'] = groups[2]
                elif 'Process:' in pattern and len(groups) >= 2:
                    info['process_name'] = groups[0]
                    info['pid'] = groups[1]
                elif '>>>' in pattern and len(groups) >= 1:
                    info['process_name'] = groups[0]
                elif 'Cmdline:' in pattern and len(groups) >= 1:
                    info['cmdline'] = groups[0]
                    # å¾ cmdline æå–é€²ç¨‹å
                    if '/' in groups[0]:
                        info['process_name'] = groups[0].split('/')[-1]
                    else:
                        info['process_name'] = groups[0]
                
                if 'pid' in info and 'tid' in info:
                    break
        
        # æå–ç·šç¨‹åç¨±
        thread_patterns = [
            r'Thread-\d+\s+"([^"]+)"',
            r'name:\s*([^\s]+)\s+>>>',
            r'thread_name:\s*([^\s]+)',
        ]
        
        for pattern in thread_patterns:
            thread_match = re.search(pattern, content)
            if thread_match:
                info['thread_name'] = thread_match.group(1)
                break
        
        if 'thread_name' not in info:
            info['thread_name'] = info.get('process_name', 'Unknown')
        
        # æå– ABI å’Œæ§‹å»ºæŒ‡ç´‹
        abi_match = re.search(r"ABI:\s*'([^']+)'", content)
        if abi_match:
            info['abi'] = abi_match.group(1)
        
        fingerprint_match = re.search(r"Build fingerprint:\s*'([^']+)'", content)
        if fingerprint_match:
            info['build_fingerprint'] = fingerprint_match.group(1)
        
        return info
    
    def _extract_abort_message(self, content: str) -> Optional[str]:
        """æå– abort message"""
        for pattern in self.patterns['abort_patterns']:
            match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
            if match:
                message = match.group(1).strip()
                # æ¸…ç†è¨Šæ¯
                message = message.replace('\\n', '\n')
                message = message.replace('\\t', '\t')
                return message
        
        # æª¢æŸ¥ FORTIFY è¨Šæ¯
        for pattern in self.patterns['fortify_patterns']:
            match = re.search(pattern, content)
            if match:
                return f"FORTIFY: {match.group(1)}"
        
        return None
    
    def _extract_backtrace(self, content: str) -> List[Dict]:
        """æå–å´©æ½°å †ç–Š"""
        backtrace = []
        
        # æŸ¥æ‰¾ backtrace å€æ®µ
        backtrace_patterns = [
            r'(?:backtrace:|stack:)\s*\n(.*?)(?:\n\n|memory map:|open files:)',
            r'((?:#\d+\s+pc\s+[0-9a-fA-F]+.*\n)+)',
            r'Stack Trace:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        backtrace_text = None
        for pattern in backtrace_patterns:
            match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if match:
                backtrace_text = match.group(1)
                break
        
        if backtrace_text:
            # è§£æå †ç–Šå¹€
            for pattern in self.patterns['backtrace_patterns']:
                frames = re.findall(pattern, backtrace_text, re.MULTILINE)
                
                for frame_match in frames:
                    if len(frame_match) >= 3:
                        frame_info = {
                            'num': int(frame_match[0]) if frame_match[0].isdigit() else 0,
                            'pc': frame_match[1],
                            'location': frame_match[2],
                            'symbol': frame_match[3] if len(frame_match) > 3 else None
                        }
                        
                        # è§£æç¬¦è™Ÿè³‡è¨Š
                        if frame_info['symbol']:
                            frame_info['demangled'] = self._demangle_symbol(frame_info['symbol'])
                        
                        backtrace.append(frame_info)
                
                if backtrace:
                    break
        
        return backtrace
    
    def _demangle_symbol(self, symbol: str) -> str:
        """å˜—è©¦ demangle C++ ç¬¦è™Ÿ"""
        # é€™æ˜¯ç°¡åŒ–ç‰ˆæœ¬ï¼Œå¯¦éš›æ‡‰è©²èª¿ç”¨ c++filt
        if symbol.startswith('_Z'):
            # C++ mangled symbol
            return f"{symbol} (C++ mangled)"
        return symbol
    
    def _extract_memory_map(self, content: str) -> List[str]:
        """æå–è¨˜æ†¶é«”æ˜ å°„"""
        memory_map = []
        
        # æŸ¥æ‰¾ memory map å€æ®µ
        map_patterns = [
            r'memory map.*?:\s*\n(.*?)(?:\n\n|open files:|$)',
            r'maps:\s*\n(.*?)(?:\n\n|$)',
            r'memory near.*?:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in map_patterns:
            map_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if map_section:
                map_text = map_section.group(1)
                
                # è§£æè¨˜æ†¶é«”æ˜ å°„è¡Œ
                for line in map_text.splitlines():
                    if re.match(r'[0-9a-f]+-[0-9a-f]+\s+[rwxps-]+', line):
                        memory_map.append(line.strip())
                
                if memory_map:
                    break
        
        return memory_map[:100]  # é™åˆ¶æ•¸é‡
    
    def _extract_open_files(self, content: str) -> List[str]:
        """æå–æ‰“é–‹çš„æª”æ¡ˆ"""
        open_files = []
        
        # æŸ¥æ‰¾ open files å€æ®µ
        files_patterns = [
            r'open files.*?:\s*\n(.*?)(?:\n\n|$)',
            r'fd table:\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in files_patterns:
            files_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if files_section:
                files_text = files_section.group(1)
                
                for line in files_text.splitlines():
                    line = line.strip()
                    if line and not line.startswith('-'):
                        # è§£ææ–‡ä»¶æè¿°ç¬¦è³‡è¨Š
                        fd_match = re.match(r'(\d+):\s+(.+)', line)
                        if fd_match:
                            open_files.append(f"fd {fd_match.group(1)}: {fd_match.group(2)}")
                        else:
                            open_files.append(line)
                
                if open_files:
                    break
        
        return open_files[:50]  # é™åˆ¶æ•¸é‡
    
    def _extract_registers(self, content: str) -> Dict[str, str]:
        """æå–å¯„å­˜å™¨è³‡è¨Š"""
        registers = {}
        
        # æŸ¥æ‰¾å¯„å­˜å™¨å€æ®µ
        reg_patterns = [
            r'registers.*?:\s*\n(.*?)(?:\n\n|backtrace:|$)',
            r'((?:[rx]\d+|pc|sp|lr|fp)\s+[0-9a-fA-F]+.*\n)+',
        ]
        
        for pattern in reg_patterns:
            reg_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if reg_section:
                reg_text = reg_section.group(1)
                
                # è§£æå¯„å­˜å™¨
                for reg_pattern in self.patterns['register_patterns']:
                    matches = re.findall(reg_pattern, reg_text)
                    
                    for reg_name, reg_value in matches:
                        registers[reg_name] = reg_value
                
                if registers:
                    break
        
        # ç‰¹æ®Šè™•ç†æŸäº›æ¶æ§‹çš„å¯„å­˜å™¨é¡¯ç¤º
        if not registers:
            # ARM64 æ ¼å¼
            arm64_match = re.search(
                r'x0\s+([0-9a-f]+)\s+x1\s+([0-9a-f]+)\s+x2\s+([0-9a-f]+)\s+x3\s+([0-9a-f]+)',
                content
            )
            if arm64_match:
                for i in range(4):
                    registers[f'x{i}'] = arm64_match.group(i + 1)
        
        return registers
    
    def _extract_all_threads_tombstone(self, lines: List[str], content: str) -> List[ThreadInfo]:
        """æå–æ‰€æœ‰ç·šç¨‹è³‡è¨Š (Tombstone)"""
        threads = []
        
        # æŸ¥æ‰¾ç·šç¨‹å€æ®µ
        thread_patterns = [
            r'(?:threads|other threads).*?:\s*\n(.*?)(?:\n\n|memory map:|$)',
            r'--- --- --- --- --- --- --- ---\s*\n(.*?)(?:\n\n|$)',
        ]
        
        for pattern in thread_patterns:
            thread_section = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if thread_section:
                thread_text = thread_section.group(1)
                
                # è§£ææ¯å€‹ç·šç¨‹
                thread_blocks = re.split(r'\n(?=tid=|Thread \d+)', thread_text)
                
                for block in thread_blocks:
                    if 'tid=' in block or 'Thread' in block:
                        thread_info = self._parse_thread_block(block)
                        if thread_info:
                            threads.append(thread_info)
                
                break
        
        return threads
    
    def _parse_thread_block(self, block: str) -> Optional[ThreadInfo]:
        """è§£æç·šç¨‹å€å¡Š"""
        # æå–ç·šç¨‹è³‡è¨Š
        tid_match = re.search(r'tid=(\d+)', block)
        name_match = re.search(r'name=([^\s]+)', block)
        
        if tid_match:
            thread = ThreadInfo(
                name=name_match.group(1) if name_match else 'Unknown',
                tid=tid_match.group(1),
                state=ThreadState.UNKNOWN
            )
            
            # æå–å †ç–Š
            stack_lines = []
            for line in block.splitlines():
                if re.match(r'\s*#\d+\s+pc', line):
                    stack_lines.append(line.strip())
            
            thread.backtrace = stack_lines
            return thread
        
        return None
    
    def _extract_java_stack(self, content: str) -> List[str]:
        """æå– Java å †ç–Šï¼ˆå¦‚æœæœ‰ï¼‰"""
        java_stack = []
        
        # æŸ¥æ‰¾ Java å †ç–Šå€æ®µ
        java_patterns = [
            r'java stack trace.*?:\s*\n(.*?)(?:\n\n|$)',
            r'(at\s+[a-zA-Z0-9._$]+\([^)]+\).*\n)+',
        ]
        
        for pattern in java_patterns:
            java_match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
            if java_match:
                java_text = java_match.group(1)
                
                # è§£æ Java å †ç–Šè¡Œ
                for line in java_text.splitlines():
                    if line.strip().startswith('at '):
                        java_stack.append(line.strip())
                    elif line.strip().startswith('Caused by:'):
                        java_stack.append(line.strip())
                
                break
        
        return java_stack
    
    def _generate_report(self, info: TombstoneInfo, content: str) -> str:
        """ç”Ÿæˆ Tombstone å ±å‘Š"""
        generator = TombstoneReportGenerator(info, content)
        return generator.generate()
    
class TombstoneReportGenerator:
    """Tombstone å ±å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, info: TombstoneInfo, content: str):
        self.info = info
        self.content = content
        self.report_lines = []
        self.intelligent_engine = IntelligentAnalysisEngine()
    
    def generate(self) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        self._add_summary()
        self._add_basic_info()
        self._add_signal_analysis()
        self._add_abort_analysis()
        self._add_backtrace_analysis()
        self._add_memory_analysis()
        self._add_root_cause_analysis()
        self._add_intelligent_crash_analysis()  # æ–°å¢
        self._add_fortify_analysis()           # æ–°å¢
        self._add_symbol_resolution_guide()    # æ–°å¢
        self._add_suggestions()
        
        return "\n".join(self.report_lines)
    
    def _add_summary(self):
        """æ·»åŠ æ‘˜è¦"""
        self.report_lines.extend([
            "ğŸ’¥ Tombstone å´©æ½°åˆ†æå ±å‘Š",
            "=" * 60,
            f"ğŸ“Š å´©æ½°é¡å‹: {self._get_crash_type()}",
            f"ğŸš¨ ä¿¡è™Ÿ: {self.info.signal.value[1]} (signal {self.info.signal.value[0]})",
            f"ğŸ“± é€²ç¨‹: {self.info.process_name} (pid={self.info.pid})",
            f"ğŸ§µ ç·šç¨‹: {self.info.thread_name} (tid={self.info.tid})",
        ])
        
        # å¿«é€Ÿåˆ¤æ–·
        severity = self._assess_severity()
        self.report_lines.append(f"âš ï¸ åš´é‡ç¨‹åº¦: {severity}")
        
        root_cause = self._quick_root_cause()
        self.report_lines.append(f"ğŸ¯ å¯èƒ½åŸå› : {root_cause}")
        
        fixability = self._assess_fixability()
        self.report_lines.append(f"ğŸ”§ å¯ä¿®å¾©æ€§: {fixability}")
        
        self.report_lines.extend(["", "=" * 60, ""])

    def _add_suggestions(self):
        """æ·»åŠ è§£æ±ºå»ºè­°"""
        self.report_lines.append("\nğŸ’¡ è§£æ±ºå»ºè­°")
        
        suggestions = self._generate_suggestions()
        
        # èª¿è©¦å»ºè­°
        if suggestions['debugging']:
            self.report_lines.append("\nğŸ” èª¿è©¦å»ºè­°:")
            for i, suggestion in enumerate(suggestions['debugging'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # ä¿®å¾©å»ºè­°
        if suggestions['fixing']:
            self.report_lines.append("\nğŸ”§ ä¿®å¾©å»ºè­°:")
            for i, suggestion in enumerate(suggestions['fixing'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # é é˜²å»ºè­°
        if suggestions['prevention']:
            self.report_lines.append("\nğŸ›¡ï¸ é é˜²æªæ–½:")
            for i, suggestion in enumerate(suggestions['prevention'], 1):
                self.report_lines.append(f"  {i}. {suggestion}")
        
        # æ¨è–¦å·¥å…·
        self.report_lines.append("\nğŸ”¨ æ¨è–¦å·¥å…·:")
        tools = [
            "addr2line - ç¬¦è™Ÿè§£æ",
            "ndk-stack - å †ç–Šç¬¦è™ŸåŒ–",
            "AddressSanitizer (ASAN) - è¨˜æ†¶é«”éŒ¯èª¤æª¢æ¸¬",
            "ThreadSanitizer (TSAN) - ç·šç¨‹ç«¶çˆ­æª¢æ¸¬",
            "UndefinedBehaviorSanitizer (UBSAN) - æœªå®šç¾©è¡Œç‚ºæª¢æ¸¬",
            "Valgrind - è¨˜æ†¶é«”æ´©æ¼æª¢æ¸¬",
            "GDB/LLDB - èª¿è©¦å™¨",
            "Android Studio Native Debugger - IDE èª¿è©¦"
        ]
        
        for tool in tools:
            self.report_lines.append(f"  â€¢ {tool}")
        
        # ç›¸é—œæ–‡æª”
        self.report_lines.append("\nğŸ“š ç›¸é—œæ–‡æª”:")
        docs = [
            "Android NDK èª¿è©¦æŒ‡å—: https://developer.android.com/ndk/guides/debug",
            "AddressSanitizer ä½¿ç”¨: https://source.android.com/docs/security/test/asan",
            "Native Crash åˆ†æ: https://source.android.com/docs/core/architecture/debugging/native-crash",
            "Tombstone åˆ†ææŒ‡å—: https://source.android.com/docs/core/architecture/debugging"
        ]
        
        for doc in docs:
            self.report_lines.append(f"  â€¢ {doc}")
            
    def _get_crash_type(self) -> str:
        """ç²å–å´©æ½°é¡å‹"""
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000', '0000000000000000']:
                return "ç©ºæŒ‡é‡è§£å¼•ç”¨"
            else:
                return "è¨˜æ†¶é«”è¨ªå•é•è¦"
        elif self.info.signal == CrashSignal.SIGABRT:
            return "ç¨‹åºä¸»å‹•çµ‚æ­¢"
        elif self.info.signal == CrashSignal.SIGILL:
            return "éæ³•æŒ‡ä»¤"
        elif self.info.signal == CrashSignal.SIGBUS:
            return "åŒ¯æµæ’éŒ¯èª¤"
        elif self.info.signal == CrashSignal.SIGFPE:
            return "æµ®é»ç•°å¸¸"
        else:
            return "æœªçŸ¥å´©æ½°é¡å‹"
    
    def _assess_severity(self) -> str:
        """è©•ä¼°åš´é‡ç¨‹åº¦"""
        # æª¢æŸ¥æ˜¯å¦ç‚ºç³»çµ±é€²ç¨‹
        if any(keyword in self.info.process_name for keyword in ['system_server', 'zygote', 'mediaserver']):
            return "ğŸ”´ æ¥µå…¶åš´é‡ (ç³»çµ±é€²ç¨‹å´©æ½°)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¡†æ¶åº«
        if self.info.crash_backtrace:
            for frame in self.info.crash_backtrace[:3]:
                location = frame.get('location', '')
                if any(lib in location for lib in ['libc.so', 'libandroid_runtime.so', 'libbinder.so']):
                    return "ğŸŸ  åš´é‡ (æ¡†æ¶å±¤å´©æ½°)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå» å•†åº«
        if any('vendor' in frame.get('location', '') for frame in self.info.crash_backtrace[:5]):
            return "ğŸŸ¡ ä¸­ç­‰ (å» å•†åº«å•é¡Œ)"
        
        return "ğŸŸ¢ è¼•å¾® (æ‡‰ç”¨å±¤å´©æ½°)"
    
    def _quick_root_cause(self) -> str:
        """å¿«é€Ÿå®šä½æ ¹æœ¬åŸå› """
        causes = []
        
        # åŸºæ–¼ä¿¡è™Ÿ
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000']:
                causes.append("ç©ºæŒ‡é‡è§£å¼•ç”¨")
            else:
                causes.append("é‡æŒ‡é‡æˆ–è¨˜æ†¶é«”è¶Šç•Œ")
        elif self.info.signal == CrashSignal.SIGABRT:
            if self.info.abort_message:
                if 'assert' in self.info.abort_message.lower():
                    causes.append("æ–·è¨€å¤±æ•—")
                elif 'check failed' in self.info.abort_message.lower():
                    causes.append("æª¢æŸ¥å¤±æ•—")
                else:
                    causes.append("ä¸»å‹•çµ‚æ­¢")
            else:
                causes.append("ç•°å¸¸çµ‚æ­¢")
        
        # åŸºæ–¼å †ç–Š
        if self.info.crash_backtrace:
            top_frame = self.info.crash_backtrace[0]
            symbol = top_frame.get('symbol', '')
            location = top_frame.get('location', '')
            
            if 'malloc' in symbol or 'free' in symbol:
                causes.append("è¨˜æ†¶é«”ç®¡ç†éŒ¯èª¤")
            elif 'strlen' in symbol or 'strcpy' in symbol:
                causes.append("å­—ä¸²è™•ç†éŒ¯èª¤")
            elif 'JNI' in location:
                causes.append("JNI èª¿ç”¨éŒ¯èª¤")
        
        return " / ".join(causes) if causes else "éœ€é€²ä¸€æ­¥åˆ†æ"
    
    def _assess_fixability(self) -> str:
        """è©•ä¼°å¯ä¿®å¾©æ€§"""
        # æª¢æŸ¥æ˜¯å¦åœ¨æ‡‰ç”¨ä»£ç¢¼
        if self.info.crash_backtrace:
            for frame in self.info.crash_backtrace[:5]:
                location = frame.get('location', '')
                if self.info.process_name in location:
                    return "ğŸŸ¢ å®¹æ˜“ (æ‡‰ç”¨å±¤ä»£ç¢¼)"
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå» å•†åº«
        if any('vendor' in frame.get('location', '') for frame in self.info.crash_backtrace[:5]):
            return "ğŸŸ¡ ä¸­ç­‰ (éœ€è¦å» å•†æ”¯æ´)"
        
        # ç³»çµ±åº«
        if any(lib in frame.get('location', '') for frame in self.info.crash_backtrace[:3] 
               for lib in ['libc.so', 'libandroid_runtime.so']):
            return "ğŸ”´ å›°é›£ (ç³»çµ±å±¤å•é¡Œ)"
        
        return "ğŸŸ¡ ä¸­ç­‰"
    
    def _add_basic_info(self):
        """æ·»åŠ åŸºæœ¬è³‡è¨Š"""
        self.report_lines.append("ğŸ“‹ è©³ç´°è³‡è¨Š")
        self.report_lines.append(f"\nğŸ“ æ•…éšœåœ°å€: {self.info.fault_addr}")
        
        # åˆ†ææ•…éšœåœ°å€
        addr_analysis = self._analyze_fault_address()
        if addr_analysis:
            self.report_lines.append(f"   åˆ†æ: {addr_analysis}")
        
        self.report_lines.append(f"ğŸ“Ÿ ä¿¡è™Ÿç¢¼: {self.info.signal_code}")
    
    def _analyze_fault_address(self) -> Optional[str]:
        """åˆ†ææ•…éšœåœ°å€"""
        addr = self.info.fault_addr.lower()
        
        # æª¢æŸ¥æ˜¯å¦ç‚º Unknown æˆ–ç„¡æ•ˆåœ°å€
        if addr in ['unknown', 'n/a', 'none', '']:
            return None
        
        if addr in ['0x0', '0', '00000000', '0000000000000000']:
            return "ç©ºæŒ‡é‡ - å˜—è©¦è¨ªå• NULL"
        elif addr == '0xdeadbaad':
            return "Bionic libc abort æ¨™è¨˜"
        elif addr.startswith('0xdead'):
            return "å¯èƒ½æ˜¯èª¿è©¦æ¨™è¨˜æˆ–æå£çš„æŒ‡é‡"
        
        # å®‰å…¨åœ°å˜—è©¦è½‰æ›ç‚ºæ•´æ•¸
        try:
            addr_int = int(addr, 16)
            if addr_int < 0x1000:
                return "ä½åœ°å€ - å¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»"
            elif addr_int > 0x7fffffffffff:
                return "å…§æ ¸åœ°å€ç©ºé–“ - å¯èƒ½æ˜¯å…§æ ¸éŒ¯èª¤"
        except ValueError:
            # å¦‚æœç„¡æ³•è§£æç‚ºåå…­é€²åˆ¶ï¼Œè¿”å› None
            return None
        
        # æª¢æŸ¥æ˜¯å¦åœ¨è¨˜æ†¶é«”æ˜ å°„ä¸­
        for mem_line in self.info.memory_map[:20]:
            if '-' in mem_line:
                parts = mem_line.split()
                if parts:
                    range_str = parts[0]
                    if '-' in range_str:
                        start_str, end_str = range_str.split('-')
                        try:
                            start = int(start_str, 16)
                            end = int(end_str, 16)
                            addr_int = int(addr, 16)
                            if start <= addr_int <= end:
                                # æ‰¾åˆ°å°æ‡‰çš„è¨˜æ†¶é«”å€åŸŸ
                                if len(parts) > 6:
                                    return f"ä½æ–¼ {parts[6]}"
                        except:
                            pass
        
        return None
    
    def _add_signal_analysis(self):
        """æ·»åŠ ä¿¡è™Ÿåˆ†æ"""
        self.report_lines.append(f"\nğŸ” ä¿¡è™Ÿåˆ†æ")
        
        signal_analyses = {
            CrashSignal.SIGSEGV: [
                "è¨˜æ†¶é«”è¨ªå•é•è¦ - ç¨‹åºå˜—è©¦è¨ªå•ç„¡æ•ˆè¨˜æ†¶é«”",
                "å¸¸è¦‹åŸå› : ç©ºæŒ‡é‡ã€é‡æŒ‡é‡ã€æ•¸çµ„è¶Šç•Œã€ä½¿ç”¨å·²é‡‹æ”¾çš„è¨˜æ†¶é«”",
            ],
            CrashSignal.SIGABRT: [
                "ç¨‹åºä¸»å‹•çµ‚æ­¢ - é€šå¸¸ç”± abort() èª¿ç”¨è§¸ç™¼",
                "å¸¸è¦‹åŸå› : assert å¤±æ•—ã€æª¢æ¸¬åˆ°åš´é‡éŒ¯èª¤ã€æ‰‹å‹•èª¿ç”¨ abort",
            ],
            CrashSignal.SIGILL: [
                "éæ³•æŒ‡ä»¤ - CPU ç„¡æ³•åŸ·è¡Œçš„æŒ‡ä»¤",
                "å¸¸è¦‹åŸå› : ä»£ç¢¼æå£ã€å‡½æ•¸æŒ‡é‡éŒ¯èª¤ã€CPU æ¶æ§‹ä¸åŒ¹é…",
            ],
            CrashSignal.SIGBUS: [
                "åŒ¯æµæ’éŒ¯èª¤ - è¨˜æ†¶é«”å°é½Šæˆ–ç¡¬é«”å•é¡Œ",
                "å¸¸è¦‹åŸå› : æœªå°é½Šçš„è¨˜æ†¶é«”è¨ªå•ã€ç¡¬é«”æ•…éšœ",
            ],
            CrashSignal.SIGFPE: [
                "æµ®é»ç•°å¸¸ - æ•¸å­¸é‹ç®—éŒ¯èª¤",
                "å¸¸è¦‹åŸå› : é™¤é›¶ã€æ•´æ•¸æº¢å‡ºã€ç„¡æ•ˆçš„æµ®é»é‹ç®—",
            ],
        }
        
        analyses = signal_analyses.get(self.info.signal, ["æœªçŸ¥ä¿¡è™Ÿé¡å‹"])
        for analysis in analyses:
            self.report_lines.append(f"  â€¢ {analysis}")
    
    def _add_abort_analysis(self):
        """æ·»åŠ  abort message åˆ†æ"""
        if not self.info.abort_message:
            return
        
        self.report_lines.append(f"\nğŸ—¨ï¸ Abort Message åˆ†æ")
        self.report_lines.append(f"è¨Šæ¯: {self.info.abort_message}")
        
        # åˆ†æ abort message
        analyses = []
        
        msg_lower = self.info.abort_message.lower()
        
        if 'assert' in msg_lower:
            analyses.append("æª¢æ¸¬åˆ°æ–·è¨€å¤±æ•—")
            
            # å˜—è©¦æå–æ–‡ä»¶å’Œè¡Œè™Ÿ
            file_match = re.search(r'(\w+\.\w+):(\d+)', self.info.abort_message)
            if file_match:
                analyses.append(f"ä½ç½®: {file_match.group(1)}:{file_match.group(2)}")
        
        elif 'check failed' in msg_lower:
            analyses.append("åŸ·è¡Œæ™‚æª¢æŸ¥å¤±æ•—")
        
        elif 'fatal' in msg_lower:
            analyses.append("è‡´å‘½éŒ¯èª¤")
        
        elif 'out of memory' in msg_lower:
            analyses.append("è¨˜æ†¶é«”ä¸è¶³")
        
        elif 'stack overflow' in msg_lower:
            analyses.append("å †ç–Šæº¢å‡º")
        
        if analyses:
            self.report_lines.append("åˆ†æ:")
            for analysis in analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
    
    def _add_backtrace_analysis(self):
        """æ·»åŠ å †ç–Šåˆ†æ"""
        if not self.info.crash_backtrace:
            self.report_lines.append("\nâŒ ç„¡å´©æ½°å †ç–Šè³‡è¨Š")
            return
        
        self.report_lines.append(f"\nğŸ“š å´©æ½°å †ç–Šåˆ†æ (å…± {len(self.info.crash_backtrace)} å±¤)")
        
        # æ‰¾å‡ºå´©æ½°é»
        crash_point = self._find_crash_point()
        if crash_point:
            self.report_lines.append(f"ğŸ’¥ å´©æ½°é»: {crash_point}")
        
        # åˆ†æå †ç–Š
        stack_analyses = self._analyze_crash_stack()
        if stack_analyses:
            self.report_lines.append("\nå †ç–Šåˆ†æ:")
            for analysis in stack_analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
        
        # é¡¯ç¤ºé—œéµå †ç–Š
        self.report_lines.append("\né—œéµå †ç–Š:")
        for i, frame in enumerate(self.info.crash_backtrace[:15]):
            frame_str = self._format_frame(frame)
            marker = self._get_frame_marker_tombstone(frame)
            self.report_lines.append(f"  #{i:02d} {frame_str} {marker}")
    
    def _find_crash_point(self) -> Optional[str]:
        """æ‰¾å‡ºå´©æ½°é»"""
        for frame in self.info.crash_backtrace[:5]:
            if frame.get('symbol'):
                return f"#{frame['num']} {frame['symbol']} @ {frame['location']}"
        
        # å¦‚æœæ²’æœ‰ç¬¦è™Ÿï¼Œè¿”å›ç¬¬ä¸€å€‹æœ‰æ•ˆå¹€
        if self.info.crash_backtrace:
            frame = self.info.crash_backtrace[0]
            return f"#{frame['num']} pc {frame['pc']} @ {frame['location']}"
        
        return None
    
    def _analyze_crash_stack(self) -> List[str]:
        """åˆ†æå´©æ½°å †ç–Š"""
        analyses = []
        
        # æª¢æŸ¥è¨˜æ†¶é«”ç®¡ç†å•é¡Œ
        memory_funcs = ['malloc', 'free', 'realloc', 'calloc', 'delete', 'new']
        for frame in self.info.crash_backtrace[:10]:
            symbol = frame.get('symbol', '')
            if any(func in symbol for func in memory_funcs):
                analyses.append("æª¢æ¸¬åˆ°è¨˜æ†¶é«”ç®¡ç†å‡½æ•¸ - å¯èƒ½æ˜¯è¨˜æ†¶é«”æå£æˆ–é›™é‡é‡‹æ”¾")
                break
        
        # æª¢æŸ¥å­—ä¸²æ“ä½œ
        string_funcs = ['strlen', 'strcpy', 'strcat', 'strcmp', 'memcpy', 'memmove']
        for frame in self.info.crash_backtrace[:10]:
            symbol = frame.get('symbol', '')
            if any(func in symbol for func in string_funcs):
                analyses.append("æª¢æ¸¬åˆ°å­—ä¸²æ“ä½œå‡½æ•¸ - å¯èƒ½æ˜¯ç·©è¡å€æº¢å‡ºæˆ–ç„¡æ•ˆæŒ‡é‡")
                break
        
        # æª¢æŸ¥ JNI
        jni_found = False
        for frame in self.info.crash_backtrace[:10]:
            location = frame.get('location', '')
            symbol = frame.get('symbol', '')
            if 'JNI' in location or 'jni' in symbol.lower():
                analyses.append("æª¢æ¸¬åˆ° JNI èª¿ç”¨ - æª¢æŸ¥ Java/Native ä»‹é¢")
                jni_found = True
                break
        
        # æª¢æŸ¥ç³»çµ±åº«
        system_libs = ['libc.so', 'libandroid_runtime.so', 'libbinder.so', 'libutils.so']
        for frame in self.info.crash_backtrace[:5]:
            location = frame.get('location', '')
            for lib in system_libs:
                if lib in location:
                    if not jni_found:  # é¿å…é‡è¤‡
                        analyses.append(f"å´©æ½°ç™¼ç”Ÿåœ¨ç³»çµ±åº« {lib}")
                    break
        
        # æª¢æŸ¥å †ç–Šæ·±åº¦
        if len(self.info.crash_backtrace) > 50:
            analyses.append(f"å †ç–Šéæ·± ({len(self.info.crash_backtrace)} å±¤) - å¯èƒ½æœ‰éè¿´æˆ–å †ç–Šæº¢å‡º")
        
        return analyses
    
    def _format_frame(self, frame: Dict) -> str:
        """æ ¼å¼åŒ–å †ç–Šå¹€"""
        pc = frame.get('pc', 'Unknown')
        location = frame.get('location', 'Unknown')
        symbol = frame.get('symbol', '')
        
        if symbol:
            return f"pc {pc} {location} ({symbol})"
        else:
            return f"pc {pc} {location}"
    
    def _get_frame_marker_tombstone(self, frame: Dict) -> str:
        """ç²å–å †ç–Šå¹€æ¨™è¨˜ (Tombstone)"""
        symbol = frame.get('symbol', '')
        location = frame.get('location', '')
        
        # è¨˜æ†¶é«”ç®¡ç†
        if any(func in symbol for func in ['malloc', 'free', 'new', 'delete']):
            return "ğŸ’¾ [è¨˜æ†¶é«”]"
        
        # å­—ä¸²æ“ä½œ
        elif any(func in symbol for func in ['strlen', 'strcpy', 'strcat']):
            return "ğŸ“ [å­—ä¸²]"
        
        # JNI
        elif 'JNI' in location or 'jni' in symbol.lower():
            return "â˜• [JNI]"
        
        # ç³»çµ±åº«
        elif 'libc.so' in location:
            return "ğŸ”§ [libc]"
        elif 'libandroid_runtime.so' in location:
            return "ğŸ¤– [Runtime]"
        elif 'libbinder.so' in location:
            return "ğŸ”— [Binder]"
        
        # å» å•†åº«
        elif 'vendor' in location:
            return "ğŸ­ [å» å•†]"
        
        # æ‡‰ç”¨åº«
        elif self.info.process_name in location:
            return "ğŸ“± [æ‡‰ç”¨]"
        
        return ""
    
    def _add_memory_analysis(self):
        """æ·»åŠ è¨˜æ†¶é«”åˆ†æ"""
        if not self.info.memory_map:
            return
        
        self.report_lines.append(f"\nğŸ’¾ è¨˜æ†¶é«”æ˜ å°„åˆ†æ (é¡¯ç¤ºå‰ 20 é …)")
        
        # åˆ†ææ•…éšœåœ°å€æ‰€åœ¨å€åŸŸ
        fault_region = self._find_fault_memory_region()
        if fault_region:
            self.report_lines.append(f"\næ•…éšœåœ°å€æ‰€åœ¨å€åŸŸ:")
            self.report_lines.append(f"  {fault_region}")
        
        # é¡¯ç¤ºé—œéµè¨˜æ†¶é«”å€åŸŸ
        self.report_lines.append("\né—œéµè¨˜æ†¶é«”å€åŸŸ:")
        for i, mem_line in enumerate(self.info.memory_map[:20]):
            if any(keyword in mem_line for keyword in [
                self.info.process_name,
                'stack',
                'heap',
                '/system/lib',
                '/vendor/lib'
            ]):
                self.report_lines.append(f"  {mem_line}")
    
    def _find_fault_memory_region(self) -> Optional[str]:
        """æ‰¾å‡ºæ•…éšœåœ°å€æ‰€åœ¨çš„è¨˜æ†¶é«”å€åŸŸ"""
        try:
            fault_addr_int = int(self.info.fault_addr, 16)
        except:
            return None
        
        for mem_line in self.info.memory_map:
            if '-' in mem_line:
                parts = mem_line.split()
                if parts:
                    range_str = parts[0]
                    if '-' in range_str:
                        start_str, end_str = range_str.split('-')
                        try:
                            start = int(start_str, 16)
                            end = int(end_str, 16)
                            if start <= fault_addr_int <= end:
                                return mem_line
                        except:
                            continue
        
        return None
    
    def _add_root_cause_analysis(self):
        """æ·»åŠ æ ¹æœ¬åŸå› åˆ†æ"""
        self.report_lines.append("\nğŸ¯ æ ¹æœ¬åŸå› åˆ†æ")
        
        # åŸºæ–¼ä¿¡è™Ÿå’Œå †ç–Šçš„ç¶œåˆåˆ†æ
        root_causes = []
        
        # ç©ºæŒ‡é‡åˆ†æ
        if self.info.signal == CrashSignal.SIGSEGV and self.info.fault_addr in ['0x0', '0', '00000000']:
            root_causes.append("ç©ºæŒ‡é‡è§£å¼•ç”¨:")
            root_causes.append("  â€¢ æª¢æŸ¥æŒ‡é‡æ˜¯å¦åœ¨ä½¿ç”¨å‰åˆå§‹åŒ–")
            root_causes.append("  â€¢ æª¢æŸ¥å‡½æ•¸è¿”å›å€¼æ˜¯å¦ç‚º NULL")
            root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æå‰é‡‹æ”¾çš„æƒ…æ³")
        
        # è¨˜æ†¶é«”æå£åˆ†æ
        elif self.info.signal == CrashSignal.SIGSEGV:
            if self.info.crash_backtrace:
                top_symbol = self.info.crash_backtrace[0].get('symbol', '')
                if any(func in top_symbol for func in ['free', 'delete']):
                    root_causes.append("å¯èƒ½çš„é›™é‡é‡‹æ”¾æˆ–ä½¿ç”¨å·²é‡‹æ”¾è¨˜æ†¶é«”:")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡ free/delete")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦åœ¨é‡‹æ”¾å¾Œç¹¼çºŒä½¿ç”¨æŒ‡é‡")
                elif any(func in top_symbol for func in ['malloc', 'new']):
                    root_causes.append("è¨˜æ†¶é«”åˆ†é…å¤±æ•—æˆ–å †æå£:")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰è¨˜æ†¶é«”æ´©æ¼")
                    root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰ç·©è¡å€æº¢å‡º")
            
            root_causes.append("è¨˜æ†¶é«”è¨ªå•é•è¦:")
            root_causes.append("  â€¢ æª¢æŸ¥æ•¸çµ„é‚Šç•Œ")
            root_causes.append("  â€¢ æª¢æŸ¥æŒ‡é‡é‹ç®—")
        
        # Abort åˆ†æ
        elif self.info.signal == CrashSignal.SIGABRT:
            if self.info.abort_message:
                if 'assert' in self.info.abort_message.lower():
                    root_causes.append("æ–·è¨€å¤±æ•—:")
                    root_causes.append("  â€¢ ç¨‹åºç‹€æ…‹ä¸ç¬¦åˆé æœŸ")
                    root_causes.append("  â€¢ æª¢æŸ¥æ–·è¨€æ¢ä»¶")
                elif 'check failed' in self.info.abort_message.lower():
                    root_causes.append("é‹è¡Œæ™‚æª¢æŸ¥å¤±æ•—:")
                    root_causes.append("  â€¢ æª¢æŸ¥å¤±æ•—çš„æ¢ä»¶")
                    root_causes.append("  â€¢ åˆ†æç‚ºä½•æœƒé”åˆ°é€™å€‹ç‹€æ…‹")
            else:
                root_causes.append("ç¨‹åºä¸»å‹•çµ‚æ­¢:")
                root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æ˜ç¢ºçš„ abort() èª¿ç”¨")
                root_causes.append("  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æœªæ•ç²çš„ç•°å¸¸")
        
        for cause in root_causes:
            self.report_lines.append(f"  {cause}")
        
        self._add_intelligent_crash_analysis()  # æ–°å¢é€™è¡Œ
    
    def _add_intelligent_crash_analysis(self):
        """æ·»åŠ æ™ºèƒ½å´©æ½°åˆ†æ"""
        self.report_lines.append("\nğŸ§  æ™ºèƒ½å´©æ½°åˆ†æ")
        
        # åˆ†æå´©æ½°æ¨¡å¼
        crash_analysis = self.intelligent_engine.analyze_crash_pattern(self.info)
        
        # é¡¯ç¤ºå´©æ½°æµç¨‹
        if crash_analysis['crash_flow']:
            self.report_lines.append("\nğŸ“Š å´©æ½°èª¿ç”¨æµç¨‹:")
            for i, flow in enumerate(crash_analysis['crash_flow']):
                marker = "â†’" if i < len(crash_analysis['crash_flow']) - 1 else "ğŸ’¥"
                self.report_lines.append(
                    f"  {marker} #{i} pc {flow['pc']} @ {flow['location']}"
                )
                if flow['symbol']:
                    self.report_lines.append(f"      {flow['symbol']}")
                if flow['analysis'] != 'æœªçŸ¥':
                    self.report_lines.append(f"      åˆ†æ: {flow['analysis']}")
        
        # é¡¯ç¤ºè¨˜æ†¶é«”ä¸Šä¸‹æ–‡
        if crash_analysis['memory_context']:
            ctx = crash_analysis['memory_context']
            self.report_lines.append("\nğŸ’¾ è¨˜æ†¶é«”ä¸Šä¸‹æ–‡åˆ†æ:")
            
            if ctx['analysis']:
                self.report_lines.append(f"  â€¢ {ctx['analysis']}")
            
            if ctx['fault_location']:
                self.report_lines.append(f"  â€¢ å´©æ½°ä½ç½®: {ctx['fault_location']}")
            
            if ctx['nearby_regions']:
                self.report_lines.append("  â€¢ é™„è¿‘å€åŸŸ:")
                for region in ctx['nearby_regions'][:3]:
                    self.report_lines.append(f"    - {region}")
        
        # å´©æ½°ç°½å
        if crash_analysis['crash_signature']:
            self.report_lines.append(f"\nğŸ”‘ å´©æ½°ç°½å: {crash_analysis['crash_signature']}")
            self.report_lines.append("  (å¯ç”¨æ–¼æœå°‹ç›¸ä¼¼å´©æ½°)")
        
        # åŒ¹é…å·²çŸ¥æ¨¡å¼
        known_patterns = self.intelligent_engine.match_tombstone_patterns(self.info)
        if known_patterns:
            self.report_lines.append("\nğŸ¯ åŒ¹é…çš„å·²çŸ¥å´©æ½°æ¨¡å¼:")
            for pattern in known_patterns[:3]:
                self.report_lines.append(
                    f"\n  ğŸ“Œ {pattern['root_cause']} "
                    f"(ä¿¡å¿ƒåº¦: {pattern['confidence']*100:.0f}%)"
                )
                self.report_lines.append(f"     åš´é‡æ€§: {pattern['severity']}")
                self.report_lines.append("     è§£æ±ºæ–¹æ¡ˆ:")
                for solution in pattern['solutions']:
                    self.report_lines.append(f"       â€¢ {solution}")
        
        # ç›¸ä¼¼å´©æ½°å»ºè­°
        self._add_similar_crash_suggestions()
    
    def _add_similar_crash_suggestions(self):
        """æ·»åŠ ç›¸ä¼¼å´©æ½°å»ºè­°"""
        self.report_lines.append("\nğŸ” ç›¸ä¼¼å´©æ½°åˆ†æ:")
        
        # åŸºæ–¼å´©æ½°ç‰¹å¾µçµ¦å‡ºå»ºè­°
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000', '0000000000000000']:
                self.report_lines.extend([
                    "  â€¢ é€™æ˜¯å…¸å‹çš„ç©ºæŒ‡é‡å´©æ½°",
                    "  â€¢ å»ºè­°æœå°‹é¡ä¼¼çš„ç©ºæŒ‡é‡å´©æ½°æ¡ˆä¾‹",
                    "  â€¢ ä½¿ç”¨é˜²ç¦¦æ€§ç·¨ç¨‹æª¢æŸ¥æ‰€æœ‰æŒ‡é‡",
                ])
            elif int(self.info.fault_addr, 16) < 0x1000:
                self.report_lines.extend([
                    "  â€¢ ä½åœ°å€è¨ªå•ï¼Œå¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»",
                    "  â€¢ æª¢æŸ¥æ•¸çµ„æˆ–çµæ§‹é«”æˆå“¡è¨ªå•",
                ])
            else:
                self.report_lines.extend([
                    "  â€¢ è¨˜æ†¶é«”è¨ªå•é•è¦ï¼Œå¯èƒ½æ˜¯é‡æŒ‡é‡æˆ–ç·©è¡å€æº¢å‡º",
                    "  â€¢ å»ºè­°é–‹å•Ÿ AddressSanitizer (ASAN) é€²è¡Œèª¿è©¦",
                    "  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰ use-after-free æƒ…æ³",
                ])
        elif self.info.signal == CrashSignal.SIGABRT:
            self.report_lines.extend([
                "  â€¢ ä¸»å‹•çµ‚æ­¢é€šå¸¸ç”± assert æˆ–æª¢æŸ¥å¤±æ•—å¼•èµ·",
                "  â€¢ æŸ¥çœ‹ abort_message ç²å–æ›´å¤šè³‡è¨Š",
                "  â€¢ æª¢æŸ¥æ˜¯å¦æœ‰æœªæ•ç²çš„ç•°å¸¸",
            ])
        elif self.info.signal == CrashSignal.SIGSYS:
            self.report_lines.extend([
                "  â€¢ Seccomp é•è¦ - å˜—è©¦èª¿ç”¨è¢«ç¦æ­¢çš„ç³»çµ±èª¿ç”¨",
                "  â€¢ æª¢æŸ¥æ‡‰ç”¨çš„ seccomp ç­–ç•¥",
                "  â€¢ é¿å…ä½¿ç”¨å—é™çš„ç³»çµ±èª¿ç”¨",
            ])
    
    def _add_fortify_analysis(self):
        """æ·»åŠ  FORTIFY åˆ†æ"""
        fortify_info = self.intelligent_engine._analyze_fortify_failure(self.content)
        if fortify_info:
            self.report_lines.append("\nğŸ›¡ï¸ FORTIFY ä¿è­·æª¢æ¸¬")
            self.report_lines.append(f"  é¡å‹: {fortify_info['type']}")
            self.report_lines.append(f"  è¨Šæ¯: {fortify_info['message']}")
            self.report_lines.append(f"  åš´é‡æ€§: {fortify_info['severity']}")
            self.report_lines.append(f"  å»ºè­°: {fortify_info['suggestion']}")
            self.report_lines.append("  å¸¸è¦‹åŸå› :")
            self.report_lines.append("    â€¢ ç·©è¡å€æº¢å‡º")
            self.report_lines.append("    â€¢ å­—ä¸²æ“ä½œè¶Šç•Œ")
            self.report_lines.append("    â€¢ æ ¼å¼åŒ–å­—ä¸²æ¼æ´")
    
    def _add_symbol_resolution_guide(self):
        """æ·»åŠ ç¬¦è™Ÿè§£ææŒ‡å—"""
        self.report_lines.append("\nğŸ”§ ç¬¦è™Ÿè§£ææŒ‡å—")
        
        # ç”Ÿæˆ addr2line å‘½ä»¤
        addr2line_cmds = self._generate_addr2line_commands(self.info)
        if addr2line_cmds:
            self.report_lines.append("\nğŸ“ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è§£æè©³ç´°ç¬¦è™Ÿ:")
            for i, cmd in enumerate(addr2line_cmds[:5], 1):
                self.report_lines.append(f"  {i}. {cmd}")
            
            if len(addr2line_cmds) > 5:
                self.report_lines.append(f"  ... é‚„æœ‰ {len(addr2line_cmds) - 5} å€‹å‘½ä»¤")
        
        # æä¾› ndk-stack ä½¿ç”¨å»ºè­°
        self.report_lines.append("\nğŸ’¡ æˆ–ä½¿ç”¨ ndk-stack å·¥å…·:")
        self.report_lines.append("  $ ndk-stack -sym <path-to-symbols> -dump <tombstone-file>")
        
        # ç¬¦è™Ÿæ–‡ä»¶ä½ç½®æç¤º
        self.report_lines.append("\nğŸ“‚ ç¬¦è™Ÿæ–‡ä»¶é€šå¸¸ä½æ–¼:")
        self.report_lines.append("  â€¢ æœ¬åœ°ç·¨è­¯: out/target/product/*/symbols/")
        self.report_lines.append("  â€¢ NDK æ‡‰ç”¨: app/build/intermediates/cmake/*/obj/")
        self.report_lines.append("  â€¢ ç³»çµ±åº«: éœ€è¦å°æ‡‰ç‰ˆæœ¬çš„ symbols.zip")
    
    def _generate_addr2line_commands(self, tombstone_info: TombstoneInfo) -> List[str]:
        """ç”Ÿæˆ addr2line å‘½ä»¤ä¾›é–‹ç™¼è€…ä½¿ç”¨"""
        commands = []
        seen_libs = set()
        
        for frame in tombstone_info.crash_backtrace:
            location = frame.get('location', '')
            pc = frame.get('pc', '')
            
            # åªç‚º .so æ–‡ä»¶ç”Ÿæˆå‘½ä»¤
            if '.so' in location and location not in seen_libs:
                seen_libs.add(location)
                
                # åˆ¤æ–·æ¶æ§‹
                if 'arm64' in self.content or 'aarch64' in self.content:
                    prefix = "aarch64-linux-android-"
                elif 'arm' in self.content:
                    prefix = "arm-linux-androideabi-"
                elif 'x86_64' in self.content:
                    prefix = "x86_64-linux-android-"
                else:
                    prefix = "i686-linux-android-"
                
                cmd = f"{prefix}addr2line -C -f -e {location} {pc}"
                commands.append(cmd)
        
        return commands
    
    def _add_backtrace_analysis(self):
        """æ·»åŠ å †ç–Šåˆ†æ - å¢å¼·ç‰ˆ"""
        if not self.info.crash_backtrace:
            self.report_lines.append("\nâŒ ç„¡å´©æ½°å †ç–Šè³‡è¨Š")
            return
        
        self.report_lines.append(f"\nğŸ“š å´©æ½°å †ç–Šåˆ†æ (å…± {len(self.info.crash_backtrace)} å±¤)")
        
        # æ‰¾å‡ºå´©æ½°é»
        crash_point = self._find_crash_point()
        if crash_point:
            self.report_lines.append(f"ğŸ’¥ å´©æ½°é»: {crash_point}")
        
        # åˆ†æå †ç–Š
        stack_analyses = self._analyze_crash_stack()
        if stack_analyses:
            self.report_lines.append("\nå †ç–Šåˆ†æ:")
            for analysis in stack_analyses:
                self.report_lines.append(f"  â€¢ {analysis}")
        
        # é¡¯ç¤ºé—œéµå †ç–Š
        self.report_lines.append("\né—œéµå †ç–Š:")
        for i, frame in enumerate(self.info.crash_backtrace[:15]):
            frame_str = self._format_frame(frame)
            marker = self._get_frame_marker_tombstone(frame)
            self.report_lines.append(f"  #{i:02d} {frame_str} {marker}")
            
            # å°é—œéµå¹€æ·»åŠ é¡å¤–åˆ†æ
            if i < 5 and not frame.get('symbol'):
                self.report_lines.append(f"      ğŸ’¡ æç¤º: ä½¿ç”¨ addr2line è§£æç¬¦è™Ÿ")
    
    def _generate_suggestions(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆå»ºè­° - å¢å¼·ç‰ˆ"""
        suggestions = {
            'debugging': [],
            'fixing': [],
            'prevention': []
        }
        
        # èª¿è©¦å»ºè­°
        suggestions['debugging'].extend([
            "ä½¿ç”¨ addr2line å·¥å…·è§£æè©³ç´°çš„æºç¢¼ä½ç½®",
            "åœ¨ Android Studio ä¸­ä½¿ç”¨ LLDB èª¿è©¦å™¨é‡ç¾å•é¡Œ",
            "é–‹å•Ÿ AddressSanitizer (ASAN) æª¢æ¸¬è¨˜æ†¶é«”éŒ¯èª¤",
            "æ”¶é›† coredump é€²è¡Œé›¢ç·šåˆ†æ",
        ])
        
        # åŸºæ–¼å´©æ½°é¡å‹çš„å»ºè­°
        if self.info.signal == CrashSignal.SIGSEGV:
            if self.info.fault_addr in ['0x0', '0', '00000000']:
                suggestions['fixing'].extend([
                    "æª¢æŸ¥æ‰€æœ‰æŒ‡é‡ä½¿ç”¨å‰æ˜¯å¦ç‚º NULL",
                    "ç‚ºæŒ‡é‡æ·»åŠ é˜²ç¦¦æ€§æª¢æŸ¥",
                    "ä½¿ç”¨æ™ºèƒ½æŒ‡é‡ (å¦‚ std::unique_ptr, std::shared_ptr)",
                    "å•Ÿç”¨ç·¨è­¯å™¨çš„ -Wnull-dereference è­¦å‘Š",
                ])
            else:
                suggestions['fixing'].extend([
                    "æª¢æŸ¥æ•¸çµ„é‚Šç•Œè¨ªå•",
                    "ä½¿ç”¨ valgrind æˆ– ASAN æª¢æ¸¬è¨˜æ†¶é«”å•é¡Œ",
                    "æª¢æŸ¥å¤šç·šç¨‹ä¸‹çš„è¨˜æ†¶é«”è¨ªå•ç«¶çˆ­",
                    "ç¢ºèªè¨˜æ†¶é«”å°é½Šè¦æ±‚",
                ])
        
        elif self.info.signal == CrashSignal.SIGABRT:
            suggestions['fixing'].extend([
                "æª¢æŸ¥ assert æ¢ä»¶æ˜¯å¦åˆç†",
                "æ·»åŠ æ›´å¤šçš„éŒ¯èª¤è™•ç†å’Œæ¢å¾©æ©Ÿåˆ¶",
                "ä½¿ç”¨ try-catch æ•ç² C++ ç•°å¸¸",
                "æª¢æŸ¥æ˜¯å¦æœ‰è³‡æºè€—ç›¡ï¼ˆå¦‚è¨˜æ†¶é«”ã€æ–‡ä»¶å¥æŸ„ï¼‰",
            ])
        
        elif self.info.signal == CrashSignal.SIGSYS:
            suggestions['fixing'].extend([
                "æª¢æŸ¥ seccomp ç­–ç•¥é…ç½®",
                "é¿å…ä½¿ç”¨è¢«é™åˆ¶çš„ç³»çµ±èª¿ç”¨",
                "æ›´æ–°åˆ°æ”¯æ´çš„ API èª¿ç”¨æ–¹å¼",
            ])
        
        # JNI ç›¸é—œ
        if any('JNI' in frame.get('location', '') or 'jni' in frame.get('symbol', '').lower() 
               for frame in self.info.crash_backtrace[:10]):
            suggestions['fixing'].extend([
                "æª¢æŸ¥ JNI èª¿ç”¨çš„åƒæ•¸æœ‰æ•ˆæ€§",
                "ç¢ºä¿ JNI å±€éƒ¨å¼•ç”¨æ­£ç¢ºç®¡ç† (ä½¿ç”¨ NewLocalRef/DeleteLocalRef)",
                "æª¢æŸ¥ Java å’Œ Native ä¹‹é–“çš„æ•¸æ“šé¡å‹åŒ¹é…",
                "é©—è­‰ JNI æ–¹æ³•ç°½åæ­£ç¢ºæ€§",
                "ä½¿ç”¨ CheckJNI æ¨¡å¼èª¿è©¦ (-Xcheck:jni)",
            ])
        
        # é é˜²å»ºè­°
        suggestions['prevention'].extend([
            "ä½¿ç”¨éœæ…‹åˆ†æå·¥å…· (å¦‚ Clang Static Analyzer, PVS-Studio)",
            "ç·¨å¯«å–®å…ƒæ¸¬è©¦è¦†è“‹é‚Šç•Œæƒ…æ³",
            "ä½¿ç”¨ Code Review æª¢æŸ¥è¨˜æ†¶é«”ç®¡ç†",
            "é–‹å•Ÿç·¨è­¯å™¨çš„æ‰€æœ‰è­¦å‘Š (-Wall -Wextra -Werror)",
            "ä½¿ç”¨ Sanitizers é€²è¡ŒæŒçºŒæ¸¬è©¦ (ASAN, TSAN, UBSAN)",
            "å¯¦æ–½ FORTIFY_SOURCE ä¿è­·",
            "å®šæœŸé€²è¡Œ Fuzzing æ¸¬è©¦",
        ])
        
        # ç³»çµ±åº«å´©æ½°
        if any(lib in frame.get('location', '') for frame in self.info.crash_backtrace[:3]
               for lib in ['libc.so', 'libandroid_runtime.so']):
            suggestions['debugging'].append("æ”¶é›†å®Œæ•´çš„ bugreport åˆ†æç³»çµ±ç‹€æ…‹")
            suggestions['fixing'].append("æª¢æŸ¥æ˜¯å¦æœ‰ç³»çµ±è³‡æºè€—ç›¡")
            suggestions['fixing'].append("é©—è­‰ API èª¿ç”¨åƒæ•¸çš„æœ‰æ•ˆæ€§")
        
        return suggestions


# ============= åˆ†æå™¨å·¥å»  =============

class AnalyzerFactory:
    """åˆ†æå™¨å·¥å» """
    
    @staticmethod
    def create_analyzer(file_type: str) -> BaseAnalyzer:
        """å‰µå»ºåˆ†æå™¨"""
        if file_type.lower() == "anr":
            return ANRAnalyzer()
        elif file_type.lower() in ["tombstone", "tombstones"]:
            return TombstoneAnalyzer()
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹: {file_type}")


# ============= ä¸»ç¨‹å¼ =============

class LogAnalyzerSystem:
    """æ—¥èªŒåˆ†æç³»çµ±"""
    
    def __init__(self, input_folder: str, output_folder: str):
        self.input_folder = input_folder
        self.output_folder = output_folder
        self.stats = {
            'anr_count': 0,
            'tombstone_count': 0,
            'error_count': 0,
            'total_time': 0,
        }

    def _extract_report_info(self, html_content: str, file_path: str) -> Optional[Dict]:
        """å¾ HTML å ±å‘Šä¸­æå–é—œéµä¿¡æ¯"""

        info = {
            'path': file_path,  # ä¿ç•™çµ•å°è·¯å¾‘ä¾›å¾ŒçºŒè®€å–
            'filename': os.path.basename(file_path),
            'type': 'anr' if 'anr' in file_path.lower() else 'tombstone',
            'root_cause': '',
            'severity': '',
            'process_name': '',
            'features': [],
            'content': html_content  # ç›´æ¥ä¿å­˜å…§å®¹
        }
        
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–é—œéµä¿¡æ¯
        # æå–å¯èƒ½åŸå› 
        cause_match = re.search(r'å¯èƒ½åŸå› [ï¼š:]\s*([^<\n]+)', html_content)
        if cause_match:
            info['root_cause'] = cause_match.group(1).strip()
        
        # æå–åš´é‡ç¨‹åº¦
        severity_match = re.search(r'åš´é‡ç¨‹åº¦[ï¼š:]\s*([^<\n]+)', html_content)
        if severity_match:
            info['severity'] = severity_match.group(1).strip()
        
        # æå–é€²ç¨‹åç¨±
        process_match = re.search(r'é€²ç¨‹åç¨±[ï¼š:]\s*([^<\n]+)', html_content)
        if process_match:
            info['process_name'] = process_match.group(1).strip()
        
        # æå–ç‰¹å¾µï¼ˆç”¨æ–¼ç›¸ä¼¼åº¦è¨ˆç®—ï¼‰
        if 'Binder IPC' in html_content:
            info['features'].append('binder_ipc')
        if 'WindowManager' in html_content:
            info['features'].append('window_manager')
        if 'ç·šç¨‹æ•¸éå¤š' in html_content or 'ç·šç¨‹æ•¸é‡éå¤š' in html_content:
            info['features'].append('too_many_threads')
        if 'æ­»é–' in html_content:
            info['features'].append('deadlock')
        if 'è¨˜æ†¶é«”ä¸è¶³' in html_content:
            info['features'].append('memory_low')
        if 'WebView' in html_content:
            info['features'].append('webview')
        if 'ç©ºæŒ‡é‡' in html_content or 'null pointer' in html_content.lower():
            info['features'].append('null_pointer')
        if 'SIGSEGV' in html_content:
            info['features'].append('sigsegv')
        if 'SIGABRT' in html_content:
            info['features'].append('sigabrt')
        
        return info if info['root_cause'] else None

    def _analyze_similarity(self, reports: List[Dict]) -> List[Dict]:
        """åˆ†æå ±å‘Šçš„ç›¸ä¼¼åº¦ä¸¦åˆ†çµ„"""
        if not reports:
            return []
        
        # æŒ‰ root_cause åˆæ­¥åˆ†çµ„
        groups = {}
        for report in reports:
            root_cause = report['root_cause']
            if root_cause not in groups:
                groups[root_cause] = []
            groups[root_cause].append(report)
        
        # è¨ˆç®—æ¯çµ„çš„ç›¸ä¼¼åº¦ä¸¦ç°¡åŒ–æ¨™é¡Œ
        similarity_groups = []
        for root_cause, group_reports in groups.items():
            if len(group_reports) > 1:
                # è¨ˆç®—çµ„å…§ç›¸ä¼¼åº¦
                avg_similarity = self._calculate_group_similarity(group_reports)
                
                # æå–æœ€é—œéµçš„å…±åŒç‰¹å¾µä½œç‚ºæ¨™é¡Œ
                key_feature = self._extract_key_feature(group_reports)
                
                similarity_groups.append({
                    'title': key_feature,  # ä½¿ç”¨ç°¡åŒ–çš„æ¨™é¡Œ
                    'full_title': root_cause,  # ä¿ç•™å®Œæ•´æ¨™é¡Œä»¥å‚™ç”¨
                    'reports': group_reports,
                    'count': len(group_reports),
                    'similarity': avg_similarity,
                    'group_id': f"group_{len(similarity_groups)}"
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarity_groups.sort(key=lambda x: x['similarity'], reverse=True)
        
        return similarity_groups

    def _extract_key_feature(self, reports: List[Dict]) -> str:
        """æå–æœ€é—œéµçš„å…±åŒç‰¹å¾µä½œç‚ºç°¡åŒ–æ¨™é¡Œ"""
        # çµ±è¨ˆæ‰€æœ‰å ±å‘Šä¸­çš„é—œéµè©é »ç‡
        keyword_count = {}
        
        # å®šç¾©é—œéµè©å„ªå…ˆç´š
        priority_keywords = {
            'Binder IPC é˜»å¡': ['Binder IPC', 'BinderProxy', 'transact'],
            'ç·šç¨‹æ•¸éå¤š': ['ç·šç¨‹æ•¸éå¤š', 'ç·šç¨‹æ•¸é‡éå¤š', 'too many threads'],
            'æ­»é–': ['æ­»é–', 'deadlock', 'å¾ªç’°ç­‰å¾…'],
            'è¨˜æ†¶é«”ä¸è¶³': ['è¨˜æ†¶é«”ä¸è¶³', 'è¨˜æ†¶é«”åš´é‡ä¸è¶³', 'OutOfMemoryError'],
            'ä¸»ç·šç¨‹é˜»å¡': ['ä¸»ç·šç¨‹', 'main thread', 'UI thread'],
            'WindowManager æœå‹™é˜»å¡': ['WindowManager', 'window service'],
            'WebView å•é¡Œ': ['WebView', 'chromium'],
            'ç©ºæŒ‡é‡': ['ç©ºæŒ‡é‡', 'null pointer', 'NullPointerException'],
            'I/O æ“ä½œé˜»å¡': ['I/O', 'File', 'SQLite', 'SharedPreferences'],
            'ç¶²è·¯è«‹æ±‚é˜»å¡': ['Http', 'Socket', 'Network'],
        }
        
        # æª¢æŸ¥æ¯å€‹å„ªå…ˆé—œéµè©åœ¨æ‰€æœ‰å ±å‘Šä¸­çš„å‡ºç¾æƒ…æ³
        for key_feature, keywords in priority_keywords.items():
            found_in_all = True
            for report in reports:
                found = False
                # æª¢æŸ¥é€™å€‹ç‰¹å¾µçš„ä»»ä½•é—œéµè©æ˜¯å¦åœ¨å ±å‘Šä¸­
                for keyword in keywords:
                    if (keyword in report['root_cause'] or 
                        keyword in ' '.join(report['features'])):
                        found = True
                        break
                if not found:
                    found_in_all = False
                    break
            
            if found_in_all:
                return key_feature
        
        # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…±åŒçš„å„ªå…ˆé—œéµè©ï¼Œä½¿ç”¨æœ€å¸¸è¦‹çš„ç‰¹å¾µ
        all_features = []
        for report in reports:
            all_features.extend(report['features'])
        
        if all_features:
            from collections import Counter
            feature_counter = Counter(all_features)
            most_common = feature_counter.most_common(1)[0][0]
            
            # è½‰æ›ç‰¹å¾µåç¨±ç‚ºæ›´å‹å¥½çš„é¡¯ç¤º
            feature_map = {
                'binder_ipc': 'Binder IPC å•é¡Œ',
                'window_manager': 'WindowManager å•é¡Œ',
                'too_many_threads': 'ç·šç¨‹æ•¸éå¤š',
                'deadlock': 'æ­»é–å•é¡Œ',
                'memory_low': 'è¨˜æ†¶é«”ä¸è¶³',
                'webview': 'WebView å•é¡Œ',
                'null_pointer': 'ç©ºæŒ‡é‡éŒ¯èª¤',
                'sigsegv': 'è¨˜æ†¶é«”è¨ªå•é•è¦',
                'sigabrt': 'ç¨‹åºç•°å¸¸çµ‚æ­¢'
            }
            
            return feature_map.get(most_common, 'ç›¸ä¼¼å•é¡Œ')
        
        # æœ€å¾Œçš„fallback
        return 'ç›¸ä¼¼å•é¡Œ'

    def _calculate_group_similarity(self, reports: List[Dict]) -> float:
        """è¨ˆç®—çµ„å…§å¹³å‡ç›¸ä¼¼åº¦"""
        if len(reports) < 2:
            return 100.0
        
        similarities = []
        for i in range(len(reports)):
            for j in range(i + 1, len(reports)):
                sim = self._calculate_report_similarity(reports[i], reports[j])
                similarities.append(sim)
        
        return sum(similarities) / len(similarities) if similarities else 0

    def _calculate_report_similarity(self, report1: Dict, report2: Dict) -> float:
        """è¨ˆç®—å…©å€‹å ±å‘Šçš„ç›¸ä¼¼åº¦"""
        score = 0.0
        
        # ç›¸åŒçš„ root_cause
        if report1['root_cause'] == report2['root_cause']:
            score += 40
        
        # ç›¸åŒçš„åš´é‡ç¨‹åº¦
        if report1['severity'] == report2['severity']:
            score += 10
        
        # ç›¸åŒçš„é¡å‹
        if report1['type'] == report2['type']:
            score += 10
        
        # ç‰¹å¾µç›¸ä¼¼åº¦
        features1 = set(report1['features'])
        features2 = set(report2['features'])
        if features1 and features2:
            intersection = features1.intersection(features2)
            union = features1.union(features2)
            jaccard = len(intersection) / len(union)
            score += jaccard * 40
        
        return min(score, 100)
                    
    def analyze(self):
        """åŸ·è¡Œåˆ†æ"""
        start_time = time.time()
        
        print("ğŸš€ å•Ÿå‹•é€²éšç‰ˆ ANR/Tombstone åˆ†æç³»çµ±...")
        print(f"ğŸ“‚ è¼¸å…¥è³‡æ–™å¤¾: {self.input_folder}")
        print(f"ğŸ“‚ è¼¸å‡ºè³‡æ–™å¤¾: {self.output_folder}")
        print("")
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(self.output_folder, exist_ok=True)
        
        # æƒææª”æ¡ˆ
        files_to_analyze = self._scan_files()
        print(f"ğŸ“Š æ‰¾åˆ° {len(files_to_analyze)} å€‹æª”æ¡ˆéœ€è¦åˆ†æ")
        print("")
        
        # åˆ†ææª”æ¡ˆ
        index_data = {}
        for file_info in files_to_analyze:
            try:
                self._analyze_file(file_info, index_data)
            except Exception as e:
                print(f"âŒ åˆ†æ {file_info['path']} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                self.stats['error_count'] += 1
        
        # ç”Ÿæˆç´¢å¼•
        self._generate_index(index_data)
        
        # é¡¯ç¤ºçµ±è¨ˆ
        self.stats['total_time'] = time.time() - start_time
        self._show_statistics()
    
    def _scan_files(self) -> List[Dict]:
        """æƒææª”æ¡ˆ"""
        files = []
        
        for root, dirs, filenames in os.walk(self.input_folder):
            # éæ¿¾æ‰éš±è—è³‡æ–™å¤¾ï¼ˆä»¥ . é–‹é ­çš„è³‡æ–™å¤¾ï¼‰
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            
            base_dir = os.path.basename(root).lower()
            
            if base_dir in ["anr", "tombstones", "tombstone"]:
                for filename in filenames:
                    # è·³éç‰¹å®šæª”æ¡ˆ
                    if filename.endswith('.pb') or filename.endswith('.txt.analyzed'):
                        continue
                    if base_dir == "anr" and not filename.lower().startswith('anr'):
                        continue

                    file_path = os.path.join(root, filename)

                    # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼Œæ’é™¤ 0KB çš„æª”æ¡ˆ
                    try:
                        file_size = os.path.getsize(file_path)
                        if file_size == 0:
                            print(f"  è·³éç©ºæª”æ¡ˆ (0KB): {filename}")
                            continue
                    except OSError as e:
                        print(f"  ç„¡æ³•è®€å–æª”æ¡ˆå¤§å°: {filename} - {str(e)}")
                        continue

                    file_type = "anr" if base_dir == "anr" else "tombstone"
                    
                    files.append({
                        'path': file_path,
                        'type': file_type,
                        'name': filename,
                        'rel_path': os.path.relpath(file_path, self.input_folder)
                    })
        
        return files
    
    def _analyze_file(self, file_info: Dict, index_data: Dict):
        """åˆ†æå–®å€‹æª”æ¡ˆ"""
        print(f"ğŸ” åˆ†æ {file_info['type'].upper()}: {file_info['name']}")
        
        # å‰µå»ºåˆ†æå™¨
        analyzer = AnalyzerFactory.create_analyzer(file_info['type'])
        
        # åŸ·è¡Œåˆ†æ
        result = analyzer.analyze(file_info['path'])
        
        # ä¿å­˜çµæœ
        output_dir = os.path.join(self.output_folder, os.path.dirname(file_info['rel_path']))
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ–‡å­—ç‰ˆæœ¬
        output_file_txt = os.path.join(output_dir, file_info['name'] + '.analyzed.txt')
        with open(output_file_txt, 'w', encoding='utf-8') as f:
            f.write(result)
        
        # ç”Ÿæˆä¸¦ä¿å­˜ HTML ç‰ˆæœ¬
        output_file_html = os.path.join(output_dir, file_info['name'] + '.analyzed.html')
        try:
            html_content = self._generate_html_report(result, file_info)
            with open(output_file_html, 'w', encoding='utf-8') as f:
                f.write(html_content)
            print(f"âœ… HTML å ±å‘Šå·²ç”Ÿæˆ: {output_file_html}")
            
            # å¦‚æœ HTML ç”ŸæˆæˆåŠŸï¼Œä½¿ç”¨ HTML ç‰ˆæœ¬
            output_file = output_file_html
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ HTML å ±å‘Šå¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å¦‚æœ HTML ç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨æ–‡å­—ç‰ˆæœ¬
            output_file = output_file_txt
        
        # è¤‡è£½åŸå§‹æª”æ¡ˆ
        original_copy = os.path.join(output_dir, file_info['name'])
        shutil.copy2(file_info['path'], original_copy)
        
        # æ›´æ–°ç´¢å¼•ï¼ˆä¿æŒåŸæœ‰çµæ§‹ï¼‰
        self._update_index(index_data, file_info['rel_path'], output_file, original_copy)
        
        # æ›´æ–°çµ±è¨ˆ
        if file_info['type'] == 'anr':
            self.stats['anr_count'] += 1
        else:
            self.stats['tombstone_count'] += 1
    
    def _generate_html_report(self, text_content: str, file_info: Dict) -> str:
        """ç”Ÿæˆ HTML æ ¼å¼çš„åˆ†æå ±å‘Šï¼ˆæ”¯æ´åˆ†å‰²è¦–çª—ï¼‰"""
        import json
        
        # åŸå§‹æª”æ¡ˆçš„ç›¸å°è·¯å¾‘
        original_file = file_info['name']
        
        # å°‡å…§å®¹åˆ†è¡Œä¸¦é€²è¡Œ JSON ç·¨ç¢¼ï¼ˆæœ€å®‰å…¨çš„æ–¹å¼ï¼‰
        lines = text_content.split('\n')
        json_lines = json.dumps(lines, ensure_ascii=False)
        
        return f"""<!DOCTYPE html>
    <html lang="zh-TW">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{html.escape(file_info['name'])} - åˆ†æå ±å‘Š</title>
        <style>
            * {{
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }}
            
            body {{
                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
                background: #1a1a1a;
                color: #d4d4d4;
                overflow: hidden;
                height: 100vh;
            }}
            
            /* åˆ†å‰²è¦–çª—å®¹å™¨ */
            .split-container {{
                display: flex;
                height: 100vh;
                position: relative;
            }}
            
            /* å·¦å´é¢æ¿ - åˆ†æå ±å‘Š */
            .left-panel {{
                flex: 1;
                overflow-y: auto;
                background: #1e1e1e;
                position: relative;
            }}
            
            /* å³å´é¢æ¿ - åŸå§‹æª”æ¡ˆ */
            .right-panel {{
                flex: 0;
                width: 0;
                overflow-y: auto;
                background: #252526;
                position: relative;
                transition: width 0.3s ease;
            }}
            
            .right-panel.open {{
                flex: 1;
                width: 50%;
            }}
            
            /* åˆ†å‰²æ¢ */
            .splitter {{
                width: 5px;
                background: #333;
                cursor: col-resize;
                position: relative;
                display: none;
            }}
            
            .splitter.visible {{
                display: block;
            }}
            
            .splitter:hover {{
                background: #007acc;
            }}
            
            /* é¢æ¿å…§å®¹ */
            .panel-content {{
                padding: 20px;
                font-size: 14px;
                line-height: 1.6;
                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            }}
            
            /* æ¨™é¡Œæ¬„ */
            .panel-header {{
                position: sticky;
                top: 0;
                background: #2d2d30;
                padding: 10px 20px;
                display: flex;
                justify-content: space-between;
                align-items: center;
                border-bottom: 1px solid #3e3e42;
                z-index: 10;
            }}
            
            .panel-title {{
                font-weight: bold;
                color: #cccccc;
            }}
            
            /* æ§åˆ¶æŒ‰éˆ• */
            .panel-controls {{
                display: flex;
                gap: 10px;
            }}
            
            .control-btn {{
                background: transparent;
                border: none;
                color: #cccccc;
                cursor: pointer;
                padding: 5px 10px;
                border-radius: 3px;
                font-size: 14px;
                transition: all 0.2s;
            }}
            
            .control-btn:hover {{
                background: #3e3e42;
                color: #ffffff;
            }}
            
            /* æŸ¥çœ‹åŸå§‹æª”æ¡ˆé€£çµ */
            .view-original {{
                color: #4ec9b0;
                text-decoration: underline;
                cursor: pointer;
            }}
            
            .view-original:hover {{
                color: #6edcb8;
            }}
            
            /* å…¨å±æ¨¡å¼ */
            .fullscreen {{
                position: fixed !important;
                top: 0 !important;
                left: 0 !important;
                right: 0 !important;
                bottom: 0 !important;
                width: 100% !important;
                height: 100% !important;
                z-index: 9999;
                max-width: 100% !important;
            }}
            
            /* Loading */
            .loading {{
                text-align: center;
                padding: 50px;
                color: #666;
            }}
            
            /* å ±å‘Šè¡Œæ¨£å¼ */
            .report-line {{
                white-space: pre-wrap;
                word-wrap: break-word;
                margin: 0;
                padding: 2px 0;
            }}
            
            /* é«˜äº®æ¨£å¼ */
            .anr-type {{
                color: #ff9800;
                font-weight: bold;
            }}
            
            .process-name {{
                color: #4ec9b0;
                font-weight: bold;
            }}
            
            .timestamp {{
                color: #608b4e;
            }}
            
            .separator {{
                color: #565656;
            }}
            
            .emoji {{
                font-size: 1.1em;
            }}
            
            /* åŸå§‹æª”æ¡ˆå…§å®¹ */
            .original-content {{
                white-space: pre;
                font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            }}
        </style>
    </head>
    <body>
        <div class="split-container">
            <!-- å·¦å´é¢æ¿ - åˆ†æå ±å‘Š -->
            <div class="left-panel" id="leftPanel">
                <div class="panel-content" id="reportContent">è¼‰å…¥ä¸­...</div>
            </div>
            
            <!-- åˆ†å‰²æ¢ -->
            <div class="splitter" id="splitter"></div>
            
            <!-- å³å´é¢æ¿ - åŸå§‹æª”æ¡ˆ -->
            <div class="right-panel" id="rightPanel">
                <div class="panel-header">
                    <span class="panel-title">ğŸ“„ åŸå§‹æª”æ¡ˆ: {html.escape(original_file)}</span>
                    <div class="panel-controls">
                        <button class="control-btn" onclick="toggleFullscreen('rightPanel')" title="å…¨å±">â›¶</button>
                        <button class="control-btn" onclick="closeRightPanel()" title="é—œé–‰">âœ•</button>
                    </div>
                </div>
                <div class="panel-content" id="originalContent">
                    <div class="loading">è¼‰å…¥ä¸­...</div>
                </div>
            </div>
        </div>
        
        <script>
            // å ±å‘Šå…§å®¹ï¼ˆä½¿ç”¨ JSON æ ¼å¼æœ€å®‰å…¨ï¼‰
            const reportLines = {json_lines};
            
            // åˆå§‹åŒ–
            document.addEventListener('DOMContentLoaded', function() {{
                processReportContent();
            }});
            
            // è™•ç†å ±å‘Šå…§å®¹
            function processReportContent() {{
                const container = document.getElementById('reportContent');
                container.innerHTML = '';
                
                reportLines.forEach(function(line) {{
                    const div = document.createElement('div');
                    div.className = 'report-line';
                    
                    // è™•ç†ç‰¹æ®Šæ ¼å¼
                    let processedLine = line;
                    
                    // å°‡ "æŸ¥çœ‹åŸå§‹æª”æ¡ˆ" è½‰æ›ç‚ºé€£çµ
                    if (line.includes('ğŸ”— æŸ¥çœ‹åŸå§‹æª”æ¡ˆ:')) {{
                        processedLine = line.replace(
                            /ğŸ”— æŸ¥çœ‹åŸå§‹æª”æ¡ˆ: (.+)/,
                            'ğŸ”— <a class="view-original" onclick="openOriginalFile()">æŸ¥çœ‹åŸå§‹æª”æ¡ˆ: $1</a>'
                        );
                    }}
                    
                    // é«˜äº®é—œéµå­—
                    processedLine = processedLine.replace(/ANR é¡å‹: (.+)/, 'ANR é¡å‹: <span class="anr-type">$1</span>');
                    processedLine = processedLine.replace(/é€²ç¨‹åç¨±: (.+)/, 'é€²ç¨‹åç¨±: <span class="process-name">$1</span>');
                    processedLine = processedLine.replace(/ç™¼ç”Ÿæ™‚é–“: (.+)/, 'ç™¼ç”Ÿæ™‚é–“: <span class="timestamp">$1</span>');
                    
                    // è™•ç†åˆ†éš”ç·š
                    if (/^=+$/.test(processedLine)) {{
                        processedLine = '<span class="separator">' + processedLine + '</span>';
                    }}
                    
                    div.innerHTML = processedLine;
                    container.appendChild(div);
                }});
            }}
            
            // é–‹å•ŸåŸå§‹æª”æ¡ˆ
            function openOriginalFile() {{
                const rightPanel = document.getElementById('rightPanel');
                const splitter = document.getElementById('splitter');
                
                rightPanel.classList.add('open');
                splitter.classList.add('visible');
                
                loadOriginalFile();
            }}
            
            // è¼‰å…¥åŸå§‹æª”æ¡ˆ
            async function loadOriginalFile() {{
                try {{
                    const response = await fetch('{original_file}');
                    const text = await response.text();
                    
                    const contentDiv = document.getElementById('originalContent');
                    contentDiv.innerHTML = '';
                    
                    const pre = document.createElement('pre');
                    pre.className = 'original-content';
                    pre.textContent = text;
                    
                    contentDiv.appendChild(pre);
                }} catch (error) {{
                    document.getElementById('originalContent').innerHTML = 
                        '<div class="loading">è¼‰å…¥å¤±æ•—: ' + error.message + '</div>';
                }}
            }}
            
            // é—œé–‰å³å´é¢æ¿
            function closeRightPanel() {{
                const rightPanel = document.getElementById('rightPanel');
                const splitter = document.getElementById('splitter');
                
                rightPanel.classList.remove('open');
                splitter.classList.remove('visible');
            }}
            
            // å…¨å±åˆ‡æ›
            function toggleFullscreen(panelId) {{
                const panel = document.getElementById(panelId);
                panel.classList.toggle('fullscreen');
            }}
            
            // åˆ†å‰²æ¢æ‹–å‹•
            let isResizing = false;
            
            document.getElementById('splitter').addEventListener('mousedown', function(e) {{
                isResizing = true;
                document.body.style.cursor = 'col-resize';
                e.preventDefault();
            }});
            
            document.addEventListener('mousemove', function(e) {{
                if (!isResizing) return;
                
                const container = document.querySelector('.split-container');
                const leftPanel = document.getElementById('leftPanel');
                const rightPanel = document.getElementById('rightPanel');
                
                const containerWidth = container.offsetWidth;
                const leftWidth = e.clientX;
                const leftPercent = (leftWidth / containerWidth) * 100;
                
                if (leftPercent > 20 && leftPercent < 80) {{
                    leftPanel.style.flex = '0 0 ' + leftPercent + '%';
                    rightPanel.style.flex = '0 0 ' + (100 - leftPercent) + '%';
                }}
            }});
            
            document.addEventListener('mouseup', function() {{
                isResizing = false;
                document.body.style.cursor = 'default';
            }});
            
            // ESC é€€å‡ºå…¨å±
            document.addEventListener('keydown', function(e) {{
                if (e.key === 'Escape') {{
                    document.querySelectorAll('.fullscreen').forEach(function(el) {{
                        el.classList.remove('fullscreen');
                    }});
                }}
            }});
        </script>
    </body>
    </html>"""

    def _update_index(self, index_data: Dict, rel_path: str, analyzed_file: str, original_file: str):
        """æ›´æ–°ç´¢å¼• - ä½¿ç”¨çµ•å°è·¯å¾‘"""
        parts = rel_path.split(os.sep)
        current = index_data
        
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            current = current[part]
        
        filename = parts[-1]
        
        # æ ¹æ“šåˆ†ææª”æ¡ˆçš„å¯¦éš›æ ¼å¼å»ºç«‹ç´¢å¼•éµ
        if analyzed_file.endswith('.html'):
            index_key = filename + '.analyzed.html'
        else:
            index_key = filename + '.analyzed.txt'
        
        # å„²å­˜çµ•å°è·¯å¾‘è€Œä¸æ˜¯ç›¸å°è·¯å¾‘
        current[index_key] = {
            'analyzed_file': os.path.abspath(analyzed_file),  # ä½¿ç”¨çµ•å°è·¯å¾‘
            'original_file': os.path.abspath(original_file)   # ä½¿ç”¨çµ•å°è·¯å¾‘
        }
    
    def _generate_index(self, index_data: Dict):
        """ç”Ÿæˆ HTML ç´¢å¼•"""
        print(f"\nğŸ“Š æœ€çµ‚ç´¢å¼•æ•¸æ“šçµæ§‹:")
        print(json.dumps(index_data, indent=2, ensure_ascii=False)[:1000])
        print("...")
        
        # çµ±è¨ˆå¯¦éš›çš„ HTML æª”æ¡ˆ
        anr_html_count = 0
        tombstone_html_count = 0
        
        # æ”¶é›†æ‰€æœ‰åˆ†æå ±å‘Šç”¨æ–¼ç›¸ä¼¼åº¦åˆ†æ
        analyzed_reports = []
        
        for root, dirs, files in os.walk(self.output_folder):
            for file in files:
                if file.endswith('.analyzed.html'):
                    full_path = os.path.join(root, file)
                    rel_path = os.path.relpath(root, self.output_folder).lower()
                    
                    # è®€å–åˆ†æå ±å‘Šå…§å®¹
                    try:
                        with open(full_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            # æå–åˆ†æå ±å‘Šçš„é—œéµä¿¡æ¯
                            report_info = self._extract_report_info(content, full_path)
                            if report_info:
                                analyzed_reports.append(report_info)
                    except Exception as e:
                        print(f"è®€å–å ±å‘Šå¤±æ•—: {full_path} - {e}")
                    
                    if 'anr' in rel_path:
                        anr_html_count += 1
                    elif 'tombstone' in rel_path:
                        tombstone_html_count += 1
        
        # æ›´æ–°çµ±è¨ˆæ•¸æ“š
        self.stats['anr_count'] = anr_html_count
        self.stats['tombstone_count'] = tombstone_html_count
        
        # é€²è¡Œç›¸ä¼¼åº¦åˆ†æ
        similarity_groups = self._analyze_similarity(analyzed_reports)
        
        html_content = self._generate_html_index(index_data, similarity_groups)
        
        index_file = os.path.join(self.output_folder, 'index.html')
        with open(index_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"\nğŸ“ å·²ç”Ÿæˆç´¢å¼•æª”æ¡ˆ: {index_file}")
    
    def _get_original_styles(self) -> str:
        """ç²å–åŸå§‹æ¨£å¼ï¼ˆä¿æŒä¸è®Šï¼‰"""
        return """
            * {
                margin: 0;
                padding: 0;
                box-sizing: border-box;
            }
            
            :root {
                --bg-primary: #212121;
                --bg-secondary: #2a2a2a;
                --bg-hover: #343434;
                --text-primary: #ececec;
                --text-secondary: #a0a0a0;
                --text-muted: #6e6e6e;
                --border: #424242;
                --accent: #10a37f;
                --accent-hover: #0e8e6f;
                --anr-color: #ff9800;
                --tombstone-color: #ab47bc;
                --shadow: 0 2px 8px rgba(0, 0, 0, 0.3);
                --radius: 8px;
            }
            
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Helvetica Neue', Arial, sans-serif;
                background: var(--bg-primary);
                color: var(--text-primary);
                line-height: 1.6;
                min-height: 100vh;
            }
            
            .container {
                max-width: 1000px;
                margin: 0 auto;
                padding: 20px;
            }
            
            /* Header */
            .header {
                text-align: center;
                padding: 60px 0 40px;
                border-bottom: 1px solid var(--border);
                margin-bottom: 40px;
            }
            
            .header h1 {
                font-size: 32px;
                font-weight: 600;
                margin-bottom: 12px;
                color: var(--text-primary);
            }
            
            .header .subtitle {
                font-size: 16px;
                color: var(--text-secondary);
            }
            
            /* Stats */
            .stats {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 16px;
                margin: 40px 0;
            }
            
            .stat-card {
                background: var(--bg-secondary);
                border: 1px solid var(--border);
                border-radius: var(--radius);
                padding: 20px;
                text-align: center;
                transition: all 0.2s ease;
            }
            
            .stat-card:hover {
                border-color: var(--accent);
                transform: translateY(-2px);
            }
            
            .stat-value {
                font-size: 28px;
                font-weight: 600;
                color: var(--accent);
            }
            
            .stat-label {
                font-size: 14px;
                color: var(--text-secondary);
                margin-top: 4px;
            }
            
            /* File Browser */
            .file-browser {
                background: var(--bg-secondary);
                border: 1px solid var(--border);
                border-radius: var(--radius);
                overflow: hidden;
            }
            
            /* File Item */
            .file-item {
                border-bottom: 1px solid var(--border);
                position: relative;
                transition: background 0.2s ease;
            }
            
            .file-item:last-child {
                border-bottom: none;
            }
            
            .file-item:hover {
                background: var(--bg-hover);
            }
            
            .file-link {
                display: block;
                text-decoration: none;
                color: inherit;
            }
            
            .file-content {
                padding: 16px 20px;
                display: flex;
                align-items: center;
                gap: 12px;
            }
            
            .file-icon {
                font-size: 24px;
                flex-shrink: 0;
            }
            
            .file-info {
                flex: 1;
                min-width: 0;
            }
            
            .file-name {
                font-size: 14px;
                color: var(--text-primary);
                margin-bottom: 4px;
                overflow: hidden;
                text-overflow: ellipsis;
                white-space: nowrap;
            }
            
            .file-meta {
                display: flex;
                align-items: center;
                gap: 12px;
                font-size: 12px;
                color: var(--text-secondary);
            }
            
            .file-type {
                padding: 2px 8px;
                border-radius: 4px;
                font-weight: 500;
                text-transform: uppercase;
                font-size: 11px;
            }
            
            .file-type-anr {
                background: rgba(255, 152, 0, 0.15);
                color: var(--anr-color);
            }
            
            .file-type-tombstone {
                background: rgba(171, 71, 188, 0.2);
                color: var(--tombstone-color);
            }
            
            .source-link {
                position: absolute;
                right: 20px;
                top: 50%;
                transform: translateY(-50%);
                color: var(--text-secondary);
                padding: 8px;
                border-radius: 4px;
                transition: all 0.2s ease;
                opacity: 0;
            }
            
            .file-item:hover .source-link {
                opacity: 1;
            }
            
            .source-link:hover {
                color: var(--text-primary);
                background: var(--bg-hover);
            }
            
            /* Folder */
            .folder-item {
                border-bottom: 1px solid var(--border);
            }
            
            .folder-header {
                padding: 16px 20px;
                display: flex;
                align-items: center;
                gap: 12px;
                cursor: pointer;
                user-select: none;
                transition: background 0.2s ease;
            }
            
            .folder-header:hover {
                background: var(--bg-hover);
            }
            
            .folder-arrow {
                color: var(--text-secondary);
                transition: transform 0.2s ease;
                flex-shrink: 0;
            }
            
            .folder-arrow.open {
                transform: rotate(90deg);
            }
            
            .folder-icon {
                font-size: 20px;
                flex-shrink: 0;
            }
            
            .folder-name {
                font-size: 14px;
                color: var(--text-primary);
                flex: 1;
            }
            
            .folder-count {
                font-size: 12px;
                color: var(--text-muted);
                background: var(--bg-primary);
                padding: 2px 8px;
                border-radius: 12px;
            }
            
            .folder-content {
                background: rgba(0, 0, 0, 0.2);
            }
            
            .folder-content .file-item {
                margin-left: 32px;
            }
            
            /* Footer */
            .footer {
                text-align: center;
                padding: 40px 0;
                color: var(--text-secondary);
                font-size: 14px;
            }
            
            /* Responsive */
            @media (max-width: 768px) {
                .container {
                    padding: 16px;
                }
                
                .header {
                    padding: 40px 0 30px;
                }
                
                .header h1 {
                    font-size: 24px;
                }
                
                .stats {
                    grid-template-columns: repeat(2, 1fr);
                    gap: 12px;
                }
                
                .file-content {
                    padding: 14px 16px;
                }
                
                .source-link {
                    opacity: 1;
                    right: 16px;
                }
            }

            /* Controls */
            .controls {
                display: flex;
                gap: 12px;
                margin-bottom: 20px;
            }

            .control-btn {
                display: flex;
                align-items: center;
                gap: 6px;
                padding: 8px 16px;
                background: var(--bg-secondary);
                border: 1px solid var(--border);
                border-radius: var(--radius);
                color: var(--text-primary);
                font-size: 14px;
                cursor: pointer;
                transition: all 0.2s ease;
            }

            .control-btn:hover {
                background: var(--bg-hover);
                border-color: var(--accent);
            }

            .control-btn:active {
                transform: scale(0.98);
            }

            .control-btn svg {
                flex-shrink: 0;
            }

            .file-formats {
                display: inline-flex;
                gap: 8px;
            }

            .file-formats a {
                text-decoration: none;
                opacity: 0.7;
                transition: opacity 0.2s;
            }

            .file-formats a:hover {
                opacity: 1;
            }
        """
            
    def _generate_html_index(self, index_data: Dict, similarity_groups: List[Dict] = None) -> str:
        """ç”Ÿæˆ HTML ç´¢å¼•å…§å®¹ - Dark ChatGPT é¢¨æ ¼"""
        def render_tree(data, prefix=""):
            html_str = ""
            for name, value in sorted(data.items()):
                if isinstance(value, dict) and 'analyzed_file' in value:
                    # æª”æ¡ˆé …ç›®
                    # ç¾åœ¨ value['analyzed_file'] å’Œ value['original_file'] å·²ç¶“æ˜¯çµ•å°è·¯å¾‘
                    analyzed_path = value['analyzed_file']
                    original_path = value['original_file']
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰ HTML ç‰ˆæœ¬
                    is_html = analyzed_path.endswith('.html')
                    file_type = 'anr' if 'anr' in name.lower() else 'tombstone'
                    icon = 'âš ï¸' if file_type == 'anr' else 'ğŸ’¥'
                    
                    # ä½¿ç”¨æ–°çš„æŸ¥çœ‹å™¨ï¼Œå‚³éçµ•å°è·¯å¾‘
                    html_str += f'''
                    <div class="file-item {file_type}-item">
                        <a href="/view-analysis?path={html.escape(analyzed_path)}" class="file-link">
                            <div class="file-content">
                                <span class="file-icon">{icon}</span>
                                <div class="file-info">
                                    <div class="file-name">
                                        {html.escape(name)}
                                    </div>
                                    <div class="file-meta">
                                        <span class="file-type file-type-{file_type}">{file_type.upper()}</span>
                                        <span class="file-size">é»æ“ŠæŸ¥çœ‹åˆ†æ</span>
                                    </div>
                                </div>
                            </div>
                        </a>
                        <a href="/view-analysis?path={html.escape(original_path)}.analyzed.html" target="_blank" class="source-link" title="æŸ¥çœ‹åŸå§‹æª”æ¡ˆ">
                            <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                                <path d="M6.22 8.72a.75.75 0 001.06 1.06l5.22-5.22v1.69a.75.75 0 001.5 0v-3.5a.75.75 0 00-.75-.75h-3.5a.75.75 0 000 1.5h1.69L6.22 8.72z" fill="currentColor"/>
                                <path d="M3.5 6.75v7.5c0 .414.336.75.75.75h7.5a.75.75 0 00.75-.75v-7.5a.75.75 0 00-1.5 0v6.75h-6v-6.75a.75.75 0 00-1.5 0z" fill="currentColor"/>
                            </svg>
                        </a>
                    </div>
                    '''
                elif isinstance(value, dict):
                    # ç›®éŒ„é …ç›®ï¼ˆä¿æŒä¸è®Šï¼‰
                    folder_id = f"folder-{prefix}-{name}".replace('/', '-').replace(' ', '-')
                    file_count = _count_files(value)
                    html_str += f'''
                    <div class="folder-item">
                        <div class="folder-header" onclick="toggleFolder('{folder_id}')">
                            <svg class="folder-arrow" id="arrow-{folder_id}" width="16" height="16" viewBox="0 0 16 16">
                                <path d="M6 4l4 4-4 4" stroke="currentColor" stroke-width="1.5" fill="none"/>
                            </svg>
                            <span class="folder-icon">ğŸ“</span>
                            <span class="folder-name">{html.escape(name)}</span>
                            <span class="folder-count">{file_count}</span>
                        </div>
                        <div class="folder-content" id="{folder_id}">
                            {render_tree(value, prefix + '/' + name)}
                        </div>
                    </div>
                    '''
            return html_str

        def render_similarity_groups(groups):
            if not groups:
                return '<p>æ²’æœ‰ç™¼ç¾ç›¸ä¼¼å•é¡Œ</p>'
            
            html_str = ''
            for group in groups:
                html_str += f'''
                <div class="similarity-group" id="{group['group_id']}">
                    <div class="group-header" onclick="toggleGroup('{group['group_id']}')">
                        <svg class="group-arrow open" id="arrow-{group['group_id']}" width="16" height="16" viewBox="0 0 16 16">
                            <path d="M6 4l4 4-4 4" stroke="currentColor" stroke-width="1.5" fill="none"/>
                        </svg>
                        <span class="group-icon">ğŸ“‹</span>
                        <span class="group-title">{html.escape(group['title'])}</span>
                        <span class="group-info">
                            {group['count']} å€‹ç›¸ä¼¼æª”æ¡ˆ (ä¿¡å¿ƒåº¦: {group['similarity']:.0f}%)
                        </span>
                    </div>
                    <div class="group-content" id="content-{group['group_id']}" style="display: block;">
                '''
                
                # æ¸²æŸ“çµ„å…§çš„å ±å‘Š
                for report in group['reports']:
                    report_id = f"report_{group['group_id']}_{report['filename'].replace('.', '_')}"
                    escaped_filename = html.escape(report['filename'])
                    
                    # è®€å–æª”æ¡ˆå…§å®¹ä¸¦è½‰æ›ç‚º data URL
                    try:
                        # å¦‚æœå·²ç¶“æœ‰å…§å®¹ï¼Œç›´æ¥ä½¿ç”¨
                        if 'content' in report and report['content']:
                            report_content = report['content']
                        else:
                            # å¦å‰‡å¾æª”æ¡ˆè®€å–
                            with open(report['path'], 'r', encoding='utf-8') as f:
                                report_content = f.read()
                        
                        # Base64 ç·¨ç¢¼
                        import base64
                        encoded_content = base64.b64encode(report_content.encode('utf-8')).decode('utf-8')
                        iframe_src = f"data:text/html;charset=utf-8;base64,{encoded_content}"
                    except Exception as e:
                        print(f"ç„¡æ³•è®€å–æª”æ¡ˆ {report['path']}: {e}")
                        # é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                        error_html = f'<html><body><p style="color: red;">ç„¡æ³•è¼‰å…¥æª”æ¡ˆ: {escaped_filename}</p></body></html>'
                        encoded_error = base64.b64encode(error_html.encode('utf-8')).decode('utf-8')
                        iframe_src = f"data:text/html;charset=utf-8;base64,{encoded_error}"
                    
                    html_str += f'''
                    <div class="similarity-item">
                        <div class="report-header" onclick="toggleReport('{report_id}')">
                            <svg class="report-arrow open" id="arrow-{report_id}" width="16" height="16" viewBox="0 0 16 16">
                                <path d="M6 4l4 4-4 4" stroke="currentColor" stroke-width="1.5" fill="none"/>
                            </svg>
                            <span class="report-icon">ğŸ“„</span>
                            <span class="report-name">{escaped_filename}</span>
                        </div>
                        <div class="report-content" id="content-{report_id}" style="display: block;">
                            <iframe src="{iframe_src}" 
                                    class="report-iframe"
                                    style="width: 100%; min-height: 600px; border: 1px solid #ddd; background: white;"
                                    onload="adjustIframeHeight(this)">
                            </iframe>
                        </div>
                    </div>
                    '''
                
                html_str += '''
                    </div>
                </div>
                '''
            
            return html_str
                        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        def _count_files(data):
            count = 0
            for value in data.values():
                if isinstance(value, dict):
                    if 'analyzed_file' in value:
                        count += 1
                    else:
                        count += _count_files(value)
            return count
        
        # ä¸» HTML æ¨¡æ¿
        return f"""<!DOCTYPE html>
    <html lang="zh-TW">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Android Log åˆ†æå ±å‘Š</title>
        <style>
            /* ä¿ç•™åŸæœ‰çš„æ¨£å¼ */
            {self._get_original_styles()}
            
            /* æ–°å¢ç›¸ä¼¼å•é¡Œè¦–åœ–çš„æ¨£å¼ */
            .view-mode {{
                display: none;
            }}
            
            .view-mode.active {{
                display: block;
            }}
            
            .similarity-group {{
                background: var(--bg-secondary);
                border: 1px solid var(--border);
                border-radius: var(--radius);
                margin-bottom: 16px;
                overflow: hidden;
            }}
            
            .group-header {{
                padding: 16px 20px;
                display: flex;
                align-items: center;
                gap: 12px;
                cursor: pointer;
                user-select: none;
                transition: background 0.2s ease;
                background: rgba(255, 152, 0, 0.1);
            }}
            
            .group-header:hover {{
                background: rgba(255, 152, 0, 0.2);
            }}
            
            .group-arrow {{
                color: var(--text-secondary);
                transition: transform 0.2s ease;
                flex-shrink: 0;
            }}
            
            .group-arrow.open {{
                transform: rotate(90deg);
            }}
            
            .group-icon {{
                font-size: 20px;
                flex-shrink: 0;
            }}
            
            .group-title {{
                font-size: 16px;
                font-weight: 600;
                color: var(--text-primary);
                flex: 1;
            }}
            
            .group-info {{
                font-size: 13px;
                color: var(--text-secondary);
                background: var(--bg-primary);
                padding: 4px 12px;
                border-radius: 16px;
            }}
            
            .group-content {{
                background: rgba(0, 0, 0, 0.2);
            }}
            
            .similarity-item {{
                border-bottom: 1px solid var(--border);
            }}
            
            .similarity-item:last-child {{
                border-bottom: none;
            }}
            
            .report-header {{
                padding: 12px 20px 12px 40px;
                display: flex;
                align-items: center;
                gap: 8px;
                cursor: pointer;
                transition: background 0.2s ease;
            }}
            
            .report-header:hover {{
                background: var(--bg-hover);
            }}
            
            .report-arrow {{
                color: var(--text-secondary);
                transition: transform 0.2s ease;
                flex-shrink: 0;
            }}
            
            .report-arrow.open {{
                transform: rotate(90deg);
            }}
            
            .report-icon {{
                font-size: 16px;
            }}
            
            .report-name {{
                font-size: 14px;
                color: var(--text-primary);
            }}
            
            .report-content {{
                padding: 0;
                background: var(--bg-primary);
            }}
            
            .report-iframe {{
                width: 100%;
                height: 600px;
                border: none;
                display: block;
            }}
            
            .view-toggle {{
                display: flex;
                align-items: center;
                gap: 8px;
                padding: 8px 16px;
                background: var(--bg-secondary);
                border: 1px solid var(--border);
                border-radius: var(--radius);
                color: var(--text-primary);
                font-size: 14px;
                cursor: pointer;
                transition: all 0.2s ease;
            }}
            
            .view-toggle:hover {{
                background: var(--bg-hover);
                border-color: var(--accent);
            }}
            
            .view-toggle.active {{
                background: var(--accent);
                color: white;
                border-color: var(--accent);
            }}

            .iframe-error {{
                padding: 40px;
                text-align: center;
                color: var(--text-secondary);
                background: rgba(255, 0, 0, 0.1);
                border-radius: var(--radius);
                margin: 20px;
            }}

            .iframe-error p {{
                margin: 10px 0;
            }}

            .report-iframe {{
                width: 100%;
                min-height: 600px;
                max-height: 1000px;
                border: none;
                display: block;
                background: var(--bg-primary);
            }}

        </style>
    </head>
    <body>
        <div class="container">
            <header class="header">
                <h1>Android Log åˆ†æå ±å‘Š</h1>
                <p class="subtitle">æ™ºèƒ½åˆ†æç³»çµ± â€¢ æ·±åº¦è§£æ ANR å’Œ Tombstone å•é¡Œ</p>
            </header>
            
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-value">{self.stats['anr_count']}</div>
                    <div class="stat-label">ANR æª”æ¡ˆ</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{self.stats['tombstone_count']}</div>
                    <div class="stat-label">Tombstone æª”æ¡ˆ</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{self.stats['anr_count'] + self.stats['tombstone_count']}</div>
                    <div class="stat-label">ç¸½æª”æ¡ˆæ•¸</div>
                </div>
                <div class="stat-card">
                    <div class="stat-value">{self.stats['total_time']:.1f}s</div>
                    <div class="stat-label">åˆ†ææ™‚é–“</div>
                </div>
            </div>
            
            <div class="controls">
                <button onclick="expandAll()" class="control-btn">
                    <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                        <path d="M3 6l5 5 5-5" stroke="currentColor" stroke-width="1.5"/>
                    </svg>
                    å…¨éƒ¨å±•é–‹
                </button>
                <button onclick="collapseAll()" class="control-btn">
                    <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                        <path d="M3 10l5-5 5 5" stroke="currentColor" stroke-width="1.5"/>
                    </svg>
                    å…¨éƒ¨æ”¶åˆ
                </button>
                <button onclick="toggleView('similarity')" class="view-toggle" id="similarityBtn">
                    <svg width="16" height="16" viewBox="0 0 16 16" fill="none">
                        <path d="M8 2v6m0 0l3-3m-3 3L5 5m7 6v2a1 1 0 01-1 1H5a1 1 0 01-1-1v-2" stroke="currentColor" stroke-width="1.5"/>
                    </svg>
                    ç›¸ä¼¼å•é¡Œ
                </button>
            </div>
            
            <!-- æª”æ¡ˆç€è¦½è¦–åœ– -->
            <main class="file-browser view-mode active" id="fileView">
                {render_tree(index_data)}
            </main>
            
            <!-- ç›¸ä¼¼å•é¡Œè¦–åœ– -->
            <main class="similarity-view view-mode" id="similarityView">
                {render_similarity_groups(similarity_groups)}
            </main>
            
            <footer class="footer">
                <p>ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')} â€¢ Android Log Analyzer v5</p>
            </footer>
        </div>
        
        <script>
            let currentView = 'file';
            
            function toggleView(view) {{
                const fileView = document.getElementById('fileView');
                const similarityView = document.getElementById('similarityView');
                const similarityBtn = document.getElementById('similarityBtn');
                
                if (view === 'similarity') {{
                    if (currentView === 'similarity') {{
                        // åˆ‡æ›å›æª”æ¡ˆè¦–åœ–
                        fileView.classList.add('active');
                        similarityView.classList.remove('active');
                        similarityBtn.classList.remove('active');
                        currentView = 'file';
                    }} else {{
                        // åˆ‡æ›åˆ°ç›¸ä¼¼å•é¡Œè¦–åœ–
                        fileView.classList.remove('active');
                        similarityView.classList.add('active');
                        similarityBtn.classList.add('active');
                        currentView = 'similarity';
                    }}
                }}
            }}
            
            function toggleFolder(folderId) {{
                const folder = document.getElementById(folderId);
                const arrow = document.getElementById('arrow-' + folderId);
                
                if (folder.style.display === 'none' || folder.style.display === '') {{
                    folder.style.display = 'block';
                    arrow.classList.add('open');
                }} else {{
                    folder.style.display = 'none';
                    arrow.classList.remove('open');
                }}
            }}
            
            function toggleGroup(groupId) {{
                const content = document.getElementById('content-' + groupId);
                const arrow = document.getElementById('arrow-' + groupId);
                
                if (content.style.display === 'none') {{
                    content.style.display = 'block';
                    arrow.classList.add('open');
                }} else {{
                    content.style.display = 'none';
                    arrow.classList.remove('open');
                }}
            }}
            
            function toggleReport(reportId) {{
                const content = document.getElementById('content-' + reportId);
                const arrow = document.getElementById('arrow-' + reportId);
                
                if (content.style.display === 'none') {{
                    content.style.display = 'block';
                    arrow.classList.add('open');
                }} else {{
                    content.style.display = 'none';
                    arrow.classList.remove('open');
                }}
            }}
            
            function expandAll() {{
                if (currentView === 'file') {{
                    // æª”æ¡ˆè¦–åœ–çš„å±•é–‹
                    const folders = document.querySelectorAll('.folder-content');
                    const arrows = document.querySelectorAll('.folder-arrow');
                    
                    folders.forEach(folder => {{
                        folder.style.display = 'block';
                    }});
                    
                    arrows.forEach(arrow => {{
                        arrow.classList.add('open');
                    }});
                }} else {{
                    // ç›¸ä¼¼å•é¡Œè¦–åœ–çš„å±•é–‹
                    const groupContents = document.querySelectorAll('.group-content');
                    const groupArrows = document.querySelectorAll('.group-arrow');
                    const reportContents = document.querySelectorAll('.report-content');
                    const reportArrows = document.querySelectorAll('.report-arrow');
                    
                    groupContents.forEach(content => {{
                        content.style.display = 'block';
                    }});
                    
                    groupArrows.forEach(arrow => {{
                        arrow.classList.add('open');
                    }});
                    
                    reportContents.forEach(content => {{
                        content.style.display = 'block';
                    }});
                    
                    reportArrows.forEach(arrow => {{
                        arrow.classList.add('open');
                    }});
                }}
            }}
            
            function collapseAll() {{
                if (currentView === 'file') {{
                    // æª”æ¡ˆè¦–åœ–çš„æ”¶åˆ
                    const folders = document.querySelectorAll('.folder-content');
                    const arrows = document.querySelectorAll('.folder-arrow');
                    
                    folders.forEach(folder => {{
                        folder.style.display = 'none';
                    }});
                    
                    arrows.forEach(arrow => {{
                        arrow.classList.remove('open');
                    }});
                }} else {{
                    // ç›¸ä¼¼å•é¡Œè¦–åœ–çš„æ”¶åˆ
                    const groupContents = document.querySelectorAll('.group-content');
                    const groupArrows = document.querySelectorAll('.group-arrow');
                    const reportContents = document.querySelectorAll('.report-content');
                    const reportArrows = document.querySelectorAll('.report-arrow');
                    
                    groupContents.forEach(content => {{
                        content.style.display = 'none';
                    }});
                    
                    groupArrows.forEach(arrow => {{
                        arrow.classList.remove('open');
                    }});
                    
                    reportContents.forEach(content => {{
                        content.style.display = 'none';
                    }});
                    
                    reportArrows.forEach(arrow => {{
                        arrow.classList.remove('open');
                    }});
                }}
            }}
            
            function adjustIframeHeight(iframe) {{
                try {{
                    // å˜—è©¦è‡ªå‹•èª¿æ•´ iframe é«˜åº¦
                    const iframeDoc = iframe.contentDocument || iframe.contentWindow.document;
                    const height = Math.max(
                        iframeDoc.body.scrollHeight,
                        iframeDoc.documentElement.scrollHeight
                    );
                    iframe.style.height = Math.min(height + 20, 800) + 'px';
                }} catch (e) {{
                    // è·¨åŸŸé™åˆ¶ï¼Œä½¿ç”¨å›ºå®šé«˜åº¦
                    iframe.style.height = '600px';
                }}
            }}

            function handleIframeError(iframe, filename, path) {{
                console.error('Failed to load iframe:', filename, 'Path:', path);
                iframe.style.display = 'none';
                const errorDiv = document.createElement('div');
                errorDiv.className = 'iframe-error';
                errorDiv.innerHTML = '<p>ç„¡æ³•è¼‰å…¥åˆ†æå ±å‘Š: ' + filename + '</p>' +
                                    '<p>å˜—è©¦è·¯å¾‘: ' + path + '</p>' +
                                    '<p>è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨</p>';
                errorDiv.style.padding = '20px';
                errorDiv.style.textAlign = 'center';
                errorDiv.style.color = '#999';
                errorDiv.style.backgroundColor = 'rgba(255,0,0,0.1)';
                errorDiv.style.borderRadius = '8px';
                errorDiv.style.margin = '20px';
                iframe.parentNode.appendChild(errorDiv);
            }}

            function adjustIframeHeight(iframe) {{
                try {{
                    // é‡ç½®é«˜åº¦ä»¥ç²å¾—æ­£ç¢ºçš„å…§å®¹é«˜åº¦
                    iframe.style.height = '100px';
                    
                    // ç­‰å¾…å…§å®¹è¼‰å…¥
                    setTimeout(() => {{
                        try {{
                            const iframeDoc = iframe.contentDocument || iframe.contentWindow.document;
                            const height = Math.max(
                                iframeDoc.body.scrollHeight,
                                iframeDoc.documentElement.scrollHeight,
                                600 // æœ€å°é«˜åº¦
                            );
                            iframe.style.height = Math.min(height + 50, 1000) + 'px';
                        }} catch (e) {{
                            // è·¨åŸŸæˆ–å…¶ä»–éŒ¯èª¤ï¼Œä½¿ç”¨é è¨­é«˜åº¦
                            iframe.style.height = '700px';
                        }}
                    }}, 100);
                }} catch (e) {{
                    iframe.style.height = '700px';
                }}
            }}

            // é è¨­å±•é–‹æª”æ¡ˆè¦–åœ–
            document.addEventListener('DOMContentLoaded', function() {{
                expandAll();
            }});
        </script>
    </body>
    </html>"""

    def _show_statistics(self):
        """é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š"""
        print("\n" + "=" * 60)
        print("âœ… åˆ†æå®Œæˆï¼")
        print("=" * 60)
        
        # çµ±è¨ˆå¯¦éš›ç”Ÿæˆçš„ HTML æª”æ¡ˆ
        anr_html_count = 0
        tombstone_html_count = 0
        
        for root, dirs, files in os.walk(self.output_folder):
            for file in files:
                if file.endswith('.analyzed.html'):
                    # æ ¹æ“šè·¯å¾‘åˆ¤æ–·æ˜¯ ANR é‚„æ˜¯ Tombstone
                    rel_path = os.path.relpath(root, self.output_folder).lower()
                    if 'anr' in rel_path:
                        anr_html_count += 1
                    elif 'tombstone' in rel_path:
                        tombstone_html_count += 1
        
        print(f"\nğŸ“Š åˆ†æçµ±è¨ˆ:")
        print(f"  â€¢ ANR HTML å ±å‘Š: {anr_html_count} å€‹")
        print(f"  â€¢ Tombstone HTML å ±å‘Š: {tombstone_html_count} å€‹")
        print(f"  â€¢ ç¸½ HTML å ±å‘Š: {anr_html_count + tombstone_html_count} å€‹")
        print(f"  â€¢ éŒ¯èª¤æ•¸é‡: {self.stats['error_count']} å€‹")
        print(f"  â€¢ ç¸½åŸ·è¡Œæ™‚é–“: {self.stats['total_time']:.2f} ç§’")
        
        total_html = anr_html_count + tombstone_html_count
        if total_html > 0:
            avg_time = self.stats['total_time'] / total_html
            print(f"  â€¢ å¹³å‡è™•ç†æ™‚é–“: {avg_time:.3f} ç§’/æª”æ¡ˆ")
        
        print(f"\nğŸ¯ è¼¸å‡ºç›®éŒ„: {self.output_folder}")
        print(f"ğŸŒ è«‹é–‹å•Ÿ {os.path.join(self.output_folder, 'index.html')} æŸ¥çœ‹åˆ†æå ±å‘Š")

# ============= æ™ºèƒ½åˆ†æå¼•æ“ =============
class IntelligentAnalysisEngine:
    """æ™ºèƒ½åˆ†æå¼•æ“ - æ•´åˆæ‰€æœ‰åˆ†æåŠŸèƒ½"""
    
    def __init__(self):
        self.analysis_patterns = self._init_analysis_patterns()
        self.known_issues_db = self._init_known_issues()
        
        # å»¶é²åˆå§‹åŒ–åˆ†æå™¨ï¼Œé¿å…å¾ªç’°å¼•ç”¨
        self._analyzers_initialized = False
        self._init_analyzers_lazy()
            
    def _get_health_recommendation(self, score: int) -> str:
        """æ ¹æ“šå¥åº·åˆ†æ•¸æä¾›å»ºè­°"""
        if score >= 80:
            return "ç³»çµ±é‹è¡Œæ­£å¸¸ï¼Œç¹¼çºŒä¿æŒ"
        elif score >= 60:
            return "ç³»çµ±æœ‰è¼•å¾®å£“åŠ›ï¼Œå»ºè­°å„ªåŒ–è¨˜æ†¶é«”ä½¿ç”¨"
        elif score >= 40:
            return "ç³»çµ±å£“åŠ›è¼ƒå¤§ï¼Œéœ€è¦ç«‹å³å„ªåŒ–"
        else:
            return "ç³»çµ±åš´é‡ç•°å¸¸ï¼Œéœ€è¦ç·Šæ€¥è™•ç†"
            
    def _init_analysis_patterns(self) -> Dict:
        """åˆå§‹åŒ–åˆ†ææ¨¡å¼åº«"""
        return {
            'binder_deadlock_patterns': {
                'windowmanager_timeout': {
                    'signatures': [
                        'BinderProxy.transactNative',
                        'WindowManager.*getWindowInsets',
                        'system_server.*block'
                    ],
                    'root_cause': 'WindowManager æœå‹™é˜»å¡',
                    'severity': 'critical',
                    'solutions': [
                        'æª¢æŸ¥ system_server è² è¼‰å’Œ GC ç‹€æ³',
                        'åˆ†æ WindowManager æœå‹™æ˜¯å¦æœ‰æ­»é–',
                        'æŸ¥çœ‹åŒæ™‚é–“çš„å…¶ä»– Binder èª¿ç”¨'
                    ]
                },
                'webview_anr': {
                    'signatures': [
                        'chromium.*WebView',
                        'onDisplayChanged',
                        'WindowMetricsController'
                    ],
                    'root_cause': 'WebView æ¸²æŸ“å¼•æ“é˜»å¡',
                    'severity': 'high',
                    'solutions': [
                        'æª¢æŸ¥ WebView ç‰ˆæœ¬å’Œç›¸å®¹æ€§',
                        'åˆ†æ WebView æ¸²æŸ“ç·šç¨‹ç‹€æ…‹',
                        'è€ƒæ…®å»¶é²æˆ–ç•°æ­¥è¼‰å…¥ WebView'
                    ]
                }
            },
            'system_service_patterns': {
                'input_timeout': {
                    'signatures': [
                        'Input dispatching timed out',
                        'Waited.*ms for',
                        'FocusEvent.*hasFocus'
                    ],
                    'root_cause': 'Input äº‹ä»¶åˆ†ç™¼è¶…æ™‚',
                    'severity': 'critical',
                    'solutions': [
                        'æª¢æŸ¥ä¸»ç·šç¨‹æ˜¯å¦æœ‰è€—æ™‚æ“ä½œ',
                        'åˆ†æ InputDispatcher ç‹€æ…‹',
                        'æŸ¥çœ‹æ˜¯å¦æœ‰ Window focus åˆ‡æ›å•é¡Œ'
                    ]
                }
            },
            'tombstone_crash_patterns': {
                'null_pointer': {
                    'signatures': ['fault addr 0x0', 'signal 11', 'SIGSEGV'],
                    'root_cause': 'ç©ºæŒ‡é‡è§£å¼•ç”¨',
                    'severity': 'high',
                    'solutions': [
                        'æª¢æŸ¥æŒ‡é‡åˆå§‹åŒ–',
                        'æ·»åŠ ç©ºæŒ‡é‡æª¢æŸ¥',
                        'ä½¿ç”¨æ™ºèƒ½æŒ‡é‡'
                    ]
                },
                'memory_corruption': {
                    'signatures': ['malloc', 'free', 'heap corruption'],
                    'root_cause': 'è¨˜æ†¶é«”æå£',
                    'severity': 'critical',
                    'solutions': [
                        'ä½¿ç”¨ AddressSanitizer',
                        'æª¢æŸ¥ç·©è¡å€æº¢å‡º',
                        'é¿å… use-after-free'
                    ]
                }
            }
        }
    
    def _init_known_issues(self) -> Dict:
        """åˆå§‹åŒ–å·²çŸ¥å•é¡Œè³‡æ–™åº«"""
        return {
            # é€šç”¨çš„å·²çŸ¥å•é¡Œæ¨¡å¼ï¼Œè€Œéç‰¹å®šè¨­å‚™
            'webview_display_change_anr': {
                'patterns': [
                    'WebView.*onDisplayChanged',
                    'WindowManager.*getWindowInsets',
                    'chromium.*TrichroneWebView'
                ],
                'description': 'WebView åœ¨é¡¯ç¤ºé…ç½®è®Šæ›´æ™‚çš„ ANR',
                'affected_versions': ['Android 10+', 'WebView 83+'],
                'workarounds': [
                    'å»¶é² WebView åˆå§‹åŒ–',
                    'ä½¿ç”¨ç•°æ­¥è¼‰å…¥',
                    'é¿å…åœ¨ onDisplayChanged ä¸­é€²è¡ŒåŒæ­¥æ“ä½œ'
                ]
            },
            'system_server_overload': {
                'patterns': [
                    'system_server.*block',
                    'InputDispatcher.*timed out',
                    'Waited.*ms for.*system_server'
                ],
                'description': 'system_server éè¼‰å°è‡´çš„ ANR',
                'affected_versions': ['æ‰€æœ‰ Android ç‰ˆæœ¬'],
                'workarounds': [
                    'æ¸›å°‘åŒæ™‚é€²è¡Œçš„ç³»çµ±æœå‹™èª¿ç”¨',
                    'ä½¿ç”¨æ‰¹é‡æ“ä½œ',
                    'å¯¦æ–½é‡è©¦æ©Ÿåˆ¶'
                ]
            },
            'binder_transaction_limit': {
                'patterns': [
                    'TransactionTooLargeException',
                    'Binder transaction.*too large',
                    'data parcel size.*bytes'
                ],
                'description': 'Binder äº‹å‹™å¤§å°è¶…é™',
                'affected_versions': ['æ‰€æœ‰ Android ç‰ˆæœ¬'],
                'workarounds': [
                    'æ¸›å°‘å–®æ¬¡å‚³è¼¸çš„æ•¸æ“šé‡',
                    'åˆ†æ‰¹å‚³è¼¸å¤§æ•¸æ“š',
                    'ä½¿ç”¨ ContentProvider æˆ–æ–‡ä»¶å‚³è¼¸'
                ]
            }
        }
    
    def _init_analyzers_lazy(self):
        """å»¶é²åˆå§‹åŒ–åˆ†æå™¨"""
        if self._analyzers_initialized:
            return
            
        try:
            # å»¶é²å°å…¥
            from vp_analyze_logs_ext import (
                BinderCallChainAnalyzer, ThreadDependencyAnalyzer,
                PerformanceBottleneckDetector, TimelineAnalyzer,
                CrossProcessAnalyzer, MLAnomalyDetector, RootCausePredictor,
                RiskAssessmentEngine, TrendAnalyzer, SystemMetricsIntegrator,
                SourceCodeAnalyzer, CodeFixGenerator, ConfigurationOptimizer,
                ComparativeAnalyzer, ParallelAnalyzer, IncrementalAnalyzer,
                VisualizationGenerator, ExecutiveSummaryGenerator
            )
            
            # åˆå§‹åŒ–æ‰€æœ‰åˆ†æå™¨
            self.binder_analyzer = BinderCallChainAnalyzer()
            self.dependency_analyzer = ThreadDependencyAnalyzer()
            self.bottleneck_detector = PerformanceBottleneckDetector()
            self.timeline_analyzer = TimelineAnalyzer()
            self.cross_process_analyzer = CrossProcessAnalyzer()
            self.anomaly_detector = MLAnomalyDetector()
            self.root_cause_predictor = RootCausePredictor()
            self.risk_engine = RiskAssessmentEngine()
            self.trend_analyzer = TrendAnalyzer()
            self.system_metrics_integrator = SystemMetricsIntegrator()
            self.source_analyzer = SourceCodeAnalyzer()
            self.fix_generator = CodeFixGenerator()
            self.config_optimizer = ConfigurationOptimizer()
            self.comparative_analyzer = ComparativeAnalyzer()
            self.parallel_analyzer = ParallelAnalyzer()
            self.incremental_analyzer = IncrementalAnalyzer()
            self.viz_generator = VisualizationGenerator()
            self.summary_generator = ExecutiveSummaryGenerator()
            
            self._analyzers_initialized = True
        except Exception as e:
            print(f"è­¦å‘Š: ç„¡æ³•åˆå§‹åŒ–æ‰€æœ‰åˆ†æå™¨ - {e}")
            # è¨­ç½®ç©ºçš„åˆ†æå™¨ä»¥é¿å…éŒ¯èª¤
            self.binder_analyzer = None
            self.dependency_analyzer = None
            self.bottleneck_detector = None
            self.timeline_analyzer = None
            self.cross_process_analyzer = None
            self.anomaly_detector = None
            self.root_cause_predictor = None
            self.risk_engine = None
            self.trend_analyzer = None
            self.system_metrics_integrator = None
            self.source_analyzer = None
            self.fix_generator = None
            self.config_optimizer = None
            self.comparative_analyzer = None
            self.parallel_analyzer = None
            self.incremental_analyzer = None
            self.viz_generator = None
            self.summary_generator = None
    
    def analyze_call_chain(self, backtrace: List[str]) -> Dict:
        """åˆ†æèª¿ç”¨éˆï¼Œæ‰¾å‡ºå•é¡Œçš„å®Œæ•´è„ˆçµ¡"""
        analysis = {
            'call_flow': [],
            'blocking_points': [],
            'service_interactions': [],
            'potential_causes': []
        }
        
        # å»ºç«‹èª¿ç”¨æµç¨‹åœ–
        for i, frame in enumerate(backtrace):
            # æå–é—œéµè³‡è¨Š
            if 'BinderProxy' in frame:
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'IPC',
                    'detail': 'Binder IPC èª¿ç”¨',
                    'target': self._extract_binder_target(frame, backtrace[i:i+3])
                })
            elif 'WindowManager' in frame:
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'System Service',
                    'detail': 'WindowManager æœå‹™èª¿ç”¨',
                    'method': self._extract_method_name(frame)
                })
            elif 'WebView' in frame or 'chromium' in frame.lower():
                analysis['call_flow'].append({
                    'level': i,
                    'type': 'WebView',
                    'detail': 'WebView å…ƒä»¶',
                    'action': self._extract_webview_action(frame)
                })
        
        # è­˜åˆ¥é˜»å¡é»
        analysis['blocking_points'] = self._identify_blocking_points(backtrace)
        
        # åˆ†ææœå‹™äº¤äº’
        analysis['service_interactions'] = self._analyze_service_interactions(backtrace)
        
        return analysis
    
    def _extract_binder_target(self, frame: str, context_frames: List[str]) -> str:
        """æå– Binder èª¿ç”¨çš„ç›®æ¨™æœå‹™"""
        # å¾å¾ŒçºŒå¹€ä¸­æ‰¾å‡ºç›®æ¨™æœå‹™
        for ctx_frame in context_frames[1:]:
            if 'WindowManager' in ctx_frame:
                return 'WindowManagerService'
            elif 'ActivityManager' in ctx_frame:
                return 'ActivityManagerService'
            elif 'PackageManager' in ctx_frame:
                return 'PackageManagerService'
        return 'Unknown Service'
    
    def _extract_method_name(self, frame: str) -> str:
        """æå–æ–¹æ³•åç¨±"""
        match = re.search(r'\.(\w+)\(', frame)
        return match.group(1) if match else 'Unknown'
    
    def _extract_webview_action(self, frame: str) -> str:
        """æå– WebView ç›¸é—œå‹•ä½œ"""
        if 'onDisplayChanged' in frame:
            return 'é¡¯ç¤ºé…ç½®è®Šæ›´'
        elif 'loadUrl' in frame:
            return 'è¼‰å…¥ URL'
        elif 'onDraw' in frame:
            return 'æ¸²æŸ“ç¹ªè£½'
        return 'å…¶ä»–æ“ä½œ'
    
    def _identify_blocking_points(self, backtrace: List[str]) -> List[Dict]:
        """è­˜åˆ¥é˜»å¡é»"""
        blocking_points = []
        
        for i, frame in enumerate(backtrace[:10]):
            if 'Native method' in frame or 'transactNative' in frame:
                blocking_points.append({
                    'level': i,
                    'type': 'Native é˜»å¡',
                    'description': 'åœ¨ Native å±¤ç­‰å¾…',
                    'severity': 'high'
                })
            elif 'wait' in frame.lower() or 'park' in frame.lower():
                blocking_points.append({
                    'level': i,
                    'type': 'ç·šç¨‹ç­‰å¾…',
                    'description': 'ç·šç¨‹è¢«æ›èµ·ç­‰å¾…',
                    'severity': 'medium'
                })
        
        return blocking_points
    
    def _analyze_service_interactions(self, backtrace: List[str]) -> List[Dict]:
        """åˆ†ææœå‹™äº¤äº’"""
        interactions = []
        
        # åˆ†æ Binder èª¿ç”¨éˆ
        service_chain = []
        for frame in backtrace:
            if 'Service' in frame or 'Manager' in frame:
                service = re.search(r'(\w+(?:Service|Manager))', frame)
                if service and service.group(1) not in service_chain:
                    service_chain.append(service.group(1))
        
        # å»ºç«‹äº¤äº’é—œä¿‚
        for i in range(len(service_chain) - 1):
            interactions.append({
                'from': service_chain[i],
                'to': service_chain[i + 1],
                'type': 'Binder IPC'
            })
        
        return interactions
    
    def match_known_patterns(self, anr_info: ANRInfo) -> List[Dict]:
        """åŒ¹é…å·²çŸ¥å•é¡Œæ¨¡å¼"""
        matches = []
        
        if not anr_info.main_thread:
            return matches
        
        # å°‡å †ç–Šè½‰ç‚ºå­—ä¸²ä¾¿æ–¼åŒ¹é…
        stack_str = '\n'.join(anr_info.main_thread.backtrace)
        
        # æª¢æŸ¥åˆ†ææ¨¡å¼
        for category, patterns in self.analysis_patterns.items():
            for pattern_name, pattern_info in patterns.items():
                match_count = sum(1 for sig in pattern_info['signatures']
                                if re.search(sig, stack_str, re.IGNORECASE))
                
                if match_count > 0:
                    confidence = match_count / len(pattern_info['signatures'])
                    matches.append({
                        'pattern': pattern_name,
                        'confidence': confidence,
                        'root_cause': pattern_info['root_cause'],
                        'severity': pattern_info['severity'],
                        'solutions': pattern_info['solutions']
                    })
        
        # æª¢æŸ¥å·²çŸ¥å•é¡Œ
        for issue_name, issue_info in self.known_issues_db.items():
            if 'patterns' in issue_info:
                match_count = sum(1 for pattern in issue_info['patterns']
                                if re.search(pattern, stack_str, re.IGNORECASE))
                
                if match_count > 0:
                    confidence = match_count / len(issue_info['patterns'])
                    matches.append({
                        'pattern': issue_name,
                        'confidence': confidence,
                        'description': issue_info.get('description', ''),
                        'workarounds': issue_info.get('workarounds', [])
                    })
        
        return sorted(matches, key=lambda x: x['confidence'], reverse=True)

    def analyze_crash_pattern(self, tombstone_info: TombstoneInfo) -> Dict:
        """åˆ†æå´©æ½°æ¨¡å¼ - å°ˆé–€ç‚º Tombstone"""
        analysis = {
            'crash_flow': [],
            'memory_context': {},
            'crash_signature': '',
            'similar_crashes': []
        }
        
        # åˆ†æå´©æ½°æµç¨‹
        if tombstone_info.crash_backtrace:
            for i, frame in enumerate(tombstone_info.crash_backtrace[:10]):
                frame_analysis = {
                    'level': i,
                    'pc': frame.get('pc', 'Unknown'),
                    'location': frame.get('location', 'Unknown'),
                    'symbol': frame.get('symbol'),
                    'analysis': self._analyze_crash_frame(frame)
                }
                analysis['crash_flow'].append(frame_analysis)
        
        # åˆ†æè¨˜æ†¶é«”ä¸Šä¸‹æ–‡
        if tombstone_info.fault_addr:
            analysis['memory_context'] = self._analyze_memory_context(
                tombstone_info.fault_addr,
                tombstone_info.memory_map
            )
        
        # ç”Ÿæˆå´©æ½°ç°½åï¼ˆç”¨æ–¼ç›¸ä¼¼å´©æ½°åŒ¹é…ï¼‰
        analysis['crash_signature'] = self._generate_crash_signature(tombstone_info)
        
        return analysis

    def _analyze_crash_frame(self, frame: Dict) -> str:
        """åˆ†æå´©æ½°å¹€"""
        location = frame.get('location', '')
        symbol = frame.get('symbol', '')
        
        if 'libc.so' in location:
            if 'malloc' in symbol or 'free' in symbol:
                return 'è¨˜æ†¶é«”ç®¡ç†æ“ä½œ'
            elif 'strlen' in symbol or 'strcpy' in symbol:
                return 'å­—ä¸²æ“ä½œ'
            else:
                return 'ç³»çµ± C åº«èª¿ç”¨'
        elif 'libandroid_runtime.so' in location:
            return 'Android Runtime å±¤'
        elif 'art::' in symbol:
            return 'ART è™›æ“¬æ©Ÿ'
        elif '.so' in location and 'vendor' in location:
            return 'å» å•†åº«'
        elif '.apk' in location or '.dex' in location:
            return 'æ‡‰ç”¨å±¤ä»£ç¢¼'
        
        return 'æœªçŸ¥'

    def _analyze_memory_context(self, fault_addr: str, memory_map: List[str]) -> Dict:
        """åˆ†æè¨˜æ†¶é«”ä¸Šä¸‹æ–‡"""
        context = {
            'fault_location': None,
            'nearby_regions': [],
            'analysis': None
        }
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡æ•ˆåœ°å€
        if fault_addr.lower() in ['unknown', 'n/a', 'none', '']:
            context['analysis'] = 'ç„¡æ³•ç¢ºå®šæ•…éšœåœ°å€'
            return context
        
        try:
            fault_int = int(fault_addr, 16)
            
            # ç‰¹æ®Šåœ°å€åˆ†æ
            if fault_int == 0:
                context['analysis'] = 'ç©ºæŒ‡é‡è¨ªå•'
            elif fault_int < 0x1000:
                context['analysis'] = 'ä½åœ°å€è¨ªå•ï¼Œå¯èƒ½æ˜¯ç©ºæŒ‡é‡åŠ åç§»'
            elif fault_int == 0xdeadbaad:
                context['analysis'] = 'Android libc abort æ¨™è¨˜'
            elif fault_int == 0xdeadbeef:
                context['analysis'] = 'èª¿è©¦æ¨™è¨˜åœ°å€'
            
            # æŸ¥æ‰¾æ‰€åœ¨è¨˜æ†¶é«”å€åŸŸ
            for mem_line in memory_map[:50]:
                if '-' in mem_line:
                    parts = mem_line.split()
                    if parts:
                        addr_range = parts[0]
                        if '-' in addr_range:
                            start_str, end_str = addr_range.split('-')
                            try:
                                start = int(start_str, 16)
                                end = int(end_str, 16)
                                
                                if start <= fault_int <= end:
                                    context['fault_location'] = mem_line
                                    context['analysis'] = self._analyze_memory_region(parts)
                                elif abs(fault_int - start) < 0x1000 or abs(fault_int - end) < 0x1000:
                                    context['nearby_regions'].append(mem_line)
                            except:
                                pass
        except:
            pass
        
        return context

    def _analyze_memory_region(self, parts: List[str]) -> str:
        """åˆ†æè¨˜æ†¶é«”å€åŸŸé¡å‹"""
        if len(parts) > 6:
            region_name = parts[6]
            if '[stack]' in region_name:
                return 'å †ç–Šå€åŸŸ - å¯èƒ½æ˜¯å †ç–Šæº¢å‡º'
            elif '[heap]' in region_name:
                return 'å †å€åŸŸ - å¯èƒ½æ˜¯å †æå£'
            elif '.so' in region_name:
                return f'å…±äº«åº«å€åŸŸ: {region_name}'
            elif '.apk' in region_name:
                return 'APK ä»£ç¢¼å€åŸŸ'
        
        permissions = parts[1] if len(parts) > 1 else ''
        if 'r-x' in permissions:
            return 'ä»£ç¢¼æ®µ'
        elif 'rw-' in permissions:
            return 'æ•¸æ“šæ®µ'
        
        return 'æœªçŸ¥å€åŸŸ'

    def _generate_crash_signature(self, tombstone_info: TombstoneInfo) -> str:
        """ç”Ÿæˆå´©æ½°ç°½åç”¨æ–¼ç›¸ä¼¼å´©æ½°åŒ¹é…"""
        signature_parts = []
        
        # ä¿¡è™Ÿé¡å‹
        signature_parts.append(f"sig_{tombstone_info.signal.name}")
        
        # æ•…éšœåœ°å€ç‰¹å¾µ
        if tombstone_info.fault_addr in ['0x0', '0']:
            signature_parts.append("null_ptr")
        elif tombstone_info.fault_addr.startswith('0xdead'):
            signature_parts.append("debug_marker")
        
        # é ‚å±¤å †ç–Šç‰¹å¾µ
        if tombstone_info.crash_backtrace:
            for frame in tombstone_info.crash_backtrace[:3]:
                if frame.get('symbol'):
                    # æå–å‡½æ•¸å
                    func_name = frame['symbol'].split('(')[0].split()[-1]
                    signature_parts.append(func_name)
        
        return "_".join(signature_parts[:5])  # é™åˆ¶é•·åº¦

    def match_tombstone_patterns(self, tombstone_info: TombstoneInfo) -> List[Dict]:
        """åŒ¹é… Tombstone å·²çŸ¥æ¨¡å¼"""
        matches = []
        
        # æº–å‚™åŒ¹é…æ•¸æ“š
        crash_str = f"{tombstone_info.signal.name} {tombstone_info.fault_addr}"
        if tombstone_info.crash_backtrace:
            for frame in tombstone_info.crash_backtrace[:5]:
                crash_str += f" {frame.get('location', '')} {frame.get('symbol', '')}"
        
        # æª¢æŸ¥å´©æ½°æ¨¡å¼
        for pattern_name, pattern_info in self.analysis_patterns.get('tombstone_crash_patterns', {}).items():
            match_count = sum(1 for sig in pattern_info['signatures'] 
                            if sig.lower() in crash_str.lower())
            
            if match_count > 0:
                confidence = match_count / len(pattern_info['signatures'])
                if confidence >= 0.5:  # 50% åŒ¹é…åº¦
                    matches.append({
                        'pattern': pattern_name,
                        'confidence': confidence,
                        'root_cause': pattern_info['root_cause'],
                        'severity': pattern_info['severity'],
                        'solutions': pattern_info['solutions']
                    })
        
        return sorted(matches, key=lambda x: x['confidence'], reverse=True)

    def _detect_complex_deadlock(self, all_threads: List[ThreadInfo]) -> Dict:
        """è¤‡é›œæ­»é–æª¢æ¸¬ - åŒ…æ‹¬è·¨é€²ç¨‹æ­»é–"""
        deadlock_info = {
            'has_deadlock': False,
            'type': None,
            'cycles': [],
            'cross_process': False
        }
        
        # å»ºç«‹ç­‰å¾…åœ–
        wait_graph = {}
        lock_holders = {}
        thread_map = {t.tid: t for t in all_threads}
        
        for thread in all_threads:
            if thread.waiting_info and 'held by' in thread.waiting_info:
                # è§£æç­‰å¾…è³‡è¨Š
                match = re.search(r'held by (?:thread\s+)?(\d+)', thread.waiting_info)
                if match:
                    wait_graph[thread.tid] = match.group(1)
                
                # æª¢æŸ¥æ˜¯å¦åœ¨ç­‰å¾…å…¶ä»–é€²ç¨‹
                cross_match = re.search(r'held by tid=(\d+) in process (\d+)', thread.waiting_info)
                if cross_match:
                    deadlock_info['cross_process'] = True
            
            # è¨˜éŒ„é–æŒæœ‰è€…
            for lock in thread.held_locks:
                lock_holders[lock] = thread.tid
        
        # ä½¿ç”¨ Tarjan ç®—æ³•æª¢æ¸¬å¼·é€£é€šåˆ†é‡ï¼ˆå¾ªç’°ï¼‰
        cycles = self._tarjan_scc(wait_graph)
        
        if cycles:
            deadlock_info['has_deadlock'] = True
            deadlock_info['type'] = 'circular_wait'
            
            # è½‰æ›å¾ªç’°ç‚ºç·šç¨‹è³‡è¨Š
            for cycle in cycles:
                cycle_info = []
                for tid in cycle:
                    if tid in thread_map:
                        thread = thread_map[tid]
                        cycle_info.append({
                            'tid': tid,
                            'name': thread.name,
                            'state': thread.state.value,
                            'waiting_on': thread.waiting_locks[0] if thread.waiting_locks else None
                        })
                
                if cycle_info:
                    deadlock_info['cycles'].append(cycle_info)
        
        # æª¢æŸ¥å…¶ä»–é¡å‹çš„æ­»é–
        # 1. å„ªå…ˆç´šåè½‰
        high_prio_waiting = []
        low_prio_holding = []
        
        for thread in all_threads:
            if thread.prio and thread.prio.isdigit():
                prio = int(thread.prio)
                if prio <= 5 and thread.waiting_locks:  # é«˜å„ªå…ˆç´šç­‰å¾…
                    high_prio_waiting.append(thread)
                elif prio >= 8 and thread.held_locks:  # ä½å„ªå…ˆç´šæŒæœ‰
                    low_prio_holding.append(thread)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å„ªå…ˆç´šåè½‰
        for high_thread in high_prio_waiting:
            for low_thread in low_prio_holding:
                if any(lock in low_thread.held_locks for lock in high_thread.waiting_locks):
                    if not deadlock_info['has_deadlock']:
                        deadlock_info['has_deadlock'] = True
                        deadlock_info['type'] = 'priority_inversion'
                    break
        
        # å„²å­˜çµæœä¾›å¾ŒçºŒä½¿ç”¨
        self._last_deadlock_cycles = deadlock_info.get('cycles', [])
        
        return deadlock_info

    def _tarjan_scc(self, graph: Dict[str, str]) -> List[List[str]]:
        """ä½¿ç”¨ Tarjan ç®—æ³•å°‹æ‰¾å¼·é€£é€šåˆ†é‡ï¼ˆç”¨æ–¼æ­»é–æª¢æ¸¬ï¼‰"""
        index_counter = [0]
        stack = []
        lowlinks = {}
        index = {}
        on_stack = {}
        sccs = []
        
        def strongconnect(node):
            index[node] = index_counter[0]
            lowlinks[node] = index_counter[0]
            index_counter[0] += 1
            stack.append(node)
            on_stack[node] = True
            
            # è€ƒæ…®å¾Œç¹¼ç¯€é»
            if node in graph:
                successor = graph[node]
                if successor not in index:
                    strongconnect(successor)
                    lowlinks[node] = min(lowlinks[node], lowlinks[successor])
                elif on_stack.get(successor, False):
                    lowlinks[node] = min(lowlinks[node], index[successor])
            
            # å¦‚æœç¯€é»æ˜¯æ ¹ç¯€é»ï¼Œå‰‡å½ˆå‡ºå †ç–Šä¸¦ç”Ÿæˆ SCC
            if lowlinks[node] == index[node]:
                scc = []
                while True:
                    w = stack.pop()
                    on_stack[w] = False
                    scc.append(w)
                    if w == node:
                        break
                # åªè¿”å›åŒ…å«å¤šå€‹ç¯€é»çš„ SCCï¼ˆé€™äº›æ˜¯å¾ªç’°ï¼‰
                if len(scc) > 1:
                    sccs.append(scc)
        
        # å°åœ–ä¸­çš„æ¯å€‹ç¯€é»èª¿ç”¨ç®—æ³•
        for node in graph:
            if node not in index:
                strongconnect(node)
        
        return sccs
    
    def _detect_watchdog_timeout(self, content: str) -> Optional[Dict]:
        """æª¢æ¸¬ Watchdog è¶…æ™‚"""
        watchdog_patterns = [
            r'Watchdog.*detected.*deadlock',
            r'WATCHDOG.*TIMEOUT',
            r'system_server.*anr.*Trace\.txt'
        ]
        
        for pattern in watchdog_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                return {
                    'type': 'Watchdog Timeout',
                    'severity': 'critical',
                    'description': 'System server å¯èƒ½ç™¼ç”Ÿæ­»é–æˆ–åš´é‡é˜»å¡'
                }
        
        return None

    def _identify_crashlytics_tags(self, thread_info: ThreadInfo) -> List[str]:
        """è­˜åˆ¥ Firebase Crashlytics é¢¨æ ¼çš„æ¨™ç±¤"""
        tags = []
        
        # Triggered ANR
        if thread_info.state == ThreadState.BLOCKED and thread_info.tid == "1":
            tags.append("Triggered ANR")
        
        # Root blocking
        if thread_info.held_locks and not thread_info.waiting_locks:
            tags.append("Root blocking")
        
        # IO Root blocking
        for frame in thread_info.backtrace[:5]:
            if any(io in frame for io in ['FileInputStream', 'FileOutputStream', 'fdatasync']):
                tags.append("IO Root blocking")
                break
        
        # Deadlocked
        if self._is_in_deadlock(thread_info):
            tags.append("Deadlocked")
        
        return tags

    def _is_in_deadlock(self, thread_info: ThreadInfo) -> bool:
        """æª¢æŸ¥ç·šç¨‹æ˜¯å¦åœ¨æ­»é–ä¸­"""
        # å¦‚æœç·šç¨‹åœ¨ç­‰å¾…é–ï¼Œä¸”è©²é–è¢«å…¶ä»–ç·šç¨‹æŒæœ‰
        if thread_info.waiting_info and 'held by' in thread_info.waiting_info:
            # ç°¡å–®æª¢æŸ¥ï¼šå¦‚æœç­‰å¾…è³‡è¨Šä¸­åŒ…å«æ­»é–ç›¸é—œé—œéµå­—
            deadlock_keywords = ['deadlock', 'circular', 'cycle']
            if any(keyword in thread_info.waiting_info.lower() for keyword in deadlock_keywords):
                return True
            
            # å¦‚æœæœ‰ç­‰å¾…é–ä¸”ç‹€æ…‹æ˜¯ BLOCKED
            if thread_info.state == ThreadState.BLOCKED and thread_info.waiting_locks:
                return True
        
        return False
    
    def _detect_strictmode_violations(self, content: str) -> List[Dict]:
        """æª¢æ¸¬ StrictMode é•è¦"""
        violations = []
        
        strictmode_patterns = {
            'DiskReadViolation': 'ä¸»ç·šç¨‹ç£ç¢Ÿè®€å–',
            'DiskWriteViolation': 'ä¸»ç·šç¨‹ç£ç¢Ÿå¯«å…¥',
            'NetworkViolation': 'ä¸»ç·šç¨‹ç¶²è·¯æ“ä½œ',
            'CustomSlowCallViolation': 'è‡ªå®šç¾©æ…¢èª¿ç”¨',
            'ResourceMismatchViolation': 'è³‡æºä¸åŒ¹é…'
        }
        
        for violation_type, description in strictmode_patterns.items():
            if violation_type in content:
                violations.append({
                    'type': violation_type,
                    'description': description,
                    'suggestion': 'å°‡æ“ä½œç§»è‡³èƒŒæ™¯ç·šç¨‹'
                })
        
        return violations

    def _analyze_gc_impact(self, content: str) -> Dict:
        """åˆ†æåƒåœ¾å›æ”¶çš„å½±éŸ¿"""
        gc_info = {
            'gc_count': 0,
            'total_pause_time': 0,
            'concurrent_gc': 0,
            'explicit_gc': 0,
            'alloc_gc': 0,
            'impact': 'low'
        }
        
        # è§£æ GC æ—¥èªŒ
        gc_patterns = [
            r'GC_FOR_ALLOC.*?paused\s+(\d+)ms',
            r'GC_CONCURRENT.*?paused\s+(\d+)ms\+(\d+)ms',
            r'GC_EXPLICIT.*?paused\s+(\d+)ms',
            r'Clamp target GC heap'
        ]
        
        for pattern in gc_patterns:
            matches = re.findall(pattern, content)
            gc_info['gc_count'] += len(matches)
            
            # è¨ˆç®—ç¸½æš«åœæ™‚é–“
            for match in matches:
                if isinstance(match, tuple):
                    gc_info['total_pause_time'] += sum(int(x) for x in match)
                else:
                    gc_info['total_pause_time'] += int(match)
        
        # è©•ä¼°å½±éŸ¿
        if gc_info['total_pause_time'] > 1000:  # è¶…é1ç§’
            gc_info['impact'] = 'high'
        elif gc_info['total_pause_time'] > 500:  # è¶…é500ms
            gc_info['impact'] = 'medium'
        
        return gc_info

    def _calculate_system_health_score(self, anr_info: ANRInfo) -> Dict:
        """è¨ˆç®—ç³»çµ±å¥åº·åº¦è©•åˆ†"""
        score = 100
        factors = []
        
        # CPU ä½¿ç”¨ç‡
        if anr_info.cpu_usage:
            cpu_total = anr_info.cpu_usage.get('total', 0)
            if cpu_total > 90:
                score -= 30
                factors.append(f"CPU éè¼‰ ({cpu_total}%)")
            elif cpu_total > 70:
                score -= 15
                factors.append(f"CPU åé«˜ ({cpu_total}%)")
        
        # è¨˜æ†¶é«”å£“åŠ›
        if anr_info.memory_info:
            available = anr_info.memory_info.get('available', 0)
            if available < 100 * 1024:  # å°æ–¼ 100MB
                score -= 25
                factors.append("è¨˜æ†¶é«”åš´é‡ä¸è¶³")
        
        # ç·šç¨‹æ•¸é‡
        thread_count = len(anr_info.all_threads)
        if thread_count > 200:
            score -= 20
            factors.append(f"ç·šç¨‹éå¤š ({thread_count})")
        
        # é˜»å¡ç·šç¨‹
        blocked_count = sum(1 for t in anr_info.all_threads if t.state == ThreadState.BLOCKED)
        if blocked_count > 10:
            score -= 20
            factors.append(f"å¤§é‡é˜»å¡ç·šç¨‹ ({blocked_count})")
        
        return {
            'score': max(0, score),
            'factors': factors,
            'recommendation': self._get_health_recommendation(score)
        }

    def _analyze_fortify_failure(self, content: str) -> Optional[Dict]:
        """åˆ†æ FORTIFY å¤±æ•—"""
        fortify_match = re.search(r'FORTIFY:\s*(.+)', content)
        if fortify_match:
            return {
                'type': 'FORTIFY Protection',
                'message': fortify_match.group(1),
                'severity': 'security',
                'suggestion': 'æª¢æŸ¥ç·©è¡å€å¤§å°å’Œå­—ä¸²æ“ä½œå®‰å…¨æ€§'
            }
        return None
    
class HTMLReportGenerator:
    """HTML å ±å‘Šç”Ÿæˆå™¨åŸºé¡"""
    
    def __init__(self, source_linker: SourceLinker):
        self.source_linker = source_linker
        self.html_parts = []
    
    def add_section(self, title: str, content: str, section_class: str = ""):
        """æ·»åŠ ä¸€å€‹å€æ®µ"""
        self.html_parts.append(f'''
        <div class="section {section_class}">
            <h2>{title}</h2>
            <div class="section-content">
                {content}
            </div>
        </div>
        ''')
    
    def add_backtrace(self, title: str, backtrace: List[str], limit: int = 20):
        """æ·»åŠ å¯é»æ“Šçš„å †ç–Šè¿½è¹¤"""
        if not backtrace:
            self.add_section(title, "<p>ç„¡å †ç–Šè³‡è¨Š</p>", "backtrace-section")
            return
        
        html_frames = []
        for i, frame in enumerate(backtrace[:limit]):
            html_frames.append(self.source_linker.create_backtrace_link(frame, i))
        
        if len(backtrace) > limit:
            html_frames.append(f'<div class="more-frames">... é‚„æœ‰ {len(backtrace) - limit} å¹€</div>')
        
        content = f'''
        <div class="backtrace">
            {''.join(html_frames)}
        </div>
        '''
        
        self.add_section(title, content, "backtrace-section")
    
    def add_code_block(self, title: str, code: str, language: str = ""):
        """æ·»åŠ ä»£ç¢¼å¡Šï¼Œå…¶ä¸­çš„å…§å®¹å¯é»æ“Š"""
        lines = code.split('\n')
        linked_lines = []
        
        for line in lines:
            if line.strip():
                linked_line = self.source_linker.create_link(line)
                linked_lines.append(linked_line)
            else:
                linked_lines.append('')
        
        content = f'''
        <pre class="code-block {language}">
{'<br>'.join(linked_lines)}
        </pre>
        '''
        
        self.add_section(title, content, "code-section")
    
    def generate_html(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ HTML"""
        return ''.join(self.html_parts)
                            
def main():
    """ä¸»å‡½æ•¸"""
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python3 vp_analyze_logs.py <è¼¸å…¥è³‡æ–™å¤¾> <è¼¸å‡ºè³‡æ–™å¤¾>")
        print("ç¯„ä¾‹: python3 vp_analyze_logs.py logs/ output/")
        print("\nç‰¹é»:")
        print("  â€¢ ä½¿ç”¨ç‰©ä»¶å°å‘è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•å’Œç¶­è­·")
        print("  â€¢ æ”¯æ´æ‰€æœ‰ Android ç‰ˆæœ¬çš„ ANR å’Œ Tombstone æ ¼å¼")
        print("  â€¢ åŸºæ–¼å¤§é‡çœŸå¯¦æ¡ˆä¾‹çš„æ™ºèƒ½åˆ†æ")
        print("  â€¢ æä¾›è©³ç´°çš„æ ¹æœ¬åŸå› åˆ†æå’Œè§£æ±ºå»ºè­°")
        sys.exit(1)
    
    input_folder = sys.argv[1]
    output_folder = sys.argv[2]
    
    # å‰µå»ºåˆ†æç³»çµ±ä¸¦åŸ·è¡Œ
    analyzer = LogAnalyzerSystem(input_folder, output_folder)
    analyzer.analyze()


if __name__ == "__main__":
    main()